#! /usr/bin/env python #%# -*- mode: python -*- vi: set ft=python :
#SBATCH --account=%{ACCOUNT}
#%  if JOB.qos is defined:
#SBATCH --qos=%{JOB.qos}
#%  endif
#SBATCH --job-name=%{EXP_ID}.%{JOB.id}
#SBATCH --partition=prepost,shared
#%  if JOB.tasks is defined:
#SBATCH --ntasks=%{JOB.tasks}
#%  endif
#%  if JOB.hardware_threads|default('') is not set:
#SBATCH --ntasks-per-core=1
#%  endif
#SBATCH --output=%{SCRIPT_DIR}/%x.%j.log
#SBATCH --time=%{JOB.time_limit}

'''\
Create monitoring from ICON experiment data for a given period
'''

import argparse
import errno
import os
import shutil
import subprocess
import sys

#% include 'standard_experiments/mtime.tmpl'
#% include 'standard_experiments/logging.tmpl'

# Process command line options

def check_date(arg):
    try:
        value = mtime.DateTime(arg)
    except ValueError as ve:
        raise argparse.ArgumentTypeError(ve.message)
    return str(value.date)

command_line = argparse.ArgumentParser(description=__doc__.split('\n', 1)[0])
command_line.add_argument('start_date', type=check_date, help=
    'first date of period (YYYY-MM-DD... or YYYYMMDD...)')
command_line.add_argument('-V', '--version', action='version', version="""
$Id: DEFAULT.mon.tmpl 1 2021-05-04 23:03:55Z m221078 $
%{VERSIONS_|join('\n')}
""")
command_line.add_argument('-c', '--clean', action='store_true', help=
    'remove output files. '
    'Use ONLY after you made absolutely sure that the raw data still exists!')
command_line.add_argument('-f', '--force', action='store_true', help=
    'continue to run even if working directory exists. '
    'Use ONLY after you made absolutely sure that no other job is running!')
args = command_line.parse_args()

# Do time computations using mtime

initial_date = mtime.DateTime('%{INITIAL_DATE}')
start_date = mtime.DateTime(args.start_date)

if start_date < initial_date:
    logging.error("start_date is before initial_date")
    sys.exit(1)
    
interval = mtime.TimeDelta('%{INTERVAL}')
next_date = start_date + interval
end_date = next_date + mtime.TimeDelta('-P1D')

# Define required output

#%  set set_tags = []
#%  if JOB.tags is defined:
#%      set tags = JOB.tags
#%      for tag in tags.scalars|sort if tags[tag] is set:
#%          do set_tags.append(tag)
#%      endfor
#%  endif
tags = %{set_tags}

# Set-up template variables

template_dict = {}
template_dict['start_date'] = args.start_date.replace('-', '')
template_dict['end_date'] = str(end_date.date).replace('-', '')
template_dict['tags'] = ' '.join(tags)
template_dict['mean_op'] = '%{JOB.mean_op|d('yearavg')}'

# Prolog

logging.info('monitoring started '
             'for {start_date}-{end_date}'.format(**template_dict))

# Set-up directory structure

targets_dir = os.path.join('%{MON_DIR}', 'targets')
try: os.makedirs(targets_dir)
except OSError as xcptn:
    if xcptn.errno != errno.EEXIST: raise
template_dict['targets_dir'] = targets_dir

work_dir = os.path.join('%{JOB.work_dir}',
                        '%{JOB.id}_{start_date}-{end_date}'.
                        format(**template_dict))

logging.info('working directory is {0}'.format(work_dir))

try:
    os.makedirs(work_dir)
except OSError as xcptn:
    if xcptn.errno != errno.EEXIST:
        raise
    if args.force:
        logging.info('forcing clean-up of existing working directory')
        shutil.rmtree(work_dir)
        os.mkdir(work_dir)
    else:
        logging.error('working directory exists. '
                      'Check for running jobs, then consider using --force')
        sys.exit(1)

os.chdir(work_dir)

# Generate Makefile

makefile_template = '''\
CDO = cdo
CDOFLAGS = -s -O
PLOT_TIMESER = plot_timeser

EXP_ID = %{EXP_ID}
DATA_DIR = %{DATA_DIR}
MON_DIR = %{MON_DIR}
SCRIPT_DIR = %{SCRIPT_DIR}

MON_SCRIPT = $(SCRIPT_DIR)/$(EXP_ID).%{JOB.id}
MON_INDEX_SCRIPT = $(SCRIPT_DIR)/$(EXP_ID).mon_index

START_DATE = {start_date}
TAGS = {tags}
TARGETS_DIR = {targets_dir}
MEAN_OP = {mean_op}

TARGETS = $(TAGS:%=$(TARGETS_DIR)/$(EXP_ID)_%_$(START_DATE).html) $(MON_DIR)/index.html

all: $(TARGETS)

clean:
	$(RM) $(TARGETS) $(TARGETS:.html=.pdf) $(TARGETS:.html=.nc)

.PRECIOUS: $(TARGETS_DIR)/$(EXP_ID)_%_$(START_DATE).pdf $(TARGETS_DIR)/$(EXP_ID)_%_$(START_DATE).nc

$(MON_DIR)/index.html: $(MON_INDEX_SCRIPT)
	SHELL= filelock $@ -c '$(MON_INDEX_SCRIPT) $@'

$(TARGETS_DIR)/$(EXP_ID)_%_$(START_DATE).nc: $(DATA_DIR)/$(EXP_ID)_%_$(START_DATE).nc $(MON_SCRIPT)
	SHELL= filelock $(TARGETS_DIR)/$(EXP_ID)_$*.nc -c \
	   'set -e ;\
	    if [ -f $(MON_DIR)/$(EXP_ID)_$*.nc ] ;\
	    then \
	        $(CDO) $(CDOFLAGS) mergetime $< $(MON_DIR)/$(EXP_ID)_$*.nc \
	            $(EXP_ID)_$*.nc ;\
	        mv $(EXP_ID)_$*.nc $(MON_DIR)/$(EXP_ID)_$*.nc ;\
	    else \
	        cp $< $(MON_DIR)/$(EXP_ID)_$*.nc ;\
	    fi'
	touch $@

$(TARGETS_DIR)/$(EXP_ID)_%_$(START_DATE).pdf: $(TARGETS_DIR)/$(EXP_ID)_%_$(START_DATE).nc
	SHELL= filelock $(TARGETS_DIR)/$(EXP_ID)_$*.pdf \
	    filelock -s $(TARGETS_DIR)/$(EXP_ID)_$*.nc -c \
	   'set -e ;\
      $(CDO) $(CDOFLAGS) $(MEAN_OP) $(MON_DIR)/$(EXP_ID)_$*.nc \
	            $(EXP_ID)_$*_yearavg.nc ;\
	    mv $(EXP_ID)_$*_yearavg.nc $(MON_DIR)/$(EXP_ID)_$*_yearavg.nc ;\
	    cd $(MON_DIR) ;\
	    $(PLOT_TIMESER) --manifest=$(EXP_ID)_$*.lst --mode=monitoring \
	        --with1=$(EXP_ID)_$*.nc --with1a=$(EXP_ID)_$*_yearavg.nc --output=$(EXP_ID)_$*'
	touch $@

$(TARGETS_DIR)/$(EXP_ID)_%_$(START_DATE).html: $(TARGETS_DIR)/$(EXP_ID)_%_$(START_DATE).pdf
	SHELL= filelock $(TARGETS_DIR)/$(EXP_ID)_$*.html \
	    filelock -s $(TARGETS_DIR)/$(EXP_ID)_$*.pdf -c \
	   'set -e ;\
	    mkdir -p $* ;\
	    TEMP=$$PWD/$* ;\
	    export TEMP ;\
	    cd $(MON_DIR) ;\
	    create_plot_browser -t "$(EXP_ID) $*" $(EXP_ID)_$*.lst \
	        > $(EXP_ID)_$*.html'
	touch $@ 
'''

makefile_name = 'Makefile'
makefile = open(makefile_name, mode='w')
makefile.write(makefile_template.format(**template_dict))
makefile.close()

# Create common NCL setup

resfile_text = '''\
*wkForegroundColor  : (/0.,0.,0./)
*wkBackgroundColor  : (/1.,1.,1./)
*Font               : helvetica 
*TextFuncCode       : ~     
*wkWidth            : 800
*wkHeight           : 800
*wsMaximumSize      : 32556688
'''

resfile_name = 'hluresfile'
resfile = open(resfile_name, mode='w')
resfile.write(resfile_text)
resfile.close()

os.putenv('PATH', os.pathsep.join((os.path.join('%{MODEL_DIR}', 'utils'),
                                   os.getenv('PATH'))))
os.putenv('NCARG_USRRESFILE', resfile_name)

# Make sure that mergetime does not create duplicate data when run again

os.putenv('SKIP_SAME_TIME', '1')
os.putenv('SKIPSAMETIME', '1') # workaround for bug in cdo-1.9.6

# Run the actual make process

make_args = ['make', '-k', '-j', '%{JOB.tasks|d(1)}']
if args.clean: make_args.append('clean')
make = subprocess.Popen(make_args, universal_newlines=True,
                        stdout=subprocess.PIPE, stderr=subprocess.STDOUT)

while True:
    line = make.stdout.readline()
    if not line: break
    logging.info(line.rstrip('\n'))

make_result = make.wait()
if make_result:
    logging.error("'{0}' returned {1}".format(' '.join(make_args), make_result))
    sys.exit(1)

os.chdir('%{SCRIPT_DIR}')

#%  if JOB.debug_level|d(0)|int < 1:
shutil.rmtree(work_dir)

#%  endif

# Epilog

logging.info('monitoring finished '
             'for {start_date}-{end_date}'.format(**template_dict))

#% for job in JOB['.trigger']|list:
#%   if job:
subprocess.check_call(['%{JOB.batch_command}', '%{EXP_ID}.%{job}', args.start_date])
#%   endif
#% endfor
