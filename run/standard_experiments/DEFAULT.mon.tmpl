#! /usr/bin/env python #%# -*- mode: python -*- vi: set ft=python :
#SBATCH --account=%{ACCOUNT}
#%  if JOB.qos is defined:
#SBATCH --qos=%{JOB.qos}
#%  endif
#SBATCH --job-name=%{EXP_ID}.%{JOB.id}
#SBATCH --partition=prepost,shared
#%  if JOB.tasks is defined:
#SBATCH --ntasks=%{JOB.tasks}
#%  endif
#%  if JOB.hardware_threads|default('') is not set:
#SBATCH --ntasks-per-core=1
#%  endif
#SBATCH --output=%{SCRIPT_DIR}/%x.%j.log
#SBATCH --time=%{JOB.time_limit}

'''\
Create monitoring from ICON experiment data for a given period
'''

import argparse
import logging
import os
import re
import subprocess
import sys

sys.path.append(os.path.join('%{MODEL_DIR}', 'lib', 'python'))
import mtime

# Process command line options

def check_date(arg):
    try:
        value = mtime.DateTime(arg)
    except ValueError as ve:
        raise argparse.ArgumentTypeError(ve.message)
    return str(value.date)

command_line = argparse.ArgumentParser(description=__doc__.split('\n', 1)[0])
command_line.add_argument('start_date', type=check_date, help=
    'first date of period (YYYY-MM-DD... or YYYYMMDD...)')
command_line.add_argument('-V', '--version', action='version', version='%{VERSIONS_|join(" ")|trim()}')
command_line.add_argument('-c', '--clean', action='store_true', help=
    'remove output files. '
    'Use ONLY after you made absolutely sure that the raw data still exists!')
args = command_line.parse_args()

# Do time computations using mtime

mtime.setCalendar(mtime.CALENDAR_TYPE.%{calendar_mtime})

initial_date = mtime.DateTime('%{INITIAL_DATE}')
start_date = mtime.DateTime(args.start_date)

if start_date < initial_date:
    sys.stderr.write("Oops: start_date is before initial_date\n")
    sys.exit(1)
    
interval = mtime.TimeDelta('%{INTERVAL}')
next_date = start_date + interval
end_date = next_date + mtime.TimeDelta('-P1D')

# Define required output

tags = ['atm_mon', 'hamocc_monitor', 'oce_mon']

# Set-up template variables

template_dict = {}
template_dict['start_date'] = args.start_date.translate(None, '-')
template_dict['end_date'] = str(end_date.date).translate(None, '-')
template_dict['tags'] = ' '.join(tags)

# Prolog

logging.basicConfig(format='%(asctime)s: %(levelname)s%(message)s',
                    level=logging.INFO)
logging.addLevelName(logging.DEBUG, 'Debug: ')
logging.addLevelName(logging.INFO, '')
logging.addLevelName(logging.WARNING, 'Hey: ')
logging.addLevelName(logging.ERROR, 'Oops: ')
logging.addLevelName(logging.CRITICAL, 'Sorry: ')

logging.info('monitoring started '
             'for {start_date}-{end_date}'.format(**template_dict))

# Set-up directory structure

if not os.path.isdir('%{MON_DIR}'): os.makedirs('%{MON_DIR}')

work_dir = os.path.join('%{WORK_DIR}',
                        '%{JOB.id}_{start_date}-{end_date}'.format(**template_dict))
if not os.path.isdir(work_dir): os.makedirs(work_dir)
os.chdir(work_dir)

logging.info('working directory is {0}'.format(work_dir))

# Generate Makefile

makefile_template = '''\
CDO = cdo
CDOFLAGS = -O

EXP_ID = %{EXP_ID}
DATA_DIR = %{DATA_DIR}
MON_DIR = %{MON_DIR}

TAGS = {tags}

TARGETS = $(TAGS:%=$(MON_DIR)/$(EXP_ID)_%.pdf)

all: $(TARGETS)

clean:
	$(RM) $(TARGETS)

.PHONY: $(MON_DIR)/$(EXP_ID)_%.nc $(MON_DIR)/$(EXP_ID)_%.pdf

$(MON_DIR)/$(EXP_ID)_%.nc: $(DATA_DIR)/$(EXP_ID)_%_{start_date}.nc FORCE
	[ -f $@ ] || cp $< $@
	$(CDO) $(CDOFLAGS) mergetime $< $@ $(@F)
	mv $(@F) $@

$(MON_DIR)/$(EXP_ID)_%.pdf: $(MON_DIR)/$(EXP_ID)_%.nc FORCE
	plot_timeser --manifest=$(@:.pdf=.lst) --mode=monitoring --with1=$< --output=$(@:.pdf=)

FORCE:
'''

makefile_name = 'Makefile'
makefile = open(makefile_name, mode='w')
makefile.write(makefile_template.format(**template_dict))
makefile.close()

# Run the actual make process

# Make sure that mergetime does not create duplicate data when run again
os.putenv('SKIP_SAME_TIME', '1')
os.putenv('SKIPSAMETIME', '1') # workaround for bug in cdo-1.9.6

make_args = ['make', '-k', '-j', '%{JOB.tasks|d(1)}']
if args.clean: make_args.append('clean')
make = subprocess.Popen(make_args,
                        stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
for line in make.stdout:
    logging.info(line.rstrip('\n\r'))

make_result = make.wait()
if make_result:
    logging.error("'{0}' returned {1}".format(' '.join(make_args), make_result))
    sys.exit(1)

os.remove(makefile_name)
os.chdir('%{SCRIPT_DIR}')
os.removedirs(work_dir)

# Epilog

logging.info('monitoring finished '
             'for {start_date}-{end_date}'.format(**template_dict))

#% for job in JOB['.trigger']|list:
subprocess.check_call(['%{JOB.batch_command}', '%{EXP_ID}.%{job}', args.start_date])
#% endfor
