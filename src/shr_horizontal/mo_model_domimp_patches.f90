!>
!!               The module <i>mo_model_import_domain</i>.
!!
!!               The module <i>mo_model_import_domain</i>
!! provides functionality to import information about the models computational
!! domain. This information is read from several files that were generated by
!! the patch generator programm. The data types describing the model domain are
!! contained in <i>mo_domain_model</i>.
!!
!! @par Revision History
!! Initial version  by: Peter Korn,  MPI-M, Hamburg, June 2005
!! Modification by Thomas Heinze (2006-02-21):
!! - renamed m_modules to mo_modules
!! Modification by Thomas Heinze (2006-09-20):
!! - added method_name grid_and_patch_diagnosis
!! Modification by Pilar Ripodas, DWD, (2007-01-31)
!! - addapted to the new TYPE grid_edges (system_orientation added)
!! Modification by Peter Korn,  MPI-M, (2006-12)
!! - implementation of topography and boundary treatment, i.e.
!!   initialization of the grid & patch components that carry
!!   information about topography and the lateral boundaries of
!!   the domain; this is not related to patch boundaries.
!!   topography can either be computed by analytical l,eans or
!!   by reading from database files.
!! Modification by Hui Wan, MPI-M, (2007-02-23)
!! - Subroutine <i>init_import</i> was changed to <i>setup_grid</i>.
!!   Namelist hierarchy_ini was renamed to <i>grid_ctl</i>, moved
!!   from <i>mo_io_utilities</i> to this module and now read from
!!   an external file in subroutine <i>setup_grid</i>.
!! - Some changes in <i>init_ocean_patch_component</i> after
!!   discussion with Peter.
!! - Calculation of the min. primal edge length was added to
!!   <i>import_patches</i>. However, shouldn't it be an array with
!!   one element for each patch, rather than a scalar?
!! Modification by P. Ripodas, DWD, (2007-03-14):
!! - Now the output of "import_patches" is the min_dual_edge_lenght
!!   instead of the min_primal_edge_lenght. It will be used to set
!!   the horizontal diffusion parameter. Now it is done as it was
!!   in the prototype.
!! Modification by Almut Gassmann, MPI-M (2007-04)
!! - removed loptimize to make compatible with new grid generator
!! - removed itoa for good programming style
!! - reorganized patch input to be compatible with the new patch generator
!! - cleaning up "destruct_patches"
!! Modification by Almut Gassmann, MPI-M (2007-04-13)
!! - remove grid type and perform related adaptations
!!   (grid information comes now inside a patch)
!! - changed subroutine name form setup_grid to setup_files
!! Modified by Hui Wan, MPI-M, (2008-04-04)
!!  - topography_file_dir renamed topo_file_dir
!!  - for the hydro_atmos, control variable testtype renamed ctest_name.
!! Modified by Almut Gassmann, MPI-M, (2008-04-23)
!!  - itopo distinguishes now shallow water (itopo=1) orography function
!!    from hydro_atmos orography function (itopo=2)
!! Modification by Jochen Foerstner, DWD, (2008-07-16)
!!  - new fields in the derived type for the edges:
!!    grid_edges%primal_cart_normal (Cartesian normal to edge),
!!    grid_edges%quad_idx, grid_edges%quad_area and grid_edges%quad_orientation
!!    (indices of edges and area of the quadrilateral formed by two adjacent cells)
!!    up to now these new fields are initialized in the new routines
!!    calculate_primal_cart_normal and init_quad_twoadjcells
!!    rather than read from a grid/patch file.
!! Modification by Almut Gassmann, MPI-M, (2008-09-21)
!!  - remove reference to mask and height files, they are never used
!!  - use global_cell_type to distinguish cells as triangles or hexagons
!! Modification by Almut Gassmann, MPI-M (2008-10-30)
!!  - add subroutine init_coriolis to initialize Coriolis parameter
!! Modification by Stephan Lorenz, MPI-M (2010-02-18)
!!  - add subroutine init_ocean_patch to initialize ocean patch extensions
!! Modification by Daniel Reinert, DWD (2010-07-21)
!! - removed call of init_topography. This will be handeled within init_ext_data
!!
!! @par Copyright
!! 2002-2007 by DWD and MPI-M
!! This software is provided for non-commercial use only.
!! See the LICENSE and the WARRANTY conditions.
!!
!! @par License
!! The use of ICON is hereby granted free of charge for an unlimited time,
!! provided the following rules are accepted and applied:
!! <ol>
!! <li> You may use or modify this code for your own non commercial and non
!!    violent purposes.
!! <li> The code may not be re-distributed without the consent of the authors.
!! <li> The copyright notice and statement of authorship must appear in all
!!    copies.
!! <li> You accept the warranty conditions (see WARRANTY).
!! <li> In case you intend to use the code commercially, we oblige you to sign
!!    an according license agreement with DWD and MPI-M.
!! </ol>
!!
!! @par Warranty
!! This code has been tested up to a certain level. Defects and weaknesses,
!! which may be included in the code, do not establish any warranties by the
!! authors.
!! The authors do not make any warranty, express or implied, or assume any
!! liability or responsibility for the use, acquisition or application of this
!! software.
!!
!!

!----------------------------
#include "omp_definitions.inc"
!----------------------------

MODULE mo_model_domimp_patches
  !-------------------------------------------------------------------------
  
  USE mo_kind,               ONLY: wp
  !USE mo_io_units,           ONLY: filename_max
  USE mo_impl_constants,     ONLY: success, &
    & max_char_length,  &
    & min_rlcell, max_rlcell, &
    & min_rledge, max_rledge, &
    & min_rlvert, max_rlvert, &
    & max_dom
  USE mo_exception,          ONLY: message_text, message, warning, finish, em_warn
  USE mo_model_domain,       ONLY: t_patch, t_grid_cells, t_grid_edges, p_patch_local_parent
  USE mo_parallel_config,    ONLY: nproma
  USE mo_model_domimp_setup, ONLY: reshape_int, reshape_real,  &
    & init_quad_twoadjcells, init_coriolis, set_verts_phys_id, &
    & init_butterfly_idx, calculate_patch_cartesian_positions, &
    & fill_grid_subsets, rescale_grid
  USE mo_grid_config,        ONLY: start_lev, nroot, n_dom, n_dom_start,    &
    & lfeedback, l_limited_area, max_childdom, &
    & dynamics_grid_filename,   dynamics_parent_grid_id,  &
    & radiation_grid_filename,  global_cell_type, lplane, &
    & grid_length_rescale_factor,                         &
    & is_plane_torus, grid_sphere_radius
  USE mo_dynamics_config,    ONLY: lcoriolis
  USE mo_master_control,     ONLY: my_process_is_ocean
  USE mo_impl_constants_grf, ONLY: grf_bdyintp_start_c, grf_bdyintp_start_e
  USE mo_loopindices,        ONLY: get_indices_c, get_indices_e
  USE mo_mpi,                ONLY: my_process_is_mpi_parallel, p_comm_work
  USE mo_sync,               ONLY: disable_sync_checks, enable_sync_checks
  USE mo_communication,      ONLY: idx_no, blk_no
  USE mo_util_uuid,          ONLY: uuid_string_length, uuid_parse
  USE mo_name_list_output_config, ONLY: is_grib_output
  USE mo_master_nml,         ONLY: model_base_dir

  USE mo_grid_geometry_info, ONLY: planar_torus_geometry, sphere_geometry, &
    &  set_grid_geometry_derived_info, copy_grid_geometry_info, parallel_read_geometry_info
  USE mo_alloc_patches,      ONLY: set_patches_grid_filename, allocate_basic_patch, &
    & allocate_remaining_patch
  USE mo_math_constants,     ONLY: pi, pi_2
  USE mo_grid_subset,        ONLY: t_subset_range, get_index_range
  
#ifndef NOMPI
  ! The USE statement below lets this module use the routines from
  ! mo_read_netcdf_parallel where only 1 processor is reading
  ! and broadcasting the results
  
  USE mo_read_netcdf_parallel, ONLY:                &
    & nf_nowrite, nf_global, nf_noerr, nf_strerror,  &
    & nf_open            => p_nf_open,               &
    & nf_close           => p_nf_close,              &
    & nf_inq_dimid       => p_nf_inq_dimid,          &
    & nf_inq_dimlen      => p_nf_inq_dimlen,         &
    & nf_inq_varid       => p_nf_inq_varid,          &
    & nf_get_att_text    => p_nf_get_att_text,       &
    & nf_get_att_int     => p_nf_get_att_int,        &
    & nf_get_att_double  => p_nf_get_att_double,     &
    & nf_get_var_int     => p_nf_get_var_int,        &
    & nf_get_var_double  => p_nf_get_var_double
#endif
  
  IMPLICIT NONE
  
  PRIVATE
  
#ifdef NOMPI
  INCLUDE 'netcdf.inc'
#endif
  
  CHARACTER(LEN=*), PARAMETER :: version = '$Id$'
  
  !modules interface-------------------------------------------
  !subroutines
  PUBLIC :: import_basic_patches
  PUBLIC :: complete_patches
!   PUBLIC :: get_patch_global_indexes
  
  INTEGER :: ishift_child_id
  
  !-------------------------------------------------------------------------
  
CONTAINS
  
!   !-------------------------------------------------------------------------
!   SUBROUTINE get_patch_global_indexes(patch_no, entity_type, no_of_entities, global_indexes)
!     USE mo_model_domain, ONLY: pp_patch
!     USE mo_impl_constants, ONLY: cells, edges, verts
!     
!     INTEGER, INTENT(in) :: patch_no, entity_type
!     INTEGER, INTENT(out) :: no_of_entities
!     INTEGER, POINTER :: global_indexes(:)  ! this is intent out, but nec does not allows it
!     
!     INTEGER :: idx, return_status
!     
!     CHARACTER(LEN=*), PARAMETER :: method_name='get_patch_global_indexes'
!     
!     SELECT CASE(entity_type)
!     
!     CASE(cells)
!       no_of_entities = pp_patch(patch_no)%n_patch_cells
!       ALLOCATE( global_indexes(no_of_entities), stat=return_status )
!       IF (return_status /= success) THEN
!         CALL finish (method_name,'allocation for global_indexes failed')
!       ENDIF
!       DO idx = 1, no_of_entities
!         global_indexes(idx) = pp_patch(patch_no)%cells%glb_index(idx)
!         ! do some checking
!         IF (global_indexes(idx) <= 0) &
!           & CALL finish (method_name,'glb_index(idx) <= 0')
!         IF (global_indexes(idx) > pp_patch(patch_no)%n_patch_cells_g) &
!           & CALL finish (method_name,'glb_index(idx) > n_patch_cells_g')
!       ENDDO
!       
!     CASE(edges)
!       no_of_entities = pp_patch(patch_no)%n_patch_edges
!       ALLOCATE( global_indexes(no_of_entities), stat=return_status )
!       IF (return_status /= success) THEN
!         CALL finish (method_name,'allocation for global_indexes failed')
!       ENDIF
!       DO idx = 1, no_of_entities
!         global_indexes(idx) = pp_patch(patch_no)%edges%glb_index(idx)
!         ! do some checking
!         IF (global_indexes(idx) <= 0) &
!           & CALL finish (method_name,'glb_index(idx) <= 0')
!         IF (global_indexes(idx) > pp_patch(patch_no)%n_patch_edges_g) &
!           & CALL finish (method_name,'glb_index(idx) > n_patch_edges_g')
!       ENDDO
!       
!     CASE(verts)
!       no_of_entities = pp_patch(patch_no)%n_patch_verts
!       ALLOCATE( global_indexes(no_of_entities), stat=return_status )
!       IF (return_status /= success) THEN
!         CALL finish (method_name,'allocation for global_indexes failed')
!       ENDIF
!       DO idx = 1, no_of_entities
!         global_indexes(idx) = pp_patch(patch_no)%verts%glb_index(idx)
!         ! do some checking
!         IF (global_indexes(idx) <= 0) &
!           & CALL finish (method_name,'glb_index(idx) <= 0')
!         IF (global_indexes(idx) > pp_patch(patch_no)%n_patch_verts_g) &
!           & CALL finish (method_name,'glb_index(idx) > n_patch_verts_g')
!       ENDDO
!       
!     CASE default
!       CALL finish(method_name, 'entity_type not recognized')
!     END SELECT
!     
!   END SUBROUTINE get_patch_global_indexes
  !-------------------------------------------------------------------------  
  
  !-------------------------------------------------------------------------
  !>
  !!               This subroutine provides patch information to the model.
  !!
  !! Which data are required by the model is described in module
  !! <i>mo_model_domain</i>. The components of the patch are initialized
  !! with data stored in several patch files.
  !!
  !! @par Revision History
  !! Developed  by  Peter Korn, MPI-M (2005).
  !! @par
  !! Modified by L. Bonaventura, MPI-M (2005),
  !! to match completed patch
  !! structure in advanced patch generator.
  !! Modified by A. Gassmann, MPI-M (2007)
  !! - cleaning up the code
  !! Modified by A. Gassmann, MPI-M (2007-04)
  !! - grid information belongs now to the patch type
  !! Modified by Almut Gassmann, MPI-M (2008-09-21)
  !! - min_dual_edge_length no longer needed for new Diffusion
  !! Modified by Almut Gassmann, MPI-M (2008-10-30)
  !! - new subroutine for Coriolis initialization
  !! Modification by Stephan Lorenz, MPI-M (2010-02-06)
  !!  - new subroutine for initialization of ocean patch
  !! Modification by Rainer Johanni (2011-12-04)
  !!  - renamed to import_basic_patches
  !!  - only basic patch information for subdivision is read here
  !!    into the full (undivided, global) patch data structure
  !!
  SUBROUTINE import_basic_patches( patch, nlev,nlevp1,num_lev,num_levp1,nshift)
    
    INTEGER,INTENT(in) :: nlev, nlevp1
    INTEGER,INTENT(in) :: num_lev(:), num_levp1(:), nshift(:)
    TYPE(t_patch), TARGET, INTENT(inout) :: patch(n_dom_start:)
    
    INTEGER :: jg, jg1, n_chd, n_chdc
    INTEGER :: jgp            ! parent patch index
    !INTEGER :: jlev
    
    !LOGICAL :: l_exist
    
    !CHARACTER(filename_max) :: patch_file, gridtype
    
    TYPE(t_patch), POINTER ::  &
      & p_single_patch => NULL()
    
    CHARACTER(LEN=*), PARAMETER :: method_name = 'mo_model_domimp_patches/import_basic_patch'
    !-----------------------------------------------------------------------
    
    CALL message ('mo_model_domimp_patches:import_basic_patches', &
      & 'start to import patches')
    
    ! Set some basic flow control variables on the patch
    
    max_childdom = 0
    
    IF(n_dom_start==0) THEN
      ! The physics parent (parent of the root patch) should also be read
      patch(0)%id = 0
      patch(0)%level = start_lev-1
      patch(0)%parent_id = -1
      patch(0)%parent_child_index = 0
      patch(0)%n_childdom = 1
      patch(0)%n_chd_total = n_dom
      patch(0)%child_id(1) = 1
      DO jg = 1, n_dom
        patch(0)%child_id_list(jg) = jg
      ENDDO
      patch(1)%parent_child_index = 1
    ELSE
      patch(1)%parent_child_index = 0
    ENDIF
    
    DO jg = 1, n_dom
      
      patch(jg)%id = jg
      
      IF (jg == 1) THEN
        patch(jg)%level = start_lev
        patch(jg)%parent_id = 0
      ELSE
        patch(jg)%level = patch(dynamics_parent_grid_id(jg))%level + 1
        patch(jg)%parent_id = dynamics_parent_grid_id(jg)
      ENDIF
      
      n_chd = 0
      
      DO jg1 = jg+1, n_dom
        IF (jg == dynamics_parent_grid_id(jg1)) THEN
          n_chd = n_chd + 1
          patch(jg)%child_id(n_chd) = jg1
          patch(jg1)%parent_child_index = n_chd
        ENDIF
      ENDDO
      
      patch(jg)%n_childdom = n_chd
      max_childdom = MAX(1,max_childdom,n_chd)
      
      !
      ! store information about vertical levels
      !
      patch(jg)%nlev   = num_lev(jg)
      patch(jg)%nlevp1 = num_levp1(jg)
      
      IF (jg > 1) THEN
        IF (nshift(jg) > 0 ) THEN
          ! nshift has been modified via Namelist => use it
          patch(jg)%nshift = nshift(jg)
        ELSE
          ! set default value, assuming
          !- superimposed vertical levels
          !- 1 nested domain per grid level
          patch(jg)%nshift = num_lev(patch(jg)%parent_id) - num_lev(jg)
        ENDIF
        
        jgp = patch(jg)%parent_id
        patch(jg)%nshift_total = patch(jgp)%nshift_total + patch(jg)%nshift
      ELSE
        ! Note: the first nshift-value refers to the global domain
        patch(jg)%nshift = 0
        patch(jg)%nshift_total = 0
      ENDIF
      
    ENDDO
    
    ! Set information about total number of child domains (called recursively)
    ! and corresponding index lists
    
    ! Initialization
    DO jg = 1, n_dom
      patch(jg)%n_chd_total      = 0
      patch(jg)%child_id_list(:) = 0
    ENDDO
    
    DO jg = n_dom, 2, -1
      jg1 = patch(jg)%parent_id
      n_chd = patch(jg1)%n_chd_total
      n_chdc = patch(jg)%n_chd_total
      patch(jg1)%child_id_list(n_chd+1) = jg
      IF (n_chdc > 0) THEN
        patch(jg1)%child_id_list(n_chd+2:n_chd+1+n_chdc) = patch(jg)%child_id_list(1:n_chdc)
      ENDIF
      patch(jg1)%n_chd_total = n_chd+1+n_chdc
    ENDDO
    
    
    DO jg = 1, n_dom
      
      ! make nshift parameter also available for the parent patch
      IF (patch(jg)%n_childdom >= 1) THEN
        patch(jg)%nshift_child = patch(patch(jg)%child_id(1))%nshift
        DO jg1 = 1, patch(jg)%n_childdom
          IF (patch(patch(jg)%child_id(jg1))%nshift /= patch(jg)%nshift_child) &
            & CALL finish ('mo_model_domimp_patches:import_basic_patches', &
            & 'multiple nests at the same level must have the same nshift')
        ENDDO
      ELSE
        patch(jg)%nshift_child = 0
      ENDIF
      
    ENDDO
    
    IF (n_dom_start == 0) THEN ! reduced grid for radiation
      ! In case of n_dom_start == 0 nlev, nlevp1, nshift need to be copied from
      ! jg=1 to jg=0
      patch(0)%nlev   = patch(1)%nlev
      patch(0)%nlevp1 = patch(1)%nlevp1
      patch(0)%nshift = patch(1)%nshift
      ! The reduced grid always has the same levels as the global one
      patch(0)%nshift_child = 0
    ENDIF
    
    patch(n_dom_start:n_dom)%max_childdom =  max_childdom
    
    
    !init patch by reading data from file
    !required: path to patch directory and file names, see top of module
    ! l_exist = .FALSE.
    
    ! IF (lplane) THEN
    !   gridtype='plan'
    ! ELSE
    !   gridtype='icon'
    ! END IF
    
    CALL set_patches_grid_filename(patch)
    
    ishift_child_id = 0
    
    grid_level_loop: DO jg = n_dom_start, n_dom
      
      !   jlev = patch(jg)%level
      
      ! Allow file names without "DOM" specifier if n_dom=1.
      !   IF (n_dom == 1) THEN
      !     ! Check if file name without "DOM" specifier exists.
      !     WRITE (patch_file,'(a,a,i0,a,i2.2,a)') &
      !          & TRIM(gridtype),'R',nroot,'B',jlev,'-grid.nc'
      !     INQUIRE (FILE=patch_file, EXIST=l_exist)
      !     ! Otherwise use file name with "DOM" specifier
      !     IF (.NOT. l_exist)                                            &
      !          & WRITE (patch_file,'(a,a,i0,2(a,i2.2),a)')              &
      !          & TRIM(gridtype),'R',nroot,'B',jlev,'_DOM',jg,'-grid.nc'
      !   ELSE
      !     ! n_dom >1 --> "'_DOM',jg" required in file name
      !     WRITE (patch_file,'(a,a,i0,2(a,i2.2),a)') &
      !          & TRIM(gridtype),'R',nroot,'B',jlev,'_DOM',jg,'-grid.nc'
      !   ENDIF
      
      
      p_single_patch => patch(jg)
      
      CALL read_basic_patch( jg, p_single_patch )
      
    ENDDO grid_level_loop
    
    CALL complete_parent_index(patch)
    CALL set_pc_idx(patch)
    

  END SUBROUTINE import_basic_patches
  !-------------------------------------------------------------------------
  
  !-------------------------------------------------------------------------
  !>
  !! This method_name completes basic patches by
  !! - allocating the remaining arrays
  !! - reading the remaining arrays which are not in the basic patch
  !! - calculating arrays which are not read from input file
  
  SUBROUTINE complete_patches(patch)
    
    TYPE(t_patch), INTENT(inout) :: patch(n_dom_start:)
    
    INTEGER :: jg, jgp, n_lp, id_lp(max_dom)
    CHARACTER(LEN=*), PARAMETER :: method_name = 'mo_model_domimp_patches:complete_patches'
    
    DO jg = n_dom_start, n_dom
      ! Allocate and preset remaining arrays in patch
      IF(my_process_is_mpi_parallel()) THEN
        CALL allocate_remaining_patch(patch(jg),3)
        IF (jg > n_dom_start) CALL allocate_remaining_patch(p_patch_local_parent(jg),3)
      ELSE
        CALL allocate_remaining_patch(patch(jg),1)
      ENDIF
    ENDDO
    
    !--------------------
    ! Fill the subsets information
    DO jg = n_dom_start, n_dom
      CALL fill_grid_subsets(patch(jg))
    ENDDO
    IF(my_process_is_mpi_parallel() ) THEN
      DO jg = n_dom_start+1, n_dom
        CALL fill_grid_subsets( p_patch_local_parent(jg) )
      ENDDO
    ENDIF
    !--------------------
    
      
    DO jg = n_dom_start, n_dom
      n_lp = 0 ! Number of local parents on the same level
      IF(my_process_is_mpi_parallel()) THEN
        ! Assemble a list of local parents living on the same level as the current patch
        DO jgp = n_dom_start+1, n_dom
          IF(patch(jgp)%parent_id == jg) THEN
            n_lp = n_lp+1
            id_lp(n_lp) = jgp  ! these are children of the current patch
          ENDIF
        ENDDO
      ENDIF
   
      ! Get all patch information not read by read_basic_patch
      CALL read_remaining_patch( jg, patch(jg), n_lp, id_lp )
    ENDDO
    
    ! rescale grids
    DO jg = n_dom_start, n_dom
      CALL rescale_grid( patch(jg), grid_length_rescale_factor  )
    ENDDO
    IF(my_process_is_mpi_parallel() ) THEN
      DO jg = n_dom_start+1, n_dom
        CALL rescale_grid( p_patch_local_parent(jg), grid_length_rescale_factor )
      ENDDO
    ENDIF

          
    ! do other stuff  
    DO jg = n_dom_start, n_dom
      
      ! Initialize the data for the quadrilateral cells
      ! formed by the two adjacent cells of an edge.
      ! (later this should be provided by the grid generator)
      CALL init_quad_twoadjcells( patch(jg) )

      ! Initialize butterfly data structure, formed by the 
      ! 4 cells sharing the 2 vertices which bound a given edge.
      IF (patch(jg)%cell_type == 3) THEN
        ! not useful for hexagonal grid 
        CALL init_butterfly_idx( patch(jg) )
      ENDIF

      CALL init_coriolis( lcoriolis, lplane, patch(jg) )
      
      CALL set_verts_phys_id( patch(jg) )
      
      ! The same has to be done for local parents in parallel runs
      !
      ! Please note: The call to init_quad_twoadjcells involves boundary
      ! exchange and is not repeated here for local parents.
      ! The arrays calculated there are transfered to the local parent
      ! in transfer_interpol_state where also a lot of other arrays
      ! from the patch state are transferred
      
      IF(my_process_is_mpi_parallel() .AND. jg>n_dom_start) THEN
        CALL disable_sync_checks
        CALL init_coriolis( lcoriolis, lplane, p_patch_local_parent(jg) )
        CALL set_verts_phys_id( p_patch_local_parent(jg) )
        CALL enable_sync_checks
      ENDIF
      
    ENDDO
    
  END SUBROUTINE complete_patches
  !-------------------------------------------------------------------------
  
  !-------------------------------------------------------------------------
  !> 
  ! calculate mean geometry properties for old grids,
  ! the new grids should have these values filled
  ! All the patches should have the same geometry type
  SUBROUTINE set_grid_mean_geometry_info( patch )
    TYPE(t_patch), INTENT(inout), TARGET ::  patch  
    
    CHARACTER(LEN=*), PARAMETER :: method_name = 'mo_model_domimp_patches:set_grid_mean_geometry_info'
    
    !-----------------------------------------------------------------------
    SELECT CASE(patch%geometry_info%geometry_type)
    
    CASE (planar_torus_geometry)

      CALL finish(method_name, "planar_torus_geometry should be read from the grid file")

    CASE (sphere_geometry)
      ! note that the grid_sphere_radius is already rescaled
      patch%geometry_info%sphere_radius = grid_sphere_radius / grid_length_rescale_factor
      ! divide the sphere surface by the number of cells
      ! Note: this works only for old grids
      patch%geometry_info%mean_cell_area = &
        & (4._wp * pi * patch%geometry_info%sphere_radius &
        & * patch%geometry_info%sphere_radius)            &
        & / REAL(20*nroot**2*4**(patch%level),wp)
        
      patch%geometry_info%domain_length  = 2.0_wp * pi * patch%geometry_info%sphere_radius
      patch%geometry_info%domain_height  = patch%geometry_info%domain_length
      
      ! Note: the mean_edge_length is not used for the sphere geometry,
      ! and calculating will require global communication. Set to 0
      patch%geometry_info%mean_edge_length = 0.0_wp
    
    CASE default    
      CALL finish(method_name, "Undefined geometry type")
      
    END SELECT
    
  END SUBROUTINE set_grid_mean_geometry_info
  !-------------------------------------------------------------------------
  
  !-------------------------------------------------------------------------
  !>
  !! This method_name completes the patch information for parent edges
  !!
  !! @par Revision History
  !! Developed  by Guenther. Zaengl, DWD, 2009-03-19
  !! Moved here by Rainer Johanni, Oct 2011
  !!
  SUBROUTINE complete_parent_index(patch)
    
    TYPE(t_patch), TARGET, INTENT(inout) :: patch(n_dom_start:)
    
    ! local variables
    
    TYPE(t_grid_edges), POINTER :: p_gep => NULL()
    TYPE(t_patch),      POINTER :: p_pp => NULL()
    
    INTEGER :: jb, je, jg, ji, i_startblk, i_endblk,         &
      & i_startidx, i_endidx, iic, ibc, i_nchdom, i_child_id
    
    !-----------------------------------------------------------------------
    !
    
    DO jg = n_dom_start, n_dom-1
      
      p_gep  => patch(jg)%edges
      p_pp   => patch(jg)
      
      i_nchdom = p_pp%n_childdom
      IF (i_nchdom == 0) CYCLE
      
!$OMP PARALLEL PRIVATE(i_startblk,i_endblk)
      
      i_startblk = p_gep%start_blk(grf_bdyintp_start_e,1)
      i_endblk   = p_gep%end_blk(min_rledge,i_nchdom)
      
      ! Complete parent edge information
!$OMP DO PRIVATE(jb,i_startidx,i_endidx,ji,je,iic,ibc,i_child_id) ICON_OMP_DEFAULT_SCHEDULE
      DO jb = i_startblk, i_endblk
        
        CALL get_indices_e(p_pp, jb, i_startblk, i_endblk, &
          & i_startidx, i_endidx, grf_bdyintp_start_e, min_rledge)
        
        DO ji = 3, 4 ! Index completion only needed for child edges 3+4
          DO je = i_startidx, i_endidx
            
            iic = p_gep%child_idx(je,jb,ji)
            ibc = p_gep%child_blk(je,jb,ji)
            i_child_id = p_gep%child_id(je,jb)
            
            IF ((iic/= 0) .AND. (ibc/= 0)) THEN
              patch(i_child_id)%edges%parent_idx(iic,ibc) = je
              patch(i_child_id)%edges%parent_blk(iic,ibc) = jb
            ENDIF
          ENDDO
        ENDDO
      ENDDO
!$OMP END DO NOWAIT
!$OMP END PARALLEL
      
    ENDDO
    
  END SUBROUTINE complete_parent_index
  
  !-------------------------------------------------------------------------
  !>
  !! This method_name sets the parent-child-index for cells and edges
  !!
  !! @par Revision History
  !! Developed  by Rainer Johanni, Dec 2011
  !!
  SUBROUTINE set_pc_idx(patch)
    
    TYPE(t_patch), TARGET, INTENT(inout) :: patch(n_dom_start:)
    
    ! local variables
    
    INTEGER :: jg, jgp, jb, jl, ilp, ibp, nlen
    
    !-----------------------------------------------------------------------
    
    DO jg = n_dom_start+1, n_dom
      
      jgp = patch(jg)%parent_id
      
      patch(jg)%cells%pc_idx(:,:) = 0
      patch(jg)%edges%pc_idx(:,:) = 0
      
      DO jb = 1, patch(jg)%nblks_c
        
        IF (jb /= patch(jg)%nblks_c) THEN
          nlen = nproma
        ELSE
          nlen = patch(jg)%npromz_c
        ENDIF
        
        DO jl = 1, nlen
          
          ilp = patch(jg)%cells%parent_idx(jl,jb)
          ibp = patch(jg)%cells%parent_blk(jl,jb)
          
          IF(patch(jgp)%cells%child_idx(ilp,ibp,1) == jl .AND. &
            & patch(jgp)%cells%child_blk(ilp,ibp,1) == jb ) patch(jg)%cells%pc_idx(jl,jb) = 1
          IF(patch(jgp)%cells%child_idx(ilp,ibp,2) == jl .AND. &
            & patch(jgp)%cells%child_blk(ilp,ibp,2) == jb ) patch(jg)%cells%pc_idx(jl,jb) = 2
          IF(patch(jgp)%cells%child_idx(ilp,ibp,3) == jl .AND. &
            & patch(jgp)%cells%child_blk(ilp,ibp,3) == jb ) patch(jg)%cells%pc_idx(jl,jb) = 3
          IF(patch(jgp)%cells%child_idx(ilp,ibp,4) == jl .AND. &
            & patch(jgp)%cells%child_blk(ilp,ibp,4) == jb ) patch(jg)%cells%pc_idx(jl,jb) = 4
!          IF(patch(jg)%cells%pc_idx(jl,jb) == 0) CALL finish('set_pc_idx','cells%pc_idx')
          
        ENDDO
        
      ENDDO
      
      DO jb = 1, patch(jg)%nblks_e
        
        IF (jb /= patch(jg)%nblks_e) THEN
          nlen = nproma
        ELSE
          nlen = patch(jg)%npromz_e
        ENDIF
        
        DO jl = 1, nlen
          
          ilp = patch(jg)%edges%parent_idx(jl,jb)
          ibp = patch(jg)%edges%parent_blk(jl,jb)
          
          IF(patch(jgp)%edges%child_idx(ilp,ibp,1) == jl .AND. &
            & patch(jgp)%edges%child_blk(ilp,ibp,1) == jb ) patch(jg)%edges%pc_idx(jl,jb) = 1
          IF(patch(jgp)%edges%child_idx(ilp,ibp,2) == jl .AND. &
            & patch(jgp)%edges%child_blk(ilp,ibp,2) == jb ) patch(jg)%edges%pc_idx(jl,jb) = 2
          IF(patch(jgp)%edges%child_idx(ilp,ibp,3) == jl .AND. &
            & patch(jgp)%edges%child_blk(ilp,ibp,3) == jb ) patch(jg)%edges%pc_idx(jl,jb) = 3
          IF(patch(jgp)%edges%child_idx(ilp,ibp,4) == jl .AND. &
            & patch(jgp)%edges%child_blk(ilp,ibp,4) == jb ) patch(jg)%edges%pc_idx(jl,jb) = 4
!          IF(patch(jg)%edges%pc_idx(jl,jb) == 0) CALL finish('set_pc_idx','edges%pc_idx')
          
        ENDDO
        
      ENDDO
      
    ENDDO
    
  END SUBROUTINE set_pc_idx
  !-------------------------------------------------------------------------
  
  
  !-------------------------------------------------------------------------
  !>
  !! Initialization of the patch components with data stored
  !! in files.
  !!
  !! @par Revision History
  !! Developed  by  Peter Korn, MPI-M (2005).
  !! Modified by L. Bonaventura, MPI-M (2005),
  !! to match completed patch
  !! structure in advanced patch generator.
  !! Modified by A. Gassmann, MPI-M (2007-04-03)
  !! - cleaning up and adaptations for reading multiple patches
  !! Modified by A. Gassmann, MPI-M (2007-04-03)
  !! - patch owns grid information, global grid is obsolete.
  !! - changed name from init_patch to read_patch
  !! Modified by A. Gassmann, MPI-M (2008-09-21)
  !! - remove all not netcdf stuff
  !! - HERE we must think of how to use different 'global_cell_type's
  !! Modified by A. Gassmann, MPI-M (2008-10-30)
  !! - read in grid for either triangles or hexagons
  !! Modified by R. Johanni (2011-12-04)
  !! - split into read_basic_patch for reading the basic patch information
  !!   for subdivision into the fully allocated patch and read_remaining_patch
  !!   for reading the remaining information
  !!
  SUBROUTINE read_basic_patch( ig, patch, patch_file )
    
    CHARACTER(LEN=*), PARAMETER :: method_name = 'mo_model_domimp_patches/read_basic_patch'
    INTEGER,             INTENT(in)    ::  ig           ! domain ID
    CHARACTER(LEN=*),    INTENT(in), OPTIONAL ::  patch_file   ! name of grid file
    
    TYPE(t_patch), TARGET, INTENT(inout) ::  patch      ! patch data structure
    
    INTEGER, ALLOCATABLE :: &
      & array_c_int(:,:),  &  ! temporary arrays to read in integer values
      & array_e_int(:,:),  &
      & array_v_int(:,:)
    
    REAL(wp), ALLOCATABLE :: &
      & array_c_real(:,:), &  ! temporary arrays to read in real values
      & array_e_real(:,:), &
      & array_v_real(:,:)
    
    INTEGER, ALLOCATABLE :: &
      & start_idx_c(:,:), end_idx_c(:,:), &  ! temporary arrays to read in index lists
      & start_idx_e(:,:), end_idx_e(:,:), &
      & start_idx_v(:,:), end_idx_v(:,:)
    
    ! dummy values for number of internal halo cells, edges, vertices
    INTEGER :: n_e_halo_cells
    INTEGER :: n_e_halo_edges
    INTEGER :: n_e_halo_verts
    
    ! INTEGER :: patch_unit
    
    ! LOGICAL :: lnetcdf = .TRUE.
    ! CHARACTER(len=filename_max) :: file
    
    CHARACTER(LEN=uuid_string_length) :: uuid_string
    
    ! status variable
    INTEGER :: ist
    
    INTEGER :: ncid, dimid, varid, max_cell_connectivity, max_verts_connectivity
    INTEGER :: ji
    INTEGER :: jc, je, jcv, jce, ilc, ibc
    INTEGER :: icheck, ilev, igrid_level, igrid_id, iparent_id, i_max_childdom, ipar_id
    INTEGER :: block_size    
    !-----------------------------------------------------------------------
    
    ! set dummy values to zero
    n_e_halo_cells = 0
    n_e_halo_edges = 0
    n_e_halo_verts = 0
    
    ilev = patch%level
    ipar_id = patch%parent_id
    
    !
    ! start to fill patch type
    !
    IF (PRESENT(patch_file)) THEN
      patch%grid_filename=patch_file
    ENDIF
    
    
    CALL message (TRIM(method_name), 'start to init patch')
    
    WRITE(message_text,'(a,a)') 'Read grid file ', TRIM(patch%grid_filename)
    CALL message ('', TRIM(message_text))
    
    CALL nf(nf_open(TRIM(patch%grid_filename), nf_nowrite, ncid))
    
    uuid_string = 'ee34e42c-5fbb-11e1-ab9c-9b115d841c30' ! To avoid null characters in the standard output

    CALL nf(nf_get_att_text(ncid, nf_global, 'uuid', uuid_string), &
      & warnonly=.TRUE., silent=(.NOT. is_grib_output()))
    CALL uuid_parse(uuid_string, patch%grid_uuid)
    WRITE(message_text,'(a,a)') 'grid uuid: ', TRIM(uuid_string)
    CALL message  (TRIM(method_name), message_text)
    
    CALL nf(nf_get_att_int(ncid, nf_global, 'grid_root', icheck))
    IF (icheck /= nroot) THEN
      WRITE(message_text,'(a,i4,a,i4)') &
        & 'grid_root attribute:', icheck,', R:',nroot
      CALL message  (TRIM(method_name), TRIM(message_text))
      WRITE(message_text,'(a)') &
        & 'Mismatch between "grid_root" attribute and "R" parameter in the filename'
      CALL finish  (TRIM(method_name), TRIM(message_text))
    END IF
    
    CALL nf(nf_get_att_int(ncid, nf_global, 'grid_level', igrid_level))
    IF (igrid_level /= ilev) THEN
      WRITE(message_text,'(a,i4,a,i4)') &
        & 'grid_level attribute:', igrid_level,', B:',ilev
      CALL message  (TRIM(method_name), TRIM(message_text))
      WRITE(message_text,'(a)') &
        & 'Mismatch between "grid_level" attribute and "B" parameter in the filename'
      CALL finish  (TRIM(method_name), TRIM(message_text))
    END IF
    
    ! Check additional attributes for consistency with the current namelist settings
    CALL nf(nf_get_att_int(ncid, nf_global, 'grid_ID', igrid_id))
    IF ((.NOT.l_limited_area).AND.(igrid_id /= ig)) THEN
      WRITE(message_text,'(a,i4,a,i4)') &
        & 'grid ID attribute:', igrid_id,', namelist value:',ig
      CALL message  (TRIM(method_name), TRIM(message_text))
      WRITE(message_text,'(a)') &
        & 'Mismatch between "grid ID" attribute and corresponding namelist setting'
      CALL finish  (TRIM(method_name), TRIM(message_text))
    END IF
    
    CALL nf(nf_get_att_int(ncid, nf_global, 'parent_grid_ID', iparent_id))
    IF ((.NOT.l_limited_area).AND.(iparent_id /= ipar_id)) THEN
      WRITE(message_text,'(a,i4,a,i4)') &
        & 'parent ID attribute:', iparent_id,', namelist value:',ipar_id
      CALL message  (TRIM(method_name), TRIM(message_text))
      WRITE(message_text,'(a)') &
        & 'Mismatch between "parent grid ID" attribute and corresponding namelist setting'
      CALL finish  (TRIM(method_name), TRIM(message_text))
    END IF
    
    CALL nf(nf_get_att_int(ncid, nf_global, 'max_childdom', i_max_childdom))
    IF (i_max_childdom /= max_childdom) THEN
      WRITE(message_text,'(a,i4,a,i4)') &
        & 'max_childdom attribute:', i_max_childdom,', namelist value:',max_childdom
      CALL message  (TRIM(method_name), TRIM(message_text))
      WRITE(message_text,'(a)') &
        & 'Mismatch between "max_childdom" attribute and corresponding namelist setting'
      CALL finish  (TRIM(method_name), TRIM(message_text))
    END IF
    
     
    !--------------------------------------
    ! get number of cells, edges and vertices
    CALL nf(nf_inq_dimid(ncid, 'edge', dimid))
    CALL nf(nf_inq_dimlen(ncid, dimid, patch%n_patch_edges))
    CALL nf(nf_inq_dimid(ncid, 'cell', dimid))
    CALL nf(nf_inq_dimlen(ncid, dimid, patch%n_patch_cells))
    CALL nf(nf_inq_dimid(ncid, 'vertex', dimid))
    CALL nf(nf_inq_dimlen(ncid, dimid, patch%n_patch_verts))
    CALL nf(nf_inq_dimid(ncid, 'nv', dimid))
    CALL nf(nf_inq_dimlen(ncid, dimid, max_cell_connectivity))
    CALL nf(nf_inq_dimid(ncid, 'ne', dimid))
    CALL nf(nf_inq_dimlen(ncid, dimid, max_verts_connectivity))

    !
    ! calculate and save values for the blocking
    !
    ! ... for the cells
    patch%nblks_c       = ( patch%n_patch_cells + n_e_halo_cells - 1 )  &
      & / nproma + 1
    patch%nblks_int_c   = ( patch%n_patch_cells - 1 ) / nproma + 1
    patch%npromz_int_c  = patch%n_patch_cells  &
      & - (patch%nblks_int_c - 1)*nproma
    ! total number of cells
    patch%n_patch_cells = patch%n_patch_cells + n_e_halo_cells
    patch%npromz_c      = patch%n_patch_cells - (patch%nblks_c - 1)*nproma
    
    ! ... for the edges
    patch%nblks_e       = ( patch%n_patch_edges + n_e_halo_edges - 1 )  &
      & / nproma + 1
    patch%nblks_int_e   = ( patch%n_patch_edges - 1 ) / nproma + 1
    patch%npromz_int_e  = patch%n_patch_edges  &
      & - (patch%nblks_int_e - 1)*nproma
    ! total number of edges
    patch%n_patch_edges = patch%n_patch_edges + n_e_halo_edges
    patch%npromz_e      = patch%n_patch_edges - (patch%nblks_e - 1)*nproma
    
    ! ... for the vertices
    patch%nblks_v       = ( patch%n_patch_verts + n_e_halo_verts - 1 )  &
      & / nproma + 1
    patch%nblks_int_v   = ( patch%n_patch_verts - 1 ) / nproma + 1
    patch%npromz_int_v  = patch%n_patch_verts  &
      & - (patch%nblks_int_v - 1)*nproma
    ! total number of vertices
    patch%n_patch_verts = patch%n_patch_verts + n_e_halo_verts
    patch%npromz_v      = patch%n_patch_verts - (patch%nblks_v - 1)*nproma
    
    !
    ! allocate temporary arrays to read in data form the grid/patch generator
    !
    ! integer arrays
    ALLOCATE( array_c_int(patch%n_patch_cells,6),  &
      & array_e_int(patch%n_patch_edges,6),  &
      & array_v_int(patch%n_patch_verts,6),  &
      & stat=ist )
    IF (ist /= success) THEN
      CALL finish (TRIM(method_name), 'allocation for array_[cev]_int failed')
    ENDIF
    ! real arrays
    ALLOCATE( array_c_real(patch%n_patch_cells,6),  &
      & array_e_real(patch%n_patch_edges,6),  &
      & array_v_real(patch%n_patch_verts,6),  &
      & stat=ist )
    IF (ist /= success) THEN
      CALL finish (TRIM(method_name), 'allocation for array_[cev]_real failed')
    ENDIF
    ! integer arrays for index lists
    ALLOCATE( start_idx_c(min_rlcell:max_rlcell,max_childdom),  &
      & end_idx_c  (min_rlcell:max_rlcell,max_childdom),  &
      & start_idx_e(min_rledge:max_rledge,max_childdom),  &
      & end_idx_e  (min_rledge:max_rledge,max_childdom),  &
      & start_idx_v(min_rlvert:max_rlvert,max_childdom),  &
      & end_idx_v  (min_rlvert:max_rlvert,max_childdom),  &
      & stat=ist )
    
    IF (ist /= success) THEN
      CALL finish (TRIM(method_name), 'allocation for array_[cev]_indlist failed')
    ENDIF
    
    ! Number of global cells/edges/verts
    ! These are needed for patch allocation
    ! For a non-divided patch they are identical to the non-global values
    
    patch%n_patch_cells_g = patch%n_patch_cells
    patch%n_patch_edges_g = patch%n_patch_edges
    patch%n_patch_verts_g = patch%n_patch_verts
    
    !
    ! Allocate patch arrays which are read here
    !
    CALL allocate_basic_patch( patch )
    
    ! patch%cells%start_idx(:,:)
    ! patch%cells%start_blk(:,:)
    ! patch%cells%end_idx(:,:)
    ! patch%cells%end_blk(:,:)
    ! nesting does not work for hex grids
    CALL nf(nf_inq_varid(ncid, 'start_idx_c', varid))
    CALL nf(nf_get_var_int(ncid, varid, start_idx_c(:,:)))
    CALL reshape_idx_list( start_idx_c,                                &
      & patch%cells%start_idx, patch%cells%start_blk )
    CALL nf(nf_inq_varid(ncid, 'end_idx_c', varid))
    CALL nf(nf_get_var_int(ncid, varid, end_idx_c(:,:)))
    CALL reshape_idx_list( end_idx_c,                                &
        & patch%cells%end_idx, patch%cells%end_blk )
    
    ! patch%edges%start_idx(:,:)
    ! patch%edges%start_blk(:,:)
    ! patch%edges%end_idx(:,:)
    ! patch%edges%end_blk(:,:)
    CALL nf(nf_inq_varid(ncid, 'start_idx_e', varid))
    CALL nf(nf_get_var_int(ncid, varid, start_idx_e(:,:)))
    CALL reshape_idx_list( start_idx_e,                                &
      & patch%edges%start_idx, patch%edges%start_blk )
    CALL nf(nf_inq_varid(ncid, 'end_idx_e', varid))
    CALL nf(nf_get_var_int(ncid, varid, end_idx_e(:,:)))
    CALL reshape_idx_list( end_idx_e,                                &
      & patch%edges%end_idx, patch%edges%end_blk )
    
    ! patch%verts%start_idx(:,:)
    ! patch%verts%start_blk(:,:)
    ! patch%verts%end_idx(:,:)
    ! patch%verts%end_blk(:,:)
    CALL nf(nf_inq_varid(ncid, 'start_idx_v', varid))
    CALL nf(nf_get_var_int(ncid, varid, start_idx_v(:,:)))
    CALL reshape_idx_list( start_idx_v,                                &
      & patch%verts%start_idx, patch%verts%start_blk )
    CALL nf(nf_inq_varid(ncid, 'end_idx_v', varid))
    CALL nf(nf_get_var_int(ncid, varid, end_idx_v(:,:)))
    CALL reshape_idx_list( end_idx_v,                                &
      & patch%verts%end_idx, patch%verts%end_blk )

    
    ! patch%cells%phys_id(:,:)
    CALL nf(nf_inq_varid(ncid, 'phys_cell_id', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_c_int(:,1)))
    CALL reshape_int( array_c_int(:,1), patch%nblks_c, patch%npromz_c,  &
      & patch%cells%phys_id(:,:) )

    ! patch%cells%neighbor_idx(:,:,:)
    ! patch%cells%neighbor_blk(:,:,:)
    CALL nf(nf_inq_varid(ncid, 'neighbor_cell_index', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_c_int(:,1:max_cell_connectivity)))
    DO ji = 1, max_cell_connectivity
      CALL reshape_idx( array_c_int(:,ji), patch%nblks_c, patch%npromz_c,  &
        & patch%cells%neighbor_idx(:,:,ji),  &
        & patch%cells%neighbor_blk(:,:,ji) )
    END DO
    
    ! patch%cells%edge_idx(:,:,:)
    ! patch%cells%edge_blk(:,:,:)
    CALL nf(nf_inq_varid(ncid, 'edge_of_cell', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_c_int(:,1:max_cell_connectivity)))
    DO ji = 1, max_cell_connectivity
      CALL reshape_idx( array_c_int(:,ji), patch%nblks_c, patch%npromz_c,  &
        & patch%cells%edge_idx(:,:,ji),  &
        & patch%cells%edge_blk(:,:,ji) )
    END DO
    
    ! patch%cells%vertex_idx(:,:,:)
    ! patch%cells%vertex_blk(:,:,:)
    CALL nf(nf_inq_varid(ncid, 'vertex_of_cell', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_c_int(:,1:max_cell_connectivity)))
    DO ji = 1, max_cell_connectivity
      CALL reshape_idx( array_c_int(:,ji), patch%nblks_c, patch%npromz_c,  &
        & patch%cells%vertex_idx(:,:,ji),  &
        & patch%cells%vertex_blk(:,:,ji) )
    END DO
    
    ! patch%cells%center(:,:)%lon
    CALL nf(nf_inq_varid(ncid, 'lon_cell_centre', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_c_real(:,1)))
    CALL reshape_real( array_c_real(:,1), patch%nblks_c, patch%npromz_c,  &
       & patch%cells%center(:,:)%lon )
    
    ! patch%cells%center(:,:)%lat
    CALL nf(nf_inq_varid(ncid, 'lat_cell_centre', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_c_real(:,1)))
    CALL reshape_real( array_c_real(:,1), patch%nblks_c, patch%npromz_c,  &
      & patch%cells%center(:,:)%lat )
    
    ! patch%verts%vertex(:,:)%lon
    CALL nf(nf_inq_varid(ncid, 'longitude_vertices', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_v_real(:,1)))
    CALL reshape_real( array_v_real(:,1), patch%nblks_v, patch%npromz_v,  &
      & patch%verts%vertex(:,:)%lon )
    
    ! patch%verts%vertex(:,:)%lat
    CALL nf(nf_inq_varid(ncid, 'latitude_vertices', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_v_real(:,1)))
    CALL reshape_real( array_v_real(:,1), patch%nblks_v, patch%npromz_v,  &
      & patch%verts%vertex(:,:)%lat )
    
    !------------------------------------------
    ! nesting/lateral boundary indexes
    IF (global_cell_type == 3) THEN ! triangular grid
    
      CALL nf(nf_inq_varid(ncid, 'parent_cell_index', varid))
      ! patch%cells%parent_idx(:,:)
      ! patch%cells%parent_blk(:,:)
      CALL nf(nf_get_var_int(ncid, varid, array_c_int(:,1)))
      CALL reshape_idx( array_c_int(:,1), patch%nblks_c, patch%npromz_c,  &
        & patch%cells%parent_idx(:,:),  &
        & patch%cells%parent_blk(:,:) )
      ! patch%cells%child_idx(:,:,:)
      ! patch%cells%child_blk(:,:,:)
      CALL nf(nf_inq_varid(ncid, 'child_cell_index', varid))
      CALL nf(nf_get_var_int(ncid, varid, array_c_int(:,1:4)))
      DO ji = 1, 4
        CALL reshape_idx( array_c_int(:,ji), patch%nblks_c, patch%npromz_c,  &
          & patch%cells%child_idx(:,:,ji),  &
          & patch%cells%child_blk(:,:,ji) )
      END DO    
      ! patch%cells%child_id(:,:)
      CALL nf(nf_inq_varid(ncid, 'child_cell_id', varid))
      CALL nf(nf_get_var_int(ncid, varid, array_c_int(:,1)))
      
      ! Preparation: In limited-area mode, check if child domain ID's read
      ! from the grid files need to be shifted
      IF (ig == 1 .AND. l_limited_area .AND. patch%n_childdom>0) THEN
        ! domain ID of first nested domain should be 2
        ishift_child_id = array_c_int(start_idx_c(grf_bdyintp_start_c,1),1) - 2
      ENDIF
      
      IF(ishift_child_id /= 0 .AND. patch%n_childdom>0) THEN
        DO jc = start_idx_c(grf_bdyintp_start_c,1), end_idx_c(min_rlcell,patch%n_childdom)
          array_c_int(jc,1) = array_c_int(jc,1) - ishift_child_id
        ENDDO
      ENDIF
      
      CALL reshape_int( array_c_int(:,1), patch%nblks_c, patch%npromz_c,  &
        & patch%cells%child_id(:,:) )
        
    ELSEIF (global_cell_type == 6) THEN ! hexagonal grid
      CALL message ('read_patch',&
        & 'nesting incompatible with hexagonal grid')
    ENDIF
    
    ! patch%cells%refin_ctrl(:,:)
    CALL nf(nf_inq_varid(ncid, 'refin_c_ctrl', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_c_int(:,1)))
    CALL reshape_int( array_c_int(:,1), patch%nblks_c, patch%npromz_c,  &
      & patch%cells%refin_ctrl(:,:) )
    
    ! patch%edges%parent_idx(:,:)
    ! patch%edges%parent_blk(:,:)
    CALL nf(nf_inq_varid(ncid, 'parent_edge_index', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_e_int(:,1)))
    CALL reshape_idx( array_e_int(:,1), patch%nblks_e, patch%npromz_e,  &
      & patch%edges%parent_idx(:,:),  &
      & patch%edges%parent_blk(:,:) )
    
    ! patch%edges%child_idx(:,:,:)
    ! patch%edges%child_blk(:,:,:)
    CALL nf(nf_inq_varid(ncid, 'child_edge_index', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_e_int(:,1:4)))
    
    ! First ensure that child edge indices are all positive;
    ! if there are negative values, grid files are too old    
    IF(ANY(array_e_int(:,1:4)<0)) THEN
      CALL finish (TRIM(method_name), &
        & 'negative child edge indices detected - patch files are too old')
    ENDIF
    
    DO ji = 1, 4
      CALL reshape_idx( array_e_int(:,ji), patch%nblks_e, patch%npromz_e,  &
        & patch%edges%child_idx(:,:,ji),  &
        & patch%edges%child_blk(:,:,ji) )
    END DO
    
    ! patch%edges%child_id(:,:)
    CALL nf(nf_inq_varid(ncid, 'child_edge_id', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_e_int(:,1)))
    
    IF(ishift_child_id /= 0 .AND. patch%n_childdom>0) THEN
      DO je = start_idx_e(grf_bdyintp_start_e,1), end_idx_e(min_rledge,patch%n_childdom)
        array_e_int(je,1) = array_e_int(je,1) - ishift_child_id
      ENDDO
    ENDIF
    
    CALL reshape_int( array_e_int(:,1), patch%nblks_e, patch%npromz_e,  &
      & patch%edges%child_id(:,:) )
        
    ! patch%edges%refin_ctrl(:,:)
    CALL nf(nf_inq_varid(ncid, 'refin_e_ctrl', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_e_int(:,1)))
    CALL reshape_int( array_e_int(:,1), patch%nblks_e, patch%npromz_e,  &
      & patch%edges%refin_ctrl(:,:) )
    
    ! patch%verts%refin_ctrl(:,:)
    CALL nf(nf_inq_varid(ncid, 'refin_v_ctrl', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_v_int(:,1)))
    CALL reshape_int( array_v_int(:,1), patch%nblks_v, patch%npromz_v,  &
      & patch%verts%refin_ctrl(:,:) )
    
    CALL nf(nf_close(ncid))
    
    
    !
    ! deallocate temporary arrays to read in data form the grid/patch generator
    !
    ! integer arrays
    DEALLOCATE( array_c_int, array_e_int, array_v_int,  &
      & stat=ist )
    IF (ist /= success) THEN
      CALL finish (TRIM(method_name), 'deallocation for array_[cev]_int failed')
    ENDIF
    ! real arrays
    DEALLOCATE( array_c_real, array_e_real, array_v_real,  &
      & stat=ist )
    IF (ist /= success) THEN
      CALL finish (TRIM(method_name), 'deallocation for array_[cev]_real failed')
    ENDIF
    ! index lists arrays
    DEALLOCATE( start_idx_c, end_idx_c, start_idx_e, end_idx_e, start_idx_v, end_idx_v, &
      & stat=ist )
    IF (ist /= success) THEN
      CALL finish (TRIM(method_name), 'deallocation for array_[cev]_indlist failed')
    ENDIF

    !----------------------------------------------------------------------------------
    ! compute cells%num_edges
    ! works for general unstructured grid
    DO ibc = 1, patch%nblks_c
      block_size = nproma
      IF (ibc == patch%nblks_c) block_size = patch%npromz_c
      DO ilc=1, block_size

        patch%cells%num_edges(ilc,ibc) = 0
        DO ji = 1, max_cell_connectivity
          IF ( patch%cells%edge_idx(ilc,ibc,ji) > 0 ) &
            & patch%cells%num_edges(ilc,ibc) = patch%cells%num_edges(ilc,ibc) + 1
        END DO

      END DO
    END DO
    
    !----------------------------------------------------------------------------------
    ! account for pentagons in the hex model
    IF (global_cell_type == 6) THEN ! hexagonal grid
      DO ibc = 1, patch%nblks_c
        block_size = nproma
        IF (ibc == patch%nblks_c) block_size = patch%npromz_c
        DO ilc=1, block_size
        
          DO ji = 1, 6
          
            ! account for dummy cells arising in case of a pentagon
            IF ( patch%cells%neighbor_idx(ilc,ibc,ji) == 0 ) THEN
              IF ( ji /= 6 ) THEN
                patch%cells%neighbor_idx(ilc,ibc,ji) =  &
                  & patch%cells%neighbor_idx(ilc,ibc,6)
                patch%cells%neighbor_blk(ilc,ibc,ji) =  &
                  & patch%cells%neighbor_blk(ilc,ibc,6)
                ! this should not happen
  !               CALL finish(method_name, "cells%neighbor_idx=0 not at the end")
              END IF
              ! Fill dummy neighbor with an existing index to simplify do loops
              ! Note, however, that related multiplication factors must be zero
              patch%cells%neighbor_idx(ilc,ibc,6) = patch%cells%neighbor_idx(ilc,ibc,5)
              patch%cells%neighbor_blk(ilc,ibc,6) = patch%cells%neighbor_blk(ilc,ibc,5)
            END IF

            ! account for dummy verts arising in case of a pentagon
            IF ( patch%cells%vertex_idx(ilc,ibc,ji) == 0 ) THEN
              IF ( ji /= 6 ) THEN
                patch%cells%vertex_idx(ilc,ibc,ji) =  &
                  & patch%cells%vertex_idx(ilc,ibc,6)
                patch%cells%vertex_blk(ilc,ibc,ji) =  &
                  & patch%cells%vertex_blk(ilc,ibc,6)
              END IF
              ! Fill dummy edge with existing index to simplify do loops
              ! Note, however, that related multiplication factors must be zero
              patch%cells%vertex_idx(ilc,ibc,6) = patch%cells%vertex_idx(ilc,ibc,5)
              patch%cells%vertex_blk(ilc,ibc,6) = patch%cells%vertex_blk(ilc,ibc,5)
            END IF
            
            ! account for dummy edges arising in case of a pentagon
            IF ( patch%cells%edge_idx(ilc,ibc,ji) == 0 ) THEN
              IF ( ji /= 6 ) THEN
                patch%cells%edge_idx(ilc,ibc,ji) =  &
                  & patch%cells%edge_idx(ilc,ibc,6)
                patch%cells%edge_blk(ilc,ibc,ji) =  &
                  & patch%cells%edge_blk(ilc,ibc,6)
              END IF
              ! Fill dummy edge with existing index to simplify do loops
              ! Note, however, that related multiplication factors must be zero
              patch%cells%edge_idx(ilc,ibc,6) = patch%cells%edge_idx(ilc,ibc,5)
              patch%cells%edge_blk(ilc,ibc,6) = patch%cells%edge_blk(ilc,ibc,5)
            END IF
          
          END DO  ! ji = 1, 6
          
        END DO  ! ilc=1, block_size
      END DO ! blocks
    ENDIF  ! global_cell_type == 6
        
        
      
    !
    ! Set values which are needed for parallel runs
    ! to the correct values for a single patch owner
    !
    patch%comm   = p_comm_work
    patch%rank   = 0
    patch%n_proc = 1
    patch%proc0  = 0
    
    CALL message (TRIM(method_name), 'read_patches finished')
    
  END SUBROUTINE read_basic_patch
  !-------------------------------------------------------------------------
   
    
  !-------------------------------------------------------------------------
  !> Reads the remaining patch information into the divided patch
  SUBROUTINE read_remaining_patch( ig, patch, n_lp, id_lp )
    
    INTEGER,       INTENT(in)    ::  ig       ! domain ID
    TYPE(t_patch), INTENT(inout), TARGET ::  patch  ! patch data structure
    INTEGER,       INTENT(in)    ::  n_lp     ! Number of local parents on the same level
    INTEGER,       INTENT(in)    ::  id_lp(:) ! IDs of local parents on the same level
    
    INTEGER, POINTER :: &
      & array_c_int(:,:),  &  ! temporary arrays to read in integer values
      & array_e_int(:,:),  &
      & array_v_int(:,:)
    
    REAL(wp), POINTER :: &
      & array_c_real(:,:), &  ! temporary arrays to read in real values
      & array_e_real(:,:), &
      & array_v_real(:,:)
    
    ! status variable
    INTEGER :: ist
    
    INTEGER :: ncid, dimid, varid
    INTEGER :: ip, ji, jv
    INTEGER :: max_cell_connectivity, max_verts_connectivity

    INTEGER :: return_status
    
    TYPE(t_patch), POINTER :: p_p, patch0
    
    CHARACTER(LEN=*), PARAMETER :: method_name = 'mo_model_domimp_patches/read_remaining_patch'
    !-----------------------------------------------------------------------
    
    CALL message ('mo_model_domimp_patches:read_remaining_patch', &
      & 'Read gridmap file '//TRIM(patch%grid_filename))
    
    CALL nf(nf_open(TRIM(patch%grid_filename), nf_nowrite, ncid))
    
            
    !-------------------------------------------------
    !
    ! allocate temporary arrays to read in data from the grid/patch generator
    !
    ! integer arrays
    ALLOCATE( array_c_int(patch%n_patch_cells_g,6),  &
      & array_e_int(patch%n_patch_edges_g,6),  &
      & array_v_int(patch%n_patch_verts_g,6),  &
      & stat=ist )
    IF (ist /= success) THEN
      CALL finish ('mo_model_domain_import:read_patch',  &
        & 'allocation for array_[cev]_int failed')
    ENDIF
    ! real arrays
    ALLOCATE( array_c_real(patch%n_patch_cells_g,6),  &
      & array_e_real(patch%n_patch_edges_g,6),  &
      & array_v_real(patch%n_patch_verts_g,6),  &
      & stat=ist )
    IF (ist /= success) THEN
      CALL finish ('mo_model_domain_import:read_patch',  &
        & 'allocation for array_[cev]_real failed')
    ENDIF
        
    !--------------------------------------------------
    CALL nf(nf_inq_dimid(ncid, 'nv', dimid))
    CALL nf(nf_inq_dimlen(ncid, dimid, max_cell_connectivity))
    CALL nf(nf_inq_dimid(ncid, 'ne', dimid))
    CALL nf(nf_inq_dimlen(ncid, dimid, max_verts_connectivity))
    !--------------------------------------------------

    
    CALL nf(nf_inq_varid(ncid, 'phys_cell_id', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_c_int(:,1)))
    ! 'phys_cell_id' seems not to be set for patch 0 and 1, it is always ig in this case
    IF(ig<=1) array_c_int(:,1) = ig
    ! shift physical IDs for limited-area mode
    IF (ig > 1 .AND. ishift_child_id > 0) array_c_int(:,1) = array_c_int(:,1) - ishift_child_id
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_int( array_c_int(:,1), p_p%n_patch_cells, p_p%cells%glb_index,  &
        & p_p%cells%phys_id(:,:) )
    ENDDO
    
    ! p_p%cells%edge_orientation(:,:,:)
    CALL nf(nf_inq_varid(ncid, 'orientation_of_normal', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_c_int(:,1:max_cell_connectivity)))
    DO ji = 1, max_cell_connectivity
      DO ip = 0, n_lp
        p_p => get_patch_ptr(patch, id_lp, ip)
        CALL divide_real( REAL(array_c_int(:,ji),wp),            &
          & p_p%n_patch_cells, p_p%cells%glb_index,     &
          & p_p%cells%edge_orientation(:,:,ji) )
      ENDDO
    END DO
    
    ! p_p%cells%area(:,:)
    CALL nf(nf_inq_varid(ncid, 'cell_area_p', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_c_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_c_real(:,1), p_p%n_patch_cells, p_p%cells%glb_index, &
        & p_p%cells%area(:,:) )
    ENDDO
    
    ! p_p%edges%phys_id(:,:)
    CALL nf(nf_inq_varid(ncid, 'phys_edge_id', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_e_int(:,1)))
    ! 'phys_edge_id' seems not to be set for patch 0 and 1, it is always ig in this case
    IF(ig<=1) array_e_int(:,1) = ig
    ! shift physical IDs for limited-area mode
    IF (ig > 1 .AND. ishift_child_id > 0) array_e_int(:,1) = array_e_int(:,1) - ishift_child_id
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_int( array_e_int(:,1), p_p%n_patch_edges, p_p%edges%glb_index,  &
        & p_p%edges%phys_id(:,:) )
    ENDDO
    
    ! p_p%edges%cell_idx(:,:,:)
    ! p_p%edges%cell_blk(:,:,:)
    CALL nf(nf_inq_varid(ncid, 'adjacent_cell_of_edge', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_e_int(:,1:2)))
    DO ji = 1, 2
      DO ip = 0, n_lp
        p_p => get_patch_ptr(patch, id_lp, ip)
        CALL divide_idx( array_e_int(:,ji), p_p%n_patch_edges, p_p%edges%glb_index,  &
          & p_p%cells%loc_index,         &
          & p_p%edges%cell_idx(:,:,ji),  &
          & p_p%edges%cell_blk(:,:,ji) )
      END DO
    END DO
    
    ! p_p%edges%vertex_idx(:,:,:)
    ! p_p%edges%vertex_blk(:,:,:)
    CALL nf(nf_inq_varid(ncid, 'edge_vertices', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_e_int(:,1:2)))
    DO ji = 1, 2
      DO ip = 0, n_lp
        p_p => get_patch_ptr(patch, id_lp, ip)
        CALL divide_idx( array_e_int(:,ji), p_p%n_patch_edges, p_p%edges%glb_index,  &
          & p_p%verts%loc_index,         &
          & p_p%edges%vertex_idx(:,:,ji),  &
          & p_p%edges%vertex_blk(:,:,ji) )
      END DO
    END DO
    
    ! p_p%edges%system_orientation(:,:)
    CALL nf(nf_inq_varid(ncid, 'edge_system_orientation', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_e_int(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( REAL(array_e_int(:,1),wp),            &
        & p_p%n_patch_edges, p_p%edges%glb_index,    &
        & p_p%edges%system_orientation(:,:) )
    ENDDO
    
    ! p_p%edges%center(:,:)%lon
    CALL nf(nf_inq_varid(ncid, 'lon_edge_centre', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index,  &
        & p_p%edges%center(:,:)%lon )
    ENDDO
    
    ! p_p%edges%center(:,:)%lat
    CALL nf(nf_inq_varid(ncid, 'lat_edge_centre', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index,  &
        & p_p%edges%center(:,:)%lat )
    ENDDO
    
    ! p_p%edges%primal_normal(:,:)%v1
    CALL nf(nf_inq_varid(ncid, 'zonal_normal_primal_edge', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index,  &
        & p_p%edges%primal_normal(:,:)%v1 )
    ENDDO
    
    ! p_p%edges%primal_normal(:,:)%v2
    CALL nf(nf_inq_varid(ncid, 'meridional_normal_primal_edge', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index,  &
        & p_p%edges%primal_normal(:,:)%v2 )
    ENDDO
    
    ! p_p%edges%dual_normal(:,:)%v1
    CALL nf(nf_inq_varid(ncid, 'zonal_normal_dual_edge', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index,  &
        & p_p%edges%dual_normal(:,:)%v1 )
    ENDDO
    
    ! p_p%edges%dual_normal(:,:)%v2
    CALL nf(nf_inq_varid(ncid, 'meridional_normal_dual_edge', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index,  &
        & p_p%edges%dual_normal(:,:)%v2 )
    ENDDO
    
    ! p_p%edges%primal_edge_length(:,:)
    CALL nf(nf_inq_varid(ncid, 'edge_length', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index,  &
        & p_p%edges%primal_edge_length(:,:) )
    ENDDO
    
    ! p_p%edges%dual_edge_length(:,:)
    CALL nf(nf_inq_varid(ncid, 'dual_edge_length', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index,  &
        & p_p%edges%dual_edge_length(:,:) )
    ENDDO
    
    ! p_p%edges%edge_vert_length(:,:)
    CALL nf(nf_inq_varid(ncid, 'edge_vert_distance', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1:2)))
    DO ji = 1, 2
      DO ip = 0, n_lp
        p_p => get_patch_ptr(patch, id_lp, ip)
        CALL divide_real( array_e_real(:,ji), p_p%n_patch_edges, p_p%edges%glb_index, &
          & p_p%edges%edge_vert_length(:,:,ji) )
      ENDDO
    ENDDO
    
    ! p_p%edges%edge_cell_length(:,:)
    CALL nf(nf_inq_varid(ncid, 'edge_cell_distance', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1:2)))
    DO ji = 1, 2
      DO ip = 0, n_lp
        p_p => get_patch_ptr(patch, id_lp, ip)
        CALL divide_real( array_e_real(:,ji), p_p%n_patch_edges, p_p%edges%glb_index, &
          & p_p%edges%edge_cell_length(:,:,ji) )
      ENDDO
    ENDDO
    
    ! p_p%verts%neighbor_idx(:,:,:)
    ! p_p%verts%neighbor_blk(:,:,:)
    CALL nf(nf_inq_varid(ncid, 'vertices_of_vertex', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_v_int(:,1:max_verts_connectivity)))
    DO ji = 1, max_verts_connectivity
      DO ip = 0, n_lp
        p_p => get_patch_ptr(patch, id_lp, ip)
        CALL divide_idx( array_v_int(:,ji), p_p%n_patch_verts, p_p%verts%glb_index,  &
          & p_p%verts%loc_index,             &
          & p_p%verts%neighbor_idx(:,:,ji),  &
          & p_p%verts%neighbor_blk(:,:,ji) )
      END DO
    END DO
    
    ! p_p%verts%cell_idx(:,:,:)
    ! p_p%verts%cell_blk(:,:,:)
    CALL nf(nf_inq_varid(ncid, 'cells_of_vertex', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_v_int(:,1:max_verts_connectivity)))
    !
    ! account for dummy cells arising in case of a pentagon
    ! Fill dummy cell with existing index to simplify do loops
    ! Note, however, that related multiplication factors must be zero
!     IF (global_cell_type == 3) &
      CALL move_dummies_to_end(array_v_int, max_verts_connectivity, .TRUE.)
    !
    DO ji = 1, max_verts_connectivity
      DO ip = 0, n_lp
        p_p => get_patch_ptr(patch, id_lp, ip)
        CALL divide_idx( array_v_int(:,ji), p_p%n_patch_verts, p_p%verts%glb_index,  &
          & p_p%cells%loc_index,         &
          & p_p%verts%cell_idx(:,:,ji),  &
          & p_p%verts%cell_blk(:,:,ji) )
      END DO
    END DO
    
    ! p_p%verts%edge_idx(:,:,:)
    ! p_p%verts%edge_blk(:,:,:)
    CALL nf(nf_inq_varid(ncid, 'edges_of_vertex', varid))    
    CALL nf(nf_get_var_int(ncid, varid, array_v_int(:,1:max_verts_connectivity)))
    !
    ! Set verts%num_edges (in array_v_real(:,1))
    DO jv = 1, p_p%n_patch_verts_g
      array_v_real(jv,1) = 0.0
      DO ji=1, max_verts_connectivity
        IF (array_v_int(jv,ji) /= 0) &
          array_v_real(jv,1) = array_v_real(jv,1) + 1.0_wp
      END DO
    END DO

    ! account for dummy cells arising in case of a pentagon
    ! Fill dummy cell with existing index to simplify do loops
    ! Note, however, that related multiplication factors must be zero   
!     IF (global_cell_type == 3) &
      CALL move_dummies_to_end(array_v_int, max_verts_connectivity, .TRUE.)
    !
    DO ji = 1, max_verts_connectivity
      DO ip = 0, n_lp
        p_p => get_patch_ptr(patch, id_lp, ip)
        CALL divide_idx( array_v_int(:,ji), p_p%n_patch_verts, p_p%verts%glb_index,  &
          & p_p%edges%loc_index,         &
          & p_p%verts%edge_idx(:,:,ji),  &
          & p_p%verts%edge_blk(:,:,ji) )
      END DO
    END DO

    array_v_int(:,1) = INT(array_v_real(:,1))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_int( array_v_int(:,1), p_p%n_patch_verts, p_p%verts%glb_index,  &
        & p_p%verts%num_edges(:,:) )
    ENDDO
              
    ! p_p%verts%edge_orientation(:,:,:)
    CALL nf(nf_inq_varid(ncid, 'edge_orientation', varid))
    CALL nf(nf_get_var_int(ncid, varid, array_v_int(:,1:max_verts_connectivity)))
    ! move dummy edges to end and set edge orientation to zero
    CALL move_dummies_to_end(array_v_int, max_verts_connectivity, .FALSE.)
    DO ji = 1, max_verts_connectivity
      DO ip = 0, n_lp
        p_p => get_patch_ptr(patch, id_lp, ip)
        CALL divide_real( REAL(array_v_int(:,ji),wp),            &
          & p_p%n_patch_verts, p_p%verts%glb_index,     &
          & p_p%verts%edge_orientation(:,:,ji) )
      END DO
    END DO
    
    ! p_p%verts%dual_area(:,:)
    CALL nf(nf_inq_varid(ncid, 'dual_area_p', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_v_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_v_real(:,1), p_p%n_patch_verts, p_p%verts%glb_index, &
        & p_p%verts%dual_area(:,:) )
    ENDDO
    
    !-------------------------------------------------
    ! read geometry parameters
    patch0 => get_patch_ptr(patch, id_lp, 0)
    return_status = parallel_read_geometry_info(ncid, patch0%geometry_info)
    IF (return_status /= 0 ) THEN
      ! the information was missing from the file (ie old grids)
      ! calclulate basic settings
!       CALL finish("","did not read from file")
      CALL set_grid_mean_geometry_info(patch0)
    ENDIF
    CALL set_grid_geometry_derived_info(patch0%geometry_info)
        
    DO ip = 1, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL copy_grid_geometry_info(from_geometry_info = patch0%geometry_info, &
        &                            to_geometry_info = p_p%geometry_info)
!       write(0,*) "-------------------------------------------------------"
!       write(0,*) "area, char_lenght=", p_p%geometry_info%mean_cell_area, &
!         & p_p%geometry_info%mean_characteristic_length
!       write(0,*) "-------------------------------------------------------"
    ENDDO
    !---------------------------------------------------
    ! read cartesian positions
    return_status = read_cartesian_positions(ncid, ig, patch, n_lp, id_lp, &
      & array_c_real, array_e_real, array_v_real)
    IF (return_status /= 0) & ! this is an old grid
      CALL calculate_cartesian_positions(ig, patch, n_lp, id_lp)
    !-------------------------------------------------
    
                       
    CALL nf(nf_close(ncid))
    !-------------------------------------------------
     !Check for plane_torus case
    IF(p_p%geometry_info%geometry_type == planar_torus_geometry .AND. .NOT. is_plane_torus) THEN
      CALL message(TRIM(method_name), &
        & "Grid is plane torus: turning on is_plane_torus automatically")    
      is_plane_torus = .TRUE. 
    END IF

    IF(p_p%geometry_info%geometry_type /= planar_torus_geometry .AND. is_plane_torus) &
      CALL finish(TRIM(method_name),"Input grid is NOT plane torus, Stopping")
    !-------------------------------------------------
        
        
    !
    ! deallocate temporary arrays to read in data from the grid/patch generator
    !
    ! integer arrays
    DEALLOCATE( array_c_int, array_e_int, array_v_int,  &
      & stat=ist )
    IF (ist /= success) THEN
      CALL finish ('mo_model_domain_import:read_remaining_patch',  &
        & 'deallocation for array_[cev]_int failed')
    ENDIF
    ! real arrays
    DEALLOCATE( array_c_real, array_e_real, array_v_real,  &
      & stat=ist )
    IF (ist /= success) THEN
      CALL finish ('mo_model_domain_import:read_remaining_patch',  &
        & 'deallocation for array_[cev]_real failed')
    ENDIF

    CALL message ('mo_model_domimp_patches:read_remaining_patch', 'read finished')
    
  !-------------------------------------------------------------------------
  CONTAINS
       
    !-------------------------------------------------------------------------
    ! Checks for the pentagon case and moves dummy cells to end.
    ! The dummy entry is either set to 0 or duplicated from the last one
    SUBROUTINE move_dummies_to_end(array, max_verts_connectivity, duplicate)
      
      INTEGER, INTENT(inout) :: array(:,:)
      INTEGER, INTENT(in) :: max_verts_connectivity
      LOGICAL, INTENT(in) :: duplicate
      
      INTEGER :: j, je
      
      DO j = 1, UBOUND(array,1)
        DO je = 1, max_verts_connectivity
          IF (array(j,je) == 0) THEN
            IF ( je /= max_verts_connectivity ) array(j,je) = array(j,max_verts_connectivity)
            IF ( duplicate ) THEN
              array(j,max_verts_connectivity) = array(j,max_verts_connectivity-1)
            ELSE
              array(j,max_verts_connectivity) = 0
            ENDIF
            EXIT
          END IF
        END DO
      END DO
      
    END SUBROUTINE move_dummies_to_end
    !-------------------------------------------------------------------------
    
  END SUBROUTINE read_remaining_patch
  !-------------------------------------------------------------------------

  !-------------------------------------------------------------------------
  INTEGER FUNCTION read_cartesian_positions(ncid, ig, patch, n_lp, id_lp, &
    & array_c_real, array_e_real, array_v_real)
    
    INTEGER,       INTENT(in)    :: ncid
    INTEGER,       INTENT(in)    ::  ig       ! domain ID
    TYPE(t_patch), INTENT(inout), TARGET ::  patch  ! patch data structure
    INTEGER,       INTENT(in)    ::  n_lp     ! Number of local parents on the same level
    INTEGER,       INTENT(in)    ::  id_lp(:) ! IDs of local parents on the same level
    
    REAL(wp), POINTER :: &
      & array_c_real(:,:), &  ! temporary arrays to read in real values
      & array_e_real(:,:), &
      & array_v_real(:,:)
    
    ! status variable
    INTEGER :: ist
    
    INTEGER :: varid
    INTEGER :: ip, ji, jv

    INTEGER :: return_status
    
    TYPE(t_patch), POINTER :: p_p
    
    CHARACTER(LEN=*), PARAMETER :: method_name = 'mo_model_domimp_patches:read_cartesian_positions'
    !-----------------------------------------------------------------------
    read_cartesian_positions = -1
    return_status = nf_inq_varid(ncid, 'cell_circumcenter_cartesian_x', varid)    
    IF (return_status /= nf_noerr) RETURN ! ERROR

    CALL nf(nf_get_var_double(ncid, varid, array_c_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_c_real(:,1), p_p%n_patch_cells, p_p%cells%glb_index, &
        & p_p%cells%cartesian_center(:,:)%x(1) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'cell_circumcenter_cartesian_y', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_c_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_c_real(:,1), p_p%n_patch_cells, p_p%cells%glb_index, &
        & p_p%cells%cartesian_center(:,:)%x(2) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'cell_circumcenter_cartesian_z', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_c_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_c_real(:,1), p_p%n_patch_cells, p_p%cells%glb_index, &
        & p_p%cells%cartesian_center(:,:)%x(3) )
    ENDDO


    CALL nf(nf_inq_varid(ncid, 'edge_middle_cartesian_x', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index, &
        & p_p%edges%cartesian_center(:,:)%x(1) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'edge_middle_cartesian_y', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index, &
        & p_p%edges%cartesian_center(:,:)%x(2) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'edge_middle_cartesian_z', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index, &
        & p_p%edges%cartesian_center(:,:)%x(3) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'edge_dual_middle_cartesian_x', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index, &
        & p_p%edges%cartesian_dual_middle(:,:)%x(1) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'edge_dual_middle_cartesian_y', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index, &
        & p_p%edges%cartesian_dual_middle(:,:)%x(2) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'edge_dual_middle_cartesian_z', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index, &
        & p_p%edges%cartesian_dual_middle(:,:)%x(3) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'edge_primal_normal_cartesian_x', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index, &
        & p_p%edges%primal_cart_normal(:,:)%x(1) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'edge_primal_normal_cartesian_y', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index, &
        & p_p%edges%primal_cart_normal(:,:)%x(2) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'edge_primal_normal_cartesian_z', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index, &
        & p_p%edges%primal_cart_normal(:,:)%x(3) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'edge_dual_normal_cartesian_x', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index, &
        & p_p%edges%dual_cart_normal(:,:)%x(1) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'edge_dual_normal_cartesian_y', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index, &
        & p_p%edges%dual_cart_normal(:,:)%x(2) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'edge_dual_normal_cartesian_z', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_e_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_e_real(:,1), p_p%n_patch_edges, p_p%edges%glb_index, &
        & p_p%edges%dual_cart_normal(:,:)%x(3) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'cartesian_x_vertices', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_v_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_v_real(:,1), p_p%n_patch_verts, p_p%verts%glb_index, &
        & p_p%verts%cartesian(:,:)%x(1) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'cartesian_y_vertices', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_v_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_v_real(:,1), p_p%n_patch_verts, p_p%verts%glb_index, &
        & p_p%verts%cartesian(:,:)%x(2) )
    ENDDO

    CALL nf(nf_inq_varid(ncid, 'cartesian_z_vertices', varid))
    CALL nf(nf_get_var_double(ncid, varid, array_v_real(:,1)))
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)
      CALL divide_real( array_v_real(:,1), p_p%n_patch_verts, p_p%verts%glb_index, &
        & p_p%verts%cartesian(:,:)%x(3) )
    ENDDO

    IF (MAXVAL(ABS(patch%edges%primal_cart_normal(1,1)%x(:))) < 0.001_wp) &
      & RETURN  ! Error , the normal are filled properly
    
    read_cartesian_positions = 0

  END FUNCTION read_cartesian_positions
  !-------------------------------------------------------------------------
  
  !-------------------------------------------------------------------------
  SUBROUTINE calculate_cartesian_positions(ig, patch, n_lp, id_lp)
    
    INTEGER,       INTENT(in)    ::  ig       ! domain ID
    TYPE(t_patch), INTENT(inout), TARGET ::  patch  ! patch data structure
    INTEGER,       INTENT(in)    ::  n_lp     ! Number of local parents on the same level
    INTEGER,       INTENT(in)    ::  id_lp(:) ! IDs of local parents on the same level
    
    INTEGER :: return_status
    
    TYPE(t_patch), POINTER :: p_p

    INTEGER :: ip
    CHARACTER(LEN=*), PARAMETER :: method_name = 'mo_model_domimp_patches:calculate_cartesian_positions'
    !-----------------------------------------------------------------------
    CALL warning(method_name, " is called")
    IF (patch%geometry_info%geometry_type /= sphere_geometry) &
      CALL finish(method_name, "geometry_type /= sphere_geometry")
    
    DO ip = 0, n_lp
      p_p => get_patch_ptr(patch, id_lp, ip)

      ! calculate Cartesian components of primal normal
      ! (these are old grids)
      CALL calculate_patch_cartesian_positions( p_p )

    ENDDO  

  END SUBROUTINE calculate_cartesian_positions
  !-------------------------------------------------------------------------
    
  !-------------------------------------------------------------------------
  ! get_patch_ptr returns a pointer to patch for idx=0,
  ! a pointer to a local parent patch from the list otherwise
  FUNCTION get_patch_ptr(patch, id_lp, idx) result(patch_ptr)
    TYPE(t_patch), TARGET ::  patch  ! patch data structure
    INTEGER,       INTENT(in) ::  id_lp(:) ! IDs of local parents on the same level
    TYPE(t_patch), POINTER :: patch_ptr
    INTEGER, INTENT(in)    :: idx

    IF (idx == 0) THEN
      patch_ptr => patch
    ELSE
      patch_ptr => p_patch_local_parent(id_lp(idx))
    ENDIF
  END FUNCTION get_patch_ptr
  !-------------------------------------------------------------------------

  !-------------------------------------------------------------------------
  !>
  !! Divide and reshape (for blocking) a real array
  !!
  !! @par Revision History
  !! Developed  by Rainer Johanni (2011-12-04)
  !!
  SUBROUTINE divide_real( p_real_array_in, nvals, glb_index, &
    & p_divided_real_array_out )
    
    ! input array
    REAL(wp), INTENT(in):: p_real_array_in(:)
    ! number of values
    INTEGER, INTENT(in) :: nvals
    ! global index of values
    INTEGER, INTENT(in) :: glb_index(:)
    ! output array
    REAL(wp), INTENT(inout) :: p_divided_real_array_out(:,:)
    
    INTEGER nblks, npromz, n, nlen, jb, jl
    
    nblks  = (nvals-1)/nproma + 1
    npromz = nvals - (nblks-1)*nproma
    
    n = 0
    DO jb = 1, nblks
      
      IF (jb /= nblks) THEN
        nlen = nproma
      ELSE
        nlen = npromz
      END IF
      
      DO jl = 1, nlen
        n = n+1
        p_divided_real_array_out(jl,jb) = p_real_array_in(glb_index(n))
      END DO
      
    END DO
    
  END SUBROUTINE divide_real
  !-------------------------------------------------------------------------
  
  !-------------------------------------------------------------------------
  !>
  !! Divide and reshape (for blocking) a integer array
  !!
  !! @par Revision History
  !! Developed  by Rainer Johanni (2011-12-04)
  !!
  SUBROUTINE divide_int( p_int_array_in, nvals, glb_index, &
    & p_divided_int_array_out )
    
    ! input array
    INTEGER, INTENT(in):: p_int_array_in(:)
    ! number of values
    INTEGER, INTENT(in) :: nvals
    ! global index of values
    INTEGER, INTENT(in) :: glb_index(:)
    ! output array
    INTEGER, INTENT(inout) :: p_divided_int_array_out(:,:)
    
    INTEGER nblks, npromz, n, nlen, jb, jl
    
    nblks  = (nvals-1)/nproma + 1
    npromz = nvals - (nblks-1)*nproma
    
    n = 0
    DO jb = 1, nblks
      
      IF (jb /= nblks) THEN
        nlen = nproma
      ELSE
        nlen = npromz
      END IF
      
      DO jl = 1, nlen
        n = n+1
        p_divided_int_array_out(jl,jb) = p_int_array_in(glb_index(n))
      END DO
      
    END DO
    
  END SUBROUTINE divide_int
  !-------------------------------------------------------------------------
  
  !-------------------------------------------------------------------------
  !>
  !! Divide and reshape (for blocking) a index array
  !!
  !! @par Revision History
  !! Developed  by Rainer Johanni (2011-12-04)
  !!
  SUBROUTINE divide_idx( p_idx_array_in, nvals, glb_index, loc_index, &
    & idx_array_out, blk_array_out )
    
    ! input array
    INTEGER, INTENT(in):: p_idx_array_in(:)
    ! number of values
    INTEGER, INTENT(in) :: nvals
    ! global index of values
    INTEGER, INTENT(in) :: glb_index(:)
    ! local index
    INTEGER, INTENT(in) :: loc_index(:)
    ! output array
    INTEGER, INTENT(inout) :: idx_array_out(:,:), blk_array_out(:,:)
    
    INTEGER nblks, npromz, n, nlen, jb, jl, j_g, j_l
    
    nblks  = (nvals-1)/nproma + 1
    npromz = nvals - (nblks-1)*nproma
    
    n = 0
    DO jb = 1, nblks
      
      IF (jb /= nblks) THEN
        nlen = nproma
      ELSE
        nlen = npromz
      END IF
      
      DO jl = 1, nlen
        n = n+1
        ! get global index in divided array
        j_g = p_idx_array_in(glb_index(n))
        IF(j_g < 1 .OR. j_g > UBOUND(loc_index,1)) THEN
          ! Just for safety, this should not happen, set result to 0
          idx_array_out(jl,jb) = idx_no(0)
          blk_array_out(jl,jb) = blk_no(0)
        ELSE
          ! get local index
          j_l = loc_index(j_g)
          ! handle values outside local domain in the same way as get_local_index
          IF(j_l < 0) j_l = -j_g
          idx_array_out(jl,jb) = idx_no(j_l)
          blk_array_out(jl,jb) = blk_no(j_l)
        ENDIF
      END DO
      
    END DO
    
  END SUBROUTINE divide_idx
  !-------------------------------------------------------------------------
  
  !-------------------------------------------------------------------------
  !>
  !!               reshape an integer index array for the blocking.
  !!
  !! @par Revision History
  !! Developed  by  Jochen Foerstner, DWD (2008-10-21)
  !!
  SUBROUTINE reshape_idx( p_idx_array_in, nblks, npromz,  &
    & p_reshaped_idx_array_out,       &
    & p_reshaped_blk_array_out )
    
    
    
    ! input index array
    INTEGER, INTENT(in) :: p_idx_array_in(:)
    ! number of blocks
    INTEGER, INTENT(in) :: nblks
    ! chunk length
    INTEGER, INTENT(in) :: npromz
    
    ! output line index array
    INTEGER, INTENT(inout) :: p_reshaped_idx_array_out(:,:)
    ! output block index array
    INTEGER, INTENT(inout) :: p_reshaped_blk_array_out(:,:)
    
    INTEGER :: nlen
    INTEGER :: jl, jb
    INTEGER :: il, idx_in, idx, blk
    
    !-----------------------------------------------------------------------
    
    DO jb = 1, nblks
      
      IF (jb /= nblks) THEN
        nlen = nproma
      ELSE
        nlen = npromz
        DO jl = npromz+1, nproma
          p_reshaped_idx_array_out(jl,nblks) = 0
          p_reshaped_blk_array_out(jl,nblks) = 0
        END DO
      END IF
      
      DO jl = 1, nlen
        il  = jl + ( jb - 1 )*nproma
        idx_in = p_idx_array_in(il)
        blk = ( ABS(idx_in) - 1 ) / nproma + 1
        idx = SIGN( ABS(idx_in) - ( blk - 1 )*nproma, idx_in )
        p_reshaped_idx_array_out(jl,jb) = idx
        p_reshaped_blk_array_out(jl,jb) = blk
      END DO
      
    END DO
    
  END SUBROUTINE reshape_idx  
  !-------------------------------------------------------------------------
  
  !-------------------------------------------------------------------------
  !>
  !!               reshape an index list array for the blocking.
  !!
  !! @par Revision History
  !! Developed  by Guenther Zaengl, DWD (2008-10-23)
  !!
  SUBROUTINE reshape_indlist( indlist_in,                     &
    & start_idx_out, start_blk_out,   &
    & end_idx_out,   end_blk_out )
    
    
    
    ! input index array
    INTEGER, INTENT(in) :: indlist_in(:,:)
    
    ! output line index array
    INTEGER, INTENT(inout) :: start_idx_out(:,:), end_idx_out(:,:)
    ! output block index array
    INTEGER, INTENT(inout) :: start_blk_out(:,:), end_blk_out(:,:)
    
    !-----------------------------------------------------------------------
    
    start_blk_out(:,1) = (indlist_in(:,1) - 1) / nproma + 1
    start_idx_out(:,1) =  indlist_in(:,1) - (start_blk_out(:,1) - 1) * nproma
    
    end_blk_out(:,1) = (indlist_in(:,2) - 1) / nproma + 1
    end_idx_out(:,1) =  indlist_in(:,2) - (end_blk_out(:,1) - 1) * nproma
    
    
  END SUBROUTINE reshape_indlist
  !-------------------------------------------------------------------------  
  
  !-------------------------------------------------------------------------
  !>
  !!               reshape the start_idx / end_idx fields for blocking.
  !!
  !! @par Revision History
  !! Developed  by Guenther Zaengl, DWD (2009-07-22)
  !!
  SUBROUTINE reshape_idx_list( indlist_in, idx_out, blk_out )
    
    
    
    ! input index array
    INTEGER, INTENT(in) :: indlist_in(:,:)
    
    ! output line index array
    INTEGER, INTENT(inout) :: idx_out(:,:)
    ! output block index array
    INTEGER, INTENT(inout) :: blk_out(:,:)
    
    !-----------------------------------------------------------------------
    
    blk_out(:,1:max_childdom) = (indlist_in(:,1:max_childdom) - 1) / nproma + 1
    idx_out(:,1:max_childdom) =  indlist_in(:,1:max_childdom) - &
      & (blk_out(:,1:max_childdom) - 1) * nproma
    
  END SUBROUTINE reshape_idx_list  
  !-------------------------------------------------------------------------
    
  !-------------------------------------------------------------------------
  SUBROUTINE nf(STATUS, warnonly, silent)
    
    INTEGER, INTENT(in)           :: STATUS
    LOGICAL, INTENT(in), OPTIONAL :: warnonly
    LOGICAL, INTENT(in), OPTIONAL :: silent
    
    LOGICAL :: lwarnonly, lsilent
    
    lwarnonly = .FALSE.
    lsilent   = .FALSE.
    IF(PRESENT(warnonly)) lwarnonly = .TRUE.
    IF(PRESENT(silent))   lsilent   = silent
    
    IF (lsilent) RETURN
    IF (STATUS /= nf_noerr) THEN
      IF (lwarnonly) THEN
        CALL message('mo_model_domain_import netCDF error', nf_strerror(STATUS), &
          & level=em_warn)
      ELSE
        CALL finish('mo_model_domain_import netCDF error', nf_strerror(STATUS))
      ENDIF
    ENDIF
    
  END SUBROUTINE nf
  
END MODULE mo_model_domimp_patches


