#!/bin/bash 
#==============================================================================
# Creates the ICON run scripts
# Leonidas Linardakis, MPI-M, 2011-25-1
#==============================================================================
#==============================================================================
# The basic command for creating an ICON experiment run script is
#   
#  $make_runscript in_script=exp.<name> in_script=exec.iconrun EXPNAME=<name>
#
# By default the folder in use is ./run, and the run script is named exp.<name>.run.
# 
# Basic optional parameters for the $make_runscript command are:
#
#    out_script=<output run script name>. By default is <in_script>.run
#
#    in_folder=<input folder>.   By default is run
#
#    out_folder=<output folder>. By default is <in_folder>
#
#    mpi_procs_pernode=<number of mpi processes per node>. In the case of MPI 
#      configuration, defines how many processes per node will be used.
# 
#    no_of_nodes=<Number of nodes>. In the case of MPI configuration,
#       defines how many nodes will be used.
# 
#    openmp_threads=<Number of openmp threads>. In the case of OPENMP
#       configuration, defines how many OPENMP threads will be used.
#
#    cpu_time=<wall time>. Defines the expected run wall time.
#  
#    <free_variable>=<value> Free variables can be passed to the run script
#       using this syntax. For example: EXPNAME=test, will result the
#       definition of the variable EXPNAME=test in the run script.
#
# For more details see the parameters in the ./config/make_target_runscript
#==============================================================================
set -x
base_folder=$(pwd)
. $base_folder/config/set-up.info
input_folder=run
#==============================================================================
# Define run parameters

#   The experiment name (descriptor is ./run/exp.hat_jww)
#  exp_name="hat_heldsuarez"
#   exp_name="nat_rce_R2B04_test"
#  exp_name="hat_icoham_ape"
#   exp_name="nat_jww_nwp_mpiomp"
#   exp_name="nat_jww_nwp_simple"
#   exp_name="nat_ape_R2B04_bnchmrk"
#   exp_name="nh_dcmip_tc_52_r2b4"
#   exp_name="nh_dcmip_bi_410_R3B4L31_defnew"
#   exp_name="hat_icoham_ape_jsbach"
   exp_name="nat_rce_20km_nwp_384_f15"

#   Define how many nodes to use on blizzard, should be 1 for all other machines
#   at DKRZ and MPI-M
no_of_nodes=16

#   Define how many mpi procs to use per node.
#   On thunder this should be 16.
#   On blizzard it should be mpi_procs_pernode * openmp_threads = 64 in SMT mode (or 32 in none-SMT)
mpi_procs_pernode=32

#   Define how many openmp threads. This has effect only when compiled with openmp.
openmp_threads=2

#   The wall clock time in "hh:mm:ss"
cpu_time="07:58:00"
#==============================================================================
nproma=24
memory_model="large"
#==============================================================================


#==============================================================================
create_runscript()
{
#==============================================================================
use_shell=${use_shell:="/bin/ksh"}
# The $make_runscript command directs to the ./config/make_target_runscript
make_runscript="$use_shell ./config/make_target_runscript"

$make_runscript                  \
  in_folder=$input_folder        \
  in_script=exp.${exp_name}      \
  in_script=exec.iconrun         \
  out_script=exp.${exp_name}.run \
  EXPNAME=${exp_name}            \
  nproma=$nproma                 \
  no_of_nodes=$no_of_nodes       \
  mpi_procs_pernode=$mpi_procs_pernode  \
  openmp_threads=$openmp_threads \
  memory_model=$memory_model     \
  cpu_time=$cpu_time              
}
#==============================================================================


#==============================================================================
#   create the runscript
echo "-----------------------------------------------------------"
create_runscript
echo "-----------------------------------------------------------"
#==============================================================================
