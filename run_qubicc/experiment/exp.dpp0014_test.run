#! /bin/ksh
#=============================================================================

# daint gpu batch job parameters
# ------------------------------
#SBATCH --account=pr55
#SBATCH --partition=normal
#SBATCH --time=02:00:00
#SBATCH --constraint=gpu
#SBATCH --job-name=exp.dpp0014_test.run
#SBATCH --output=/scratch/snx3000/mgiorget/git/icon-cscs/build_daint.gpu.pgi/run/LOG.exp.dpp0014_test.run.%j.o
#SBATCH --error=/scratch/snx3000/mgiorget/git/icon-cscs/build_daint.gpu.pgi/run/LOG.exp.dpp0014_test.run.%j.o
#SBATCH --nodes=967
#SBATCH --ntasks-per-node=1
#
#=============================================================================
set -x
ulimit -s unlimited
ulimit -c 0
#=============================================================================
#
# ICON run script:
# !ATTENTION! Do not change the format of the following lines.
#             They are evaluated by checksuite scripts.
# created by ./run/make_target_runscript
# target machine is daint_gpu
# target use_compiler is pgi
# with_mpi=yes
# with_openmp=no
# memory_model=large
# submit with sbatch
#
#=============================================================================
#
# OpenMP environment variables
# ----------------------------
export OMP_NUM_THREADS=1
export ICON_THREADS=1
export OMP_SCHEDULE=static,1
export OMP_DYNAMIC="false"
export OMP_STACKSIZE=200M
#
# MPI variables
# -------------
no_of_nodes=967
mpi_procs_pernode=1
((mpi_total_procs=no_of_nodes * mpi_procs_pernode))
#
# blocking length
# ---------------
nproma=23332
#
#=============================================================================

# load local setting, if existing
# -------------------------------
if [ -a ../setting ]
then
  echo "Load Setting"
  . ../setting
fi

# environment variables for the experiment and the target system
# --------------------------------------------------------------
export EXPNAME="dpp0014_test"
# load profile
# ------------
if [[ -a  /opt/modules/default/etc/modules.sh ]]
then
	. /opt/modules/default/etc/modules.sh
fi

#=============================================================================

# directories with absolute paths
# -------------------------------
thisdir=$(pwd)
basedir=${thisdir%/*}
export basedir
icon_data_rootFolder="/users/icontest/pool/data/ICON"

# how to start the icon model
# ---------------------------
export START="srun -n $mpi_total_procs --ntasks-per-node $mpi_procs_pernode --threads-per-core=1 --cpus-per-task $OMP_NUM_THREADS"
export MODEL="${basedir}/bin/icon"

# how to submit the next job
# --------------------------
submit="sbatch"
job_name="exp.dpp0014_test.run"

# cdo for post-processing
# -----------------------
cdo="cdo"
cdo_diff="cdo diffn"

# constants for time calculations
# -------------------------------
second=1                                 # [s] 1 second
minute=60                                # [s] 1 minute
hour=3600                                # [s] 1 hour
day=86400                                # [s] 1 day
month=2592000                            # [s] 30 days
year360=31104000                         # [s] 360 days
year=31556900                            # [s] 1 earth year

# define script functions used in the experiment run script
# ---------------------------------------------------------
. ./add_run_routines

#=============================================================================

#off#export CRAY_CUDA_MPS=1
#off#export MPICH_RDMA_ENABLED_CUDA=1
#--------------------------------------------------------------------------------------------------
#
# MPI-AES Dyamond-Winter experiment
#
author_list="Monika Esch, Rene Redler, Daniel Klocke"
#
# Modified by Marco Giorgetta to be used as a test case on Daint-GPU
# - 4 days only
# - monthly mean SST and SIC files instead of the 6-hr file,
#   which cannot be handled on GPUs, reason unclear
# - output reduced to atm_2d and atm_3d files
# - 6-hr restart files
# - used RTE-RRTMGP instead of PSRAD
# - without aerosols, because this cannot be used yet in RTE-RRTMGP
#
# Setup on Daint:
# - 967 nodes = 960 comp. nodes + 7 ouput nodes
# - 1 task/node
#
#--------------------------------------------------------------------------------------------------
#
# This file describes an uncoupled experiment based on the non-hydrostatic atmosphere and the
# Sapphire physics. The atmosphere is intialized from IFS analysis files for 20 Jan 2020 and uses
# transient boundary conditions for:
# - daily SST and sea ice
# - spectral solar irradiation
# - well mixed greenhouse gases CO2, CH4, N2O, CFCs
# - O3 concentration
# - Kinne background aerosol optical properties (irad_aero=13)
#
# Output is, as far as possible, written according to the DYAMOND protocol
# In addition it is also possible to write output in AMIP style with differnet output intervals
#
#--------------------------------------------------------------------------------------------------

# (0) Basic model configuration
# -----------------------------

atmos_gridID="0015"
atmos_refinement="R02B09"

nproma_atm=23332

#
#--------------------------------------------------------------------------------------------------
#
# (1) Define the model time stepping
# ----------------------------------

radTimeStep="PT15M"              # radiation time step:    96 time steps per day
atmTimeStep="PT45S"              # atmosphere time step: 1920 time steps per day
                                 #                         30 time steps per radTimeStep
#--------------------------------------------------------------------------------------------------

# (2) Variables provided by the scripting mechanism

# EXPNAME                       = name of exp. in 'exp.<name>'
# basedir                       = base directory, where src/, run/ etc exist
# icon_data_poolFolder          = base directory, where grids/, input/ and setup/ exist
# nproma                        = blocking length for array dimensioning and inner loop lengths
#                                 -> deprecated. nproma_atm and nproma_ocn are used here.

icon_data_poolFolder="/users/icontest/pool/data/ICON/dyamond-winter/grids/private/rene/mpim"

#--------------------------------------------------------------------------------------------------

# (3) Set variables needed by the scripting mechanism
# ---------------------------------------------------

# horizontal grid(s)
# ------------------
atm_grid_name=icon_grid_${atmos_gridID}_${atmos_refinement}_G

atmo_grid_folder=/users/icontest/pool/data/ICON/grids/public/mpim/${atmos_gridID}
atmo_data_InputFolder=${icon_data_poolFolder}/${atmos_gridID}
atmo_dyn_grid=${atm_grid_name}.nc

# start and end date+time
start_date=${start_date:="2020-01-20T00:00:00Z"}
end_date=${end_date:="2020-01-24T00:00:00Z"}

# restart intervals
# -----------------
checkpoint_interval="PT6H"
restart_interval="P4D"

# output intervals
# ----------------

atm_file_interval="PT6H"
atm_file_interval_2d="PT15M"
atm_file_interval_3d="PT3H"
atm_file_interval_pl="PT15M"

atm_output_interval="PT6H"
atm_output_interval_2d="PT15M"
atm_output_interval_3d="PT3H"
atm_output_interval_pl="PT15M"

# namelist files
# --------------
atm_namelist=NAMELIST_${EXPNAME}_atm
jsbach_namelist=NAMELIST_${EXPNAME}_lnd

atmo_namelist=${atm_namelist}
#--------------------------------------------------------------------------------------------------

# (4) Define the model configuration
#-----------------------------------

# JSBACH settings
run_jsbach=yes
jsbach_usecase=jsbach_lite       # jsbach_lite or jsbach_pfts
jsbach_with_lakes=yes
jsbach_with_carbon=no            # yes needs jsbach_pfts usecase

# Some further processing for land configuration
# ----------------------------------------------

ljsbach=$([ "${run_jsbach:=no}" == yes ]          && echo .TRUE. || echo .FALSE. )
llake=$([ "${jsbach_with_lakes:=yes}" == yes ]    && echo .TRUE. || echo .FALSE. )
lcarbon=$([ "${jsbach_with_carbon:=yes}" == yes ] && echo .TRUE. || echo .FALSE. )

if [[ $jsbach_usecase == *pfts* ]]
then
  pft_file_tag="11pfts_"
else
  pft_file_tag=""
fi

#--------------------------------------------------------------------------------------------------

# (6) Output control
# ------------------

# asynchronous diagnostic output processes
# ----------------------------------------

mpi_atm_io_procs=7                 # for atmosphere (2d and 3d) (1+6)

# output file selection
# ---------------------

# Note that "mpi_atm_io_procs" must match the number of output files
#
# output_<xyz>=yes : yes --> output files for <xyz>, any other value --> no files for <xyz>

output_atm_vgrid=no                # produces 1 atm file 
output_atm_debug=no                # produces 1 atm file 
output_atm_3d=yes                  # produces 6 atm file 
output_atm_2d=yes                  # produces 1 atm file 
output_phy_3d=no                   # produces 1 atm file
                                   # Note: "yes" increases the output volume significantly!

output_lnd=no                      # produces 1 lnd file
output_dyamond=no                  # produces 14 atm_files

#-----------------------------------------------------------------------------
# II. ATMOSPHERE and LAND
#-----------------------------------------------------------------------------
#

# atmosphere namelist
# -------------------
cat > ${atm_namelist} << EOF
!
&parallel_nml
 nproma            = ${nproma_atm}
 num_io_procs      = ${mpi_atm_io_procs}
 !num_restart_procs = 300
 io_process_stride = 12
 io_proc_chunk_size = 16
/
&grid_nml
 dynamics_grid_filename = "${atmo_dyn_grid}"
/
&run_nml
 num_lev           = 90          ! number of full levels
 modelTimeStep     = "${atmTimeStep}"
 ltestcase         = .FALSE.     ! run testcase
 ldynamics         = .TRUE.      ! dynamics
 ltransport        = .TRUE.      ! transport
 iforcing          = 2           ! 0: none, 1: HS, 2: ECHAM, 3: NWP
 output            = 'nml'
 profiling_output  = 1           ! aggregated: 1; detailed: 2; in files: 3
 msg_level         = 12          ! level of details report during integration 
 restart_filename  = "${EXPNAME}_restart_atm_<rsttime>.mfr"
 activate_sync_timers = .TRUE.
/
&extpar_nml
 itopo             = 1           ! 1: read topography from the grid file
/
&initicon_nml
 init_mode         = 2           ! 2: initialize from IFS analysis
 ifs2icon_filename= "ifs2icon.nc"
/
&nonhydrostatic_nml
  iadv_rhotheta   = 2
  ivctype         = 2
  itime_scheme    = 4
  exner_expol     = 0.333
  vwind_offctr    = 0.2
  damp_height     = 44000.
  rayleigh_coeff  = 1
  lhdiff_rcf      = .true.
  divdamp_order   = 24 ! 2 ass, 24 fc
  divdamp_type    = 32  ! optional: 2 assimilation cycle, 32 forecast
  divdamp_fac     = 0.004   ! 0.004 for R2B6; recommendation for R3B7: 0.003
  divdamp_trans_start= 12500
  divdamp_trans_end  = 17500
  l_open_ubc      = .false.
  igradp_method   = 3
  l_zdiffu_t      = .true.
  thslp_zdiffu    = 0.02
  thhgtd_zdiffu   = 125.
  htop_moist_proc = 22500.
  hbot_qvsubstep  = 16000.
/
&sleve_nml
 min_lay_thckn   = 25.
 max_lay_thckn   = 400.   ! maximum layer thickness below htop_thcknlimit
 htop_thcknlimit = 14000. ! this implies that the upcoming COSMO-EU nest will have 60 levels
 top_height      = 75000.
 stretch_fac     = 0.9
 decay_scale_1   = 4000.
 decay_scale_2   = 2500.
 decay_exp       = 1.2
 flat_height     = 16000.
/
&diffusion_nml
/
&transport_nml
 tracer_names     = 'hus','clw','cli', 'qr', 'qs', 'qg'
 ivadv_tracer     =    3 ,   3 ,   3 ,   3 ,   3 ,   3
 itype_hlimit     =    3 ,   4 ,   4 ,   4 ,   4 ,   4
 ihadv_tracer     =   22 ,   2 ,   2 ,   2 ,   2 ,   2
/
&echam_phy_nml
!
! domain 1
! --------
!
! atmospheric phyiscs (""=never)
 echam_phy_config(1)%dt_rad = "${radTimeStep}"
 echam_phy_config(1)%dt_vdf = "${atmTimeStep}"
 echam_phy_config(1)%dt_cnv = ""
 echam_phy_config(1)%dt_cld = ""
 echam_phy_config(1)%dt_mig = "${atmTimeStep}"
 echam_phy_config(1)%dt_gwd = ""
 echam_phy_config(1)%dt_sso = ""
!
! atmospheric chemistry (""=never)
 echam_phy_config(1)%dt_mox = ""
 echam_phy_config(1)%dt_car = ""
 echam_phy_config(1)%dt_art = ""
!
! surface (.TRUE. or .FALSE.)
 echam_phy_config(1)%ljsb   = ${ljsbach} ! .TRUE. if run_jsbach=yes
 echam_phy_config(1)%lamip  = .TRUE.
 echam_phy_config(1)%lice   = .TRUE.
 echam_phy_config(1)%lsstice= .FALSE.
 echam_phy_config(1)%lmlo   = .FALSE.
 echam_phy_config(1)%llake  = ${llake}   ! .TRUE. if jsbach_with_lakes=yes
!
! fix negative humidity
 echam_phy_config(1)%iqneg_d2p = 2
 echam_phy_config(1)%iqneg_p2d = 2
! set htop_moist_proc also as top of graupel calculation
! echam_phy_config(1)%zmaxcloudy = 22500.
/
&echam_rad_nml
!
! domain 1
! --------
!
 echam_rad_config(1)%isolrad    =  1
 echam_rad_config(1)%irad_h2o   =  1
 echam_rad_config(1)%irad_co2   =  3
 echam_rad_config(1)%irad_ch4   =  13
 echam_rad_config(1)%irad_n2o   =  13
 echam_rad_config(1)%irad_o3    =  5
 echam_rad_config(1)%irad_o2    =  2
 echam_rad_config(1)%irad_cfc11 =  3
 echam_rad_config(1)%irad_cfc12 =  3
 echam_rad_config(1)%irad_aero  =  0
 echam_rad_config(1)%rrtmgp_columns_chunk = 100
/
&echam_gwd_nml
/
&echam_sso_nml
/
&echam_vdf_nml
 echam_vdf_config(1)%pr0        =  0.7
/
&echam_cnv_nml
/
&echam_cld_nml
/
&echam_cop_nml
 echam_cop_config(1)%cn1lnd     =  50.0
 echam_cop_config(1)%cn2lnd     = 220.0
 echam_cop_config(1)%cn1sea     =  50.0
 echam_cop_config(1)%cn2sea     = 100.0
 echam_cop_config(1)%cinhomi    =   1.0
 echam_cop_config(1)%cinhoml1   =   1.0
 echam_cop_config(1)%cinhoml2   =   1.0
 echam_cop_config(1)%cinhoml3   =   1.0
/
&echam_mig_nml
 echam_mig_config(1)%mu_rain        = 0.5
 echam_mig_config(1)%rain_n0_factor = 0.1
 echam_mig_config(1)%v0snow         = 25.
! echam_mig_config(1)%zvz0i          = 3.29  ! Terminal fall velocity of ice  (original value of Heymsfield+Donner 1990: 3.29)
/
&echam_cov_nml
 echam_cov_config(1)%icov       = 3     ! 0/1 cloud cover based on cloud water and ice
 echam_cov_config(1)%cqx        = 1.e-6
/
&sea_ice_nml
/
EOF

# jsbach namelist
# ---------------

cat > ${jsbach_namelist} << EOF
&jsb_model_nml
  usecase              = "${jsbach_usecase}"
  use_lakes            = ${llake}            ! TRUE if jsbach_with_lakes=yes
  fract_filename       = 'bc_land_frac.nc'
/
&jsb_seb_nml
  bc_filename          = 'bc_land_phys.nc'
  ic_filename          = 'ic_land_soil.nc'
/
&jsb_rad_nml
  use_alb_veg_simple = .TRUE.           ! Use TRUE for jsbach_lite, FALSE for jsbach_pfts
  bc_filename          = 'bc_land_phys.nc'
  ic_filename          = 'ic_land_soil.nc'
/
&jsb_turb_nml
  bc_filename          = 'bc_land_phys.nc'
  ic_filename          = 'ic_land_soil.nc'
/
&jsb_sse_nml
  l_heat_cap_map       = .FALSE.
  l_heat_cond_map      = .FALSE.
  l_heat_cap_dyn       = .TRUE.
  l_heat_cond_dyn      = .TRUE.
  l_snow               = .TRUE.
  l_dynsnow            = .TRUE.
  l_freeze             = .FALSE.
  l_supercool          = .FALSE.
  bc_filename          = 'bc_land_soil.nc'
  ic_filename          = 'ic_land_soil.nc'
/
&jsb_hydro_nml
  bc_filename          = 'bc_land_soil.nc'
  ic_filename          = 'ic_land_soil.nc'
  bc_sso_filename      = 'bc_land_sso.nc'
/
&jsb_assimi_nml
  active               = .FALSE.             ! Use FALSE for jsbach_lite, TRUE for jsbach_pfts
/
&jsb_pheno_nml
  scheme               = 'climatology'       ! scheme = logrop / climatology; use climatology for jsbach_lite
  bc_filename          = 'bc_land_phys.nc'
  ic_filename          = 'ic_land_soil.nc'
/
&jsb_carbon_nml
  active               = ${lcarbon}   ! TRUE if jsbach_with_carbon=yes
  bc_filename          = 'bc_land_carbon.nc'
  ic_filename          = 'ic_land_carbon.nc'
  read_cpools          = .FALSE.
/
&jsb_fuel_nml
  active               = ${lcarbon}
  fuel_algorithm       = 1
/
&jsb_disturb_nml
  active               = .FALSE.
  ic_filename          = 'ic_land_soil.nc'
  bc_filename          = 'bc_land_phys.nc'
  fire_algorithm       = 1
  windbreak_algorithm  = 1
  lburn_pasture        = .FALSE.
/
&jsb_hd_nml
  active               = .FALSE.
  routing_scheme       = 'full'
  ic_filename          = 'ic_land_hd.nc'
  bc_filename          = 'bc_land_hd.nc'
  diag_water_budget    = .TRUE.
  debug_hd             = .FALSE.
  enforce_water_budget = .FALSE.         ! True: stop in case of water conservation problem
/
EOF

#--------------------------------------------------------------------------------------------------

# Define the atmosphere and land input
# ------------------------------------

# model files
#
add_link_file ${basedir}/data/rrtmgp-data-lw-g256-2018-12-04.nc         ./coefficients_lw.nc
add_link_file ${basedir}/data/rrtmgp-data-sw-g224-2018-12-04.nc         ./coefficients_sw.nc
add_link_file ${basedir}/data/ECHAM6_CldOptProps_rrtmgp_lw.nc           ./rrtmgp-cloud-optics-coeffs-lw.nc
add_link_file ${basedir}/data/ECHAM6_CldOptProps_rrtmgp_sw.nc           ./rrtmgp-cloud-optics-coeffs-sw.nc

# namelist files
# --------------
add_required_file ${basedir}/run/${atm_namelist}                           ./
add_required_file ${basedir}/run/${jsbach_namelist}                           ./

# dictionary file for output variable names
#
dict_file="dict.${EXPNAME}"
cat dict.iconam.mpim  > ${dict_file}
add_required_file ${basedir}/run/${dict_file}                              ./

# initial conditions
#
# - atmosphere: ECMWF analysis, 2020-01-20T00:00:00Z
datadir=${atmo_data_InputFolder}/initial_condition
add_link_file ${datadir}/ifs2icon_2020012000_${atmos_refinement}_G.nc      ./ifs2icon.nc
#
# boundary conditions
#
# - well mixed greenhouse gases (ssp245: years 0-2500)
#
datadir=${icon_data_poolFolder}/independent/greenhouse_gases
add_link_file ${datadir}/greenhouse_ssp245.nc                              ./bc_greenhouse_gases.nc
#
# range of years for yearly files
# assume start_date and end_date have the format yyyy-...
#
start_year=$(( ${start_date%%-*} - 1 ))
end_year=$(( ${end_date%%-*} + 1 ))
#
# - ozone
# -- for irad_o3=8
#
datadir=${atmo_data_InputFolder}/ozone
#
year=$start_year
while [[ $year -le $end_year ]]
do
  if [[ $year -le 2014 ]]
  then
    add_link_file ${datadir}/bc_ozone_historical_${year}.nc                ./bc_ozone_${year}.nc
  else
    add_link_file ${datadir}/bc_ozone_historical_2014.nc                   ./bc_ozone_${year}.nc
  fi
  (( year = year+1 ))
done
    add_link_file ${datadir}/bc_ozone_historical_2014.nc                   ./bc_ozone.nc
#
#   Kinne background aerosols are needed for the year 1850 (irad_aero=18)
#
#   Here we use revised data (r0002) based on work by Sebastian Rast
#
datadir=${atmo_data_InputFolder}/aerosol_kinne
#
add_link_file ${datadir}/bc_aeropt_kinne_lw_b16_coa.nc                     ./
add_link_file ${datadir}/bc_aeropt_kinne_sw_b14_coa.nc                     ./
add_link_file ${datadir}/bc_aeropt_kinne_sw_b14_fin_2020.nc                ./bc_aeropt_kinne_sw_b14_fin_2020.nc
#
# - sst and sic
#
datadir=/users/icontest/pool/data/ICON/dyamond-winter/grids/private/rene/mpim/0015/sst_and_seaice
#
add_link_file $datadir/bc_sic_2020.nc                                      ./bc_sic.nc
add_link_file $datadir/bc_sst_2020.nc                                      ./bc_sst.nc
#
# - ssi and tsi
#
datadir=${icon_data_poolFolder}/independent/solar_radiation/3.2
#
add_link_file ${datadir}/swflux_14band_cmip6_1850-2299-v3.2.nc             ./bc_solar_irradiance_sw_b14.nc
#
# - land parameters
#
datadir=${atmo_data_InputFolder}/land
#
add_link_file ${datadir}/ic_land_soil_1992.nc                              ./ic_land_soil.nc
add_link_file ${datadir}/bc_land_soil_1992.nc                              ./bc_land_soil.nc
add_link_file ${datadir}/bc_land_frac_${pft_file_tag}1992.nc               ./bc_land_frac.nc
add_link_file ${datadir}/bc_land_phys_1992.nc                              ./bc_land_phys.nc
add_link_file ${datadir}/bc_land_sso_1992.nc                               ./bc_land_sso.nc
#
# - lctlib file for JSBACH
#
add_link_file ${basedir}/externals/jsbach/data/lctlib_nlct21.def           ./lctlib_nlct21.def
#
# - the atmosphere grid itself (the grid copy section below from $HGRIDDIR is ignored)
#
add_link_file ${atmo_grid_folder}/${atmo_dyn_grid}                         ./
#
#--------------------------------------------------------------------------------------------------

# (5) Define the output
# ---------------------

# Parameters for all output files
# -------------------------------
cat >> ${atm_namelist} << EOF
&io_nml
 output_nml_dict    = "${dict_file}"
 netcdf_dict        = "${dict_file}"
 write_last_restart = .TRUE.
 itype_pres_msl     = 4
 restart_file_type  = 5
 restart_write_mode = "joint procs multifile"
!lkeep_in_sync      = .TRUE.
/
EOF
#
# Define debug output file with high time res
# -------------------------------------------
#
if [[ "$output_atm_debug" == "yes" ]]; then
  #
  cat >> ${atm_namelist} << EOF
&output_nml
 output_filename  = "${EXPNAME}_atm_debug"
 filename_format  = "<output_filename>_<levtype_l>_<datetime2>"
 filetype         = 5
 remap            = 0
 operation        = 'none'
 output_grid      = .FALSE.
 output_start     = "${start_date}"
 output_end       = "${end_date}"
 output_interval  = "${atmTimeStep}"
 file_interval    = "PT5M"
 include_last     = .FALSE.
 ml_varlist       = 'ts'
/
EOF
fi
# Define output files
# -------------------
#
# output_<xyz>=yes : yes --> output files for <xyz>, any other value --> no files for <xyz>
#
# 3-dimensional files include 'ps' and 'pfull' to allow the vertical
# interpolation to pressure levels by cdo ap2pl.
#
if [[ "$output_atm_vgrid" == "yes" ]]; then
  #
  cat >> ${atm_namelist} << EOF
&output_nml
 output_filename  = "${EXPNAME}_atm_vgrid"
 filename_format  = "<output_filename>_<levtype_l>"
 filetype         = 5
 remap            = 0
 output_grid      = .TRUE.
 output_start     = "${start_date}"               ! output_start = output_end
 output_end       = "${start_date}"               ! --> write once only irrespective of
 output_interval  = "${atm_output_interval}"      !     the output interval and
 file_interval    = "${atm_file_interval}"        !     the file interval
 ml_varlist       = 'zghalf'  , 'zg'      , 'dzghalf'
/
EOF
fi


if [[ "$output_atm_3d" == "yes" ]]; then
  #
  # split file in high number of files for speedup
  #
  cat >> ${atm_namelist} << EOF
&output_nml
 output_filename  = "${EXPNAME}_atm_3d_1"
 filename_format  = "<output_filename>_<levtype_l>_<datetime2>"
 filetype         = 5
 remap            = 0
 operation        = 'mean'
 output_grid      = .FALSE.
 output_start     = "${start_date}"
 output_end       = "${end_date}"
 output_interval  = "${atm_output_interval}"
 file_interval    = "${atm_file_interval}"
 include_last     = .FALSE.
 ml_varlist       = 'pfull'   ,'ta'
/
&output_nml
 output_filename  = "${EXPNAME}_atm_3d_2"
 filename_format  = "<output_filename>_<levtype_l>_<datetime2>"
 filetype         = 5
 remap            = 0
 operation        = 'mean'
 output_grid      = .FALSE.
 output_start     = "${start_date}"
 output_end       = "${end_date}"
 output_interval  = "${atm_output_interval}"
 file_interval    = "${atm_file_interval}"
 include_last     = .FALSE.
 ml_varlist       = 'ua'      , 'va'
/
&output_nml
 output_filename  = "${EXPNAME}_atm_3d_3"
 filename_format  = "<output_filename>_<levtype_l>_<datetime2>"
 filetype         = 5
 remap            = 0
 operation        = 'mean'
 output_grid      = .FALSE.
 output_start     = "${start_date}"
 output_end       = "${end_date}"
 output_interval  = "${atm_output_interval}"
 file_interval    = "${atm_file_interval}"
 include_last     = .FALSE.
 ml_varlist       = 'wap'     , 'cl'
/
&output_nml
 output_filename  = "${EXPNAME}_atm_3d_4"
 filename_format  = "<output_filename>_<levtype_l>_<datetime2>"
 filetype         = 5
 remap            = 0
 operation        = 'mean'
 output_grid      = .FALSE.
 output_start     = "${start_date}"
 output_end       = "${end_date}"
 output_interval  = "${atm_output_interval}"
 file_interval    = "${atm_file_interval}"
 include_last     = .FALSE.
 ml_varlist       = 'hus'     , 'clw'
/
&output_nml
 output_filename  = "${EXPNAME}_atm_3d_5"
 filename_format  = "<output_filename>_<levtype_l>_<datetime2>"
 filetype         = 5
 remap            = 0
 operation        = 'mean'
 output_grid      = .FALSE.
 output_start     = "${start_date}"
 output_end       = "${end_date}"
 output_interval  = "${atm_output_interval}"
 file_interval    = "${atm_file_interval}"
 include_last     = .FALSE.
 ml_varlist       = 'cli'
/
&output_nml
 output_filename  = "${EXPNAME}_atm_3d_6"
 filename_format  = "<output_filename>_<levtype_l>_<datetime2>"
 filetype         = 5
 remap            = 0
 operation        = 'mean'
 output_grid      = .FALSE.
 output_start     = "${start_date}"
 output_end       = "${end_date}"
 output_interval  = "${atm_output_interval}"
 file_interval    = "${atm_file_interval}"
 include_last     = .FALSE.
 ml_varlist       = 'rsd'     , 'rsu'
/
EOF
fi


if [[ "$output_atm_2d" == "yes" ]]; then
  #
  cat >> ${atm_namelist} << EOF
&output_nml
 output_filename  = "${EXPNAME}_atm_2d"
 filename_format  = "<output_filename>_<levtype_l>_<datetime2>"
 filetype         = 5
 remap            = 0
 operation        = 'mean'
 output_grid      = .FALSE.
 output_start     = "${start_date}"
 output_end       = "${end_date}"
 output_interval  = "${atm_output_interval}"
 file_interval    = "${atm_file_interval}"
 include_last     = .FALSE.
 ml_varlist       = 'ps'      , 'psl'     ,
                    'rsdt'    ,
                    'rsut'    , 'rsutcs'  , 'rlut'    , 'rlutcs'  ,
                    'rsds'    , 'rsdscs'  , 'rlds'    , 'rldscs'  ,
                    'rsus'    , 'rsuscs'  , 'rlus'    ,
                    'ts'      ,
                    'sic'     , 'sit'     ,
                    'clt'     ,
                    'prlr'    , 'prls'    ,
                    'pr'      , 'prw'     , 'cllvi'   , 'clivi'   ,
                    'qgvi'    , 'qrvi'    , 'qsvi'    ,
                    'hfls'    , 'hfss'    , 'evspsbl' ,
                    'tauu'    , 'tauv'    ,
                    'sfcwind' , 'uas'     , 'vas'     ,
                    'tas'
/
EOF
fi


if [[ "$output_phy_3d" == "yes" ]]; then
  #
  cat >> ${atm_namelist} << EOF
&output_nml
 output_filename  = "${EXPNAME}_phy_3d"
 filename_format  = "<output_filename>_<levtype_l>_<datetime2>"
 filetype         = 5
 remap            = 0
 operation        = 'mean'
 output_grid      = .FALSE.
 output_start     = "${start_date}"
 output_end       = "${end_date}"
 output_interval  = "${atm_output_interval}"
 file_interval    = "${atm_file_interval}"
 include_last     = .FALSE.
 ml_varlist       = 'ps'           , 'pfull'        ,
                    'tend_ta'      , 'tend_qhus'    ,
                    'tend_ta_dyn'  , 'tend_qhus_dyn',
                    'tend_ta_phy'  , 'tend_qhus_phy',
                    'tend_ta_rlw'  , 'tend_ta_rsw'  ,
                    'tend_ta_vdf'  , 'tend_qhus_vdf',
                    'tend_ta_mig'  , 'tend_qhus_mig',
                    'tend_qclw_mig', 'tend_qcli_mig',
                    'tend_qqr_mig' , 'tend_qqs_mig' , 'tend_qqg_mig'
/
EOF
fi


# minimal jsbach output for running atm_amip experiment
# for more jsbach output see exp.atm_amip_les
#
if [[ "$output_lnd" == "yes" ]]; then
  cat >> ${atm_namelist} << EOF
&output_nml
 output_filename  = "${EXPNAME}_lnd"
 filename_format  = "<output_filename>_<levtype_l>_<datetime2>"
 filetype         = 5
 remap            = 0
 operation        = 'mean'
 output_grid      = .FALSE.
 output_start     = "${start_date}"
 output_end       = "${end_date}"
 output_interval  = "${atm_output_interval}"
 file_interval    = "${atm_file_interval}"
 include_last     = .FALSE.
 ml_varlist       = 'pheno_lai_box'             , 'pheno_fract_fpc_veg'  , 'hydro_fract_water_box' ,
                    'hydro_fract_snow_box'      , 'hydro_w_skin_box'     , 'hydro_w_snow_box'      ,
                    'hydro_w_soil_column_box'   ,
                    'hydro_runoff_box'          , 'hydro_drainage_box'   ,
                    'hydro_discharge_ocean_box' , 'hydro_discharge_box' 
/
EOF
fi

if [[ "$output_dyamond" == "yes" ]]; then
  #
  cat >> ${atm_namelist} << EOF
&output_nml
 output_filename              = "${EXPNAME}_atm_3d_u"
 filename_format              = "<output_filename>_<levtype_l>_<datetime2>"
 filetype                     =  5                        ! output format: 2=GRIB2, 4=NETCDFv2 PN: 5:NetCDF with hdf5
 file_interval                = "${atm_file_interval_3d}"
 output_start                 = "${start_date}"
 output_interval              = "${atm_output_interval_3d}"
 output_end                   = "${end_date}"
 mode                         = 2
 remap                        = 0                         ! 1: latlon,  0: native grid
 include_last                 = .FALSE.
 ml_varlist                   = 'ua'
 m_levels                     = '14...(nlev+1)'
 output_grid                  = .FALSE.
/
&output_nml
 output_filename              = "${EXPNAME}_atm_3d_v"
 filename_format              = "<output_filename>_<levtype_l>_<datetime2>"
 filetype                     =  5                        ! output format: 2=GRIB2, 4=NETCDFv2 PN: 5:NetCDF with hdf5
 file_interval                = "${atm_file_interval_3d}"
 output_start                 = "${start_date}"
 output_interval              = "${atm_output_interval_3d}"
 output_end                   = "${end_date}"
 mode                         = 2
 remap                        = 0                         ! 1: latlon,  0: native grid
 include_last                 = .FALSE.
 ml_varlist                   = 'va'
 m_levels                     = '14...(nlev+1)'
 output_grid                  = .FALSE.
/
&output_nml
 output_filename              = "${EXPNAME}_atm_3d_w"
 filename_format              = "<output_filename>_<levtype_l>_<datetime2>"
 filetype                     =  5                        ! output format: 2=GRIB2, 4=NETCDFv2 PN: 5:NetCDF with hdf5
 file_interval                = "${atm_file_interval_3d}"
 output_start                 = "${start_date}"
 output_interval              = "${atm_output_interval_3d}"
 output_end                   = "${end_date}"
 mode                         = 2
 remap                        = 0                         ! 1: latlon,  0: native grid
 include_last                 = .FALSE.
 ml_varlist                   = 'wap'
 m_levels                     = '14...(nlev+1)'
 output_grid                  = .FALSE.
/
&output_nml
 output_filename              = "${EXPNAME}_atm_3d_pres"
 filename_format              = "<output_filename>_<levtype_l>_<datetime2>"
 filetype                     =  5                        ! output format: 2=GRIB2, 4=NETCDFv2 PN 5: Netcdf with hdf5
 file_interval                = "${atm_file_interval_3d}"
 output_start                 = "${start_date}"
 output_interval              = "${atm_output_interval_3d}"
 output_end                   = "${end_date}"
 mode                         = 2
 remap                        = 0                         ! 1: latlon,  0: native grid
 include_last                 = .FALSE.
 ml_varlist                   = 'pfull'
 m_levels                     = '14...(nlev)'
 output_grid                  = .FALSE.
/
&output_nml
 output_filename              = "${EXPNAME}_atm_3d_t"
 filename_format              = "<output_filename>_<levtype_l>_<datetime2>"
 filetype                     =  5                        ! output format: 2=GRIB2, 4=NETCDFv2 PN 5: Netcdf with hdf5
 file_interval                = "${atm_file_interval_3d}"
 output_start                 = "${start_date}"
 output_interval              = "${atm_output_interval_3d}"
 output_end                   = "${end_date}"
 mode                         = 2
 remap                        = 0                         ! 1: latlon,  0: native grid
 include_last                 = .FALSE.
 ml_varlist                   = 'ta'
 m_levels                     = '14...(nlev)'
 output_grid                  = .FALSE.
/
&output_nml
 output_filename              = "${EXPNAME}_atm_3d_qv"
 filename_format              = "<output_filename>_<levtype_l>_<datetime2>"
 filetype                     =  5                        ! output format: 2=GRIB2, 4=NETCDFv2 PN 5: NetCDF with hdf5
 file_interval                = "${atm_file_interval_3d}"
 output_start                 = "${start_date}"
 output_interval              = "${atm_output_interval_3d}"
 output_end                   = "${end_date}"
 mode                         = 2
 remap                        = 0                         ! 1: latlon,  0: native grid
 include_last                 = .FALSE.
 ml_varlist                   = 'hus'
 m_levels                     = '14...(nlev)'
 output_grid                  = .FALSE.
/
&output_nml
 output_filename              = "${EXPNAME}_atm_3d_tot_qc_dia"
 filename_format              = "<output_filename>_<levtype_l>_<datetime2>"
 filetype                     =  5                        ! output format: 2=GRIB2, 4=NETCDFv2 PN 5: NetCDF with hdf5
 file_interval                = "${atm_file_interval_3d}"
 output_start                 = "${start_date}"
 output_interval              = "${atm_output_interval_3d}"
 output_end                   = "${end_date}"
 mode                         = 2
 remap                        = 0                         ! 1: latlon,  0: native grid
 include_last                 = .FALSE.
 ml_varlist                   = 'clw'
 m_levels                     = '14...(nlev)'
 output_grid                  = .FALSE.
/
&output_nml
 output_filename              = "${EXPNAME}_atm_3d_tot_qi_dia"
 filename_format              = "<output_filename>_<levtype_l>_<datetime2>"
 filetype                     =  5                        ! output format: 2=GRIB2, 4=NETCDFv2 PN 5: NetCDF with hdf5
 file_interval                = "${atm_file_interval_3d}"
 output_start                 = "${start_date}"
 output_interval              = "${atm_output_interval_3d}"
 output_end                   = "${end_date}"
 mode                         = 2
 remap                        = 0                         ! 1: latlon,  0: native grid
 include_last                 = .FALSE.
 ml_varlist                   = 'cli'
 m_levels                     = '14...(nlev)'
 output_grid                  = .FALSE.
/
&output_nml
 output_filename              = "${EXPNAME}_atm1_2d"
 filename_format              = "<output_filename>_<levtype_l>_<datetime2>"
 filetype                     =  5                        ! output format: 2=GRIB2, 4=NETCDFv2 PN: Netcdf with hdf5
 file_interval                = "${atm_file_interval_2d}"
 output_start                 = "${start_date}"
 output_interval              = "${atm_output_interval_2d}"
 output_end                   = "${end_date}"
 remap                        = 0                         ! 1: latlon,  0: native grid
 include_last                 = .FALSE.
 ml_varlist                   = 'prw' , 'cllvi' , 'clivi' , 'qgvi' , 'qrvi' , 'qsvi' 
 output_grid                  = .FALSE.
/
&output_nml
 output_filename              = "${EXPNAME}_atm3_2d"
 filename_format              = "<output_filename>_<levtype_l>_<datetime2>"
 filetype                     =  5                        ! output format: 2=GRIB2, 4=NETCDFv2 PN: Netcdf with hdf5
 file_interval                = "${atm_file_interval_2d}"
 output_start                 = "${start_date}"
 output_interval              = "${atm_output_interval_2d}"
 output_end                   = "${end_date}"
 remap                        = 0                         ! 1: latlon,  0: native grid
 include_last                 = .FALSE.
 ml_varlist                   = 'uas' , 'vas' , 'tas'
 output_grid                  = .FALSE.
/
&output_nml
 output_filename              = "${EXPNAME}_atm2_2d"
 filename_format              = "<output_filename>_<levtype_l>_<datetime2>"
 filetype                     =  5                        ! output format: 2=GRIB2, 4=NETCDFv2 PN: Netcdf with hdf5
 file_interval                = "${atm_file_interval_2d}"
 output_start                 = "${start_date}"
 output_interval              = "${atm_output_interval_2d}"
 output_end                   = "${end_date}"
 remap                        = 0                         ! 1: latlon,  0: native grid
 include_last                 = .FALSE.
 ml_varlist                   = 'clt' , 'hfls', 'hfss', 'psl' , 'ps' , 'pr'
 output_grid                  = .FALSE.
/
&output_nml
 output_filename              = "${EXPNAME}_atm4_2d"
 filename_format              = "<output_filename>_<levtype_l>_<datetime2>"
 filetype                     =  5                        ! output format: 2=GRIB2, 4=NETCDFv2 PN: Netcdf with hdf5
 file_interval                = "${atm_file_interval_2d}"
 output_start                 = "${start_date}"
 output_interval              = "${atm_output_interval_2d}"
 output_end                   = "${end_date}"
 remap                        = 0                         ! 1: latlon,  0: native grid
 include_last                 = .FALSE.
 ml_varlist                   = 'ts', 'tauu', 'tauv'
 output_grid                  = .FALSE.
/
&output_nml
 output_filename              = "${EXPNAME}_atm_2d_avg"
 filename_format              = "<output_filename>_<levtype_l>_<datetime2>"
 filetype                     =  5                        ! output format: 2=GRIB2, 4=NETCDFv2 PN: Netcfd with hdf5
 file_interval                = "${atm_file_interval_2d}"
 output_start                 = "${start_date}"
 output_interval              = "${atm_output_interval_2d}"
 output_end                   = "${end_date}"
 remap                        = 0                         ! 1: latlon,  0: native grid
 include_last                 = .FALSE
 ml_varlist                   = 'rsut' , 'rlut' , 'rsds' , 'rlds' , 'rsus' , 'rlus', 'rsdt', 'rsutcs', 'rlutcs', 'rsdscs', 'rldscs', 'rsuscs'
 output_grid                  = .FALSE.
/
&output_nml
 output_filename              = "${EXPNAME}_atm_omega_3d"
 filename_format              = "<output_filename>_<levtype_l>_<datetime2>"
 filetype                     = 5                         ! output format: 2=GRIB2, 4=NETCDFv2 PN 5: netcfd with hdf5
 file_interval                = "${atm_file_interval_pl}"
 output_start                 = "${start_date}"
 output_interval              = "${atm_output_interval_pl}"
 output_end                   = "${end_date}"
 mode                         = 2
 remap                        = 0
 include_last                 = .FALSE.
 pl_varlist                   = 'omega' , 'zg'
 p_levels                     = 20000,50000,70000,85000
 output_grid                  = .FALSE.
/
EOF
fi

#-----------------------------------------------------------------------------
#!/bin/ksh
#=============================================================================
#
# This section of the run script prepares and starts the model integration.
#
# MODEL and START must be defined as environment variables or
# they must be substituted with appropriate values.
#
# Marco Giorgetta, MPI-M, 2010-04-21
#
#-----------------------------------------------------------------------------
final_status_file=${basedir}/run/${job_name}.final_status
rm -f ${final_status_file}
#-----------------------------------------------------------------------------
#
# directories definition
#
RUNSCRIPTDIR=${basedir}/run
if [ x$grids_folder = x ] ; then
   HGRIDDIR=${basedir}/grids
else
   HGRIDDIR=$grids_folder
fi

# experiment directory, with plenty of space, create if new
EXPDIR=${basedir}/experiments/${EXPNAME}
if [ ! -d ${EXPDIR} ] ;  then
  mkdir -p ${EXPDIR}
fi
#
ls -ld ${EXPDIR}
if [ ! -d ${EXPDIR} ] ;  then
    mkdir ${EXPDIR}
#else
#   rm -rf ${EXPDIR}
#   mkdir  ${EXPDIR}
fi
ls -ld ${EXPDIR}
check_error $? "${EXPDIR} does not exist?"

cd ${EXPDIR}

#-----------------------------------------------------------------------------
final_status_file=${RUNSCRIPTDIR}/${job_name}.final_status
rm -f ${final_status_file}

#-----------------------------------------------------------------------------
# set up the model lists if they do not exist
# this works for single model runs
# for coupled runs the lists should be declared explicilty
if [ x$namelist_list = x ]; then
#  minrank_list=(        0           )
#  maxrank_list=(     65535          )
#  incrank_list=(        1           )
  minrank_list[0]=0
  maxrank_list[0]=65535
  incrank_list[0]=1
  if [ x$atmo_namelist != x ]; then
    # this is the atmo model
    namelist_list[0]="$atmo_namelist"
    modelname_list[0]="atmo"
    modeltype_list[0]=1
    run_atmo="true"
  elif [ x$ocean_namelist != x ]; then
    # this is the ocean model
    namelist_list[0]="$ocean_namelist"
    modelname_list[0]="ocean"
    modeltype_list[0]=2
  elif [ x$psrad_namelist != x ]; then
    # this is the psrad model
    namelist_list[0]="$psrad_namelist"
    modelname_list[0]="psrad"
    modeltype_list[0]=3
  elif [ x$hamocc_namelist != x ]; then
    # this is the hamocc model
    namelist_list[0]="$hamocc_namelist"
    modelname_list[0]="hamocc"
    modeltype_list[0]=4
  elif [ x$testbed_namelist != x ]; then
    # this is the testbed model
    namelist_list[0]="$testbed_namelist"
    modelname_list[0]="testbed"
    modeltype_list[0]=99
  else
    check_error 1 "No namelist is defined"
  fi
fi

#-----------------------------------------------------------------------------


#-----------------------------------------------------------------------------
# set some default values and derive some run parameteres
restart=${restart:=".false."}
restartSemaphoreFilename='isRestartRun.sem'
#AUTOMATIC_RESTART_SETUP:
if [ -f ${restartSemaphoreFilename} ]; then
  restart=.true.
  #  do not delete switch-file, to enable restart after unintended abort
  #[[ -f ${restartSemaphoreFilename} ]] && rm ${restartSemaphoreFilename}
fi
#END AUTOMATIC_RESTART_SETUP
#
# wait 5min to let GPFS finish the write operations
if [ "x$restart" != 'x.false.' -a "x$submit" != 'x' ]; then
  if [ x$(df -T ${EXPDIR} | cut -d ' ' -f 2) = gpfs ]; then
    sleep 10;
  fi
fi
# fill some checks

run_atmo=${run_atmo="false"}
if [ x$atmo_namelist != x ]; then
  run_atmo="true"
fi
run_jsbach=${run_jsbach="false"}
run_ocean=${run_ocean="false"}
if [ x$ocean_namelist != x ]; then
  run_ocean="true"
fi
run_psrad=${run_psrad="false"}
if [ x$psrad_namelist != x ]; then
  run_psrad="true"
fi
run_hamocc=${run_hamocc="false"}
if [ x$hamocc_namelist != x ]; then
  run_hamocc="true"
fi

#-----------------------------------------------------------------------------
# add grids to required files
all_grids="${atmo_dyn_grids} ${atmo_rad_grids} ${ocean_grids}"
for gridfile in ${all_grids}; do
  #
  gridfile=${gridfile//\'/} # strip all ' in case ' is used to delimit the grid names
  gridfile=${gridfile//\"/} # strip all " in case " is used to delimit the grid names
  gridfile=${gridfile//\,/} # strip all , in case , is used to separate the grid names
  #
  grfinfofile=${gridfile%.nc}-grfinfo.nc
  #
  ls -l ${HGRIDDIR}/$gridfile
  check_error $? "${HGRIDDIR}/$gridfile does not exist."
  # copy gridfile: can be very expensive
  # add_required_file ${HGRIDDIR}/${gridfile} ./
  # replace by linking
  add_link_file ${HGRIDDIR}/${gridfile} ./
  if [ -f ${HGRIDDIR}/${grfinfofile} ]; then
      # same here
      # add_required_file ${HGRIDDIR}/${grfinfofile} ./
      add_link_file ${HGRIDDIR}/${grfinfofile} ./
  fi
done
#-----------------------------------------------------------------------------
# print_required_files
copy_required_files
link_required_files


#-----------------------------------------------------------------------------
# get restart files

if  [ x$restart_atmo_from != "x" ] ; then
  rm -f restart_atm_DOM01.nc
#  ln -s ${basedir}/experiments/${restart_from_folder}/${restart_atmo_from} ${EXPDIR}/restart_atm_DOM01.nc
  cp ${basedir}/experiments/${restart_from_folder}/${restart_atmo_from} cp_restart_atm.nc
  ln -s cp_restart_atm.nc restart_atm_DOM01.nc
  restart=".true."
fi
if  [ x$restart_ocean_from != "x" ] ; then
  rm -f restart_oce.nc
#  ln -s ${basedir}/experiments/${restart_from_folder}/${restart_ocean_from} ${EXPDIR}/restart_oce.nc
  cp ${basedir}/experiments/${restart_from_folder}/${restart_ocean_from} cp_restart_oce_DOM01.nc
  ln -s cp_restart_oce_DOM01.nc restart_oce_DOM01.nc
  restart=".true."
fi
#-----------------------------------------------------------------------------


read_restart_namelists=${read_restart_namelists:=".true."}

#-----------------------------------------------------------------------------
#
# create ICON master namelist
# ------------------------
# For a complete list see Namelist_overview and Namelist_overview.pdf

#-----------------------------------------------------------------------------
# create master_namelist
master_namelist=icon_master.namelist
if [ x$end_date = x ]; then
cat > $master_namelist << EOF
&master_nml
 lrestart            = $restart
/
&master_time_control_nml
 experimentStartDate  = "$start_date"
 restartTimeIntval    = "$restart_interval"
 checkpointTimeIntval = "$checkpoint_interval"
/
&time_nml
 is_relative_time = .false.
/
EOF
else
if [ x$calendar = x ]; then
  calendar='proleptic gregorian'
  calendar_type=1
else
  calendar=$calendar
  calendar_type=$calendar_type
fi
cat > $master_namelist << EOF
&master_nml
 lrestart            = $restart
 read_restart_namelists = $read_restart_namelists
/
&master_time_control_nml
 calendar             = "$calendar"
 checkpointTimeIntval = "$checkpoint_interval"
 restartTimeIntval    = "$restart_interval"
 experimentStartDate  = "$start_date"
 experimentStopDate   = "$end_date"
/
&time_nml
 is_relative_time = .false.
/
EOF
fi
#-----------------------------------------------------------------------------


#-----------------------------------------------------------------------------
# add model component to master_namelist
add_component_to_master_namelist()
{

  model_namelist_filename="$1"
  model_name=$2
  model_type=$3
  model_min_rank=$4
  model_max_rank=$5
  model_inc_rank=$6

cat >> $master_namelist << EOF
&master_model_nml
  model_name="$model_name"
  model_namelist_filename="$model_namelist_filename"
  model_type=$model_type
  model_min_rank=$model_min_rank
  model_max_rank=$model_max_rank
  model_inc_rank=$model_inc_rank
/
EOF

#-----------
#get namelist
  if [ -f ${RUNSCRIPTDIR}/$model_namelist_filename ] ; then
    mv -f ${RUNSCRIPTDIR}/$model_namelist_filename ${EXPDIR}
    check_error $? "mv -f ${RUNSCRIPTDIR}/$model_namelist_filename"
  else
    check_error 1 "${RUNSCRIPTDIR}/$model_namelist_filename does not exist"
  fi

}
#-----------------------------------------------------------------------------


no_of_models=${#namelist_list[*]}
echo "no_of_models=$no_of_models"

j=0
while [ $j -lt ${no_of_models} ]
do
  add_component_to_master_namelist "${namelist_list[$j]}" "${modelname_list[$j]}" ${modeltype_list[$j]} ${minrank_list[$j]} ${maxrank_list[$j]} ${incrank_list[$j]}
  j=`expr ${j} + 1`
done

#-----------------------------------------------------------------------------
# Add JSBACH part to master_namelist

if [[ $run_jsbach == @(yes|true) ]]; then
  cat >> $master_namelist << EOF
&jsb_control_nml
 is_standalone      = .false.
 restart_jsbach     = .false.
 debug_level        = 0
 timer_level        = 0
/
EOF
#
if [[ -n ${atmo_dyn_grids} ]]; then
  set -A gridfiles $atmo_dyn_grids
  no_of_domains=${#gridfiles[*]}
else
  no_of_domains=1
fi
echo "no_of_domains=$no_of_domains"
domain=""
domain_suffix=""
j=1
while [ $j -le ${no_of_domains} ]
do
  if [[ $no_of_domains -gt 1 ]]; then
    # no_of_domains < 10 !
    domain=" DOM0${j}"
    domain_suffix="_d${j}"
  fi
  cat >> $master_namelist << EOF
&jsb_model_nml
 model_id = $j
 model_name = "JSBACH${domain}"
 model_shortname = "jsb${domain_suffix}"
 model_description = 'JSBACH land surface model'
 model_namelist_filename = "${jsbach_namelist}${domain_suffix}"
/
EOF
  if [[ -f ${RUNSCRIPTDIR}/NAMELIST_${EXPNAME}_lnd${domain_suffix} && -f ${EXPDIR}/NAMELIST_${EXPNAME}_lnd${domain_suffix} ]] ; then
    # namelist file has already been copied to expdir by copy_required_files above
    rm ${RUNSCRIPTDIR}/NAMELIST_${EXPNAME}_lnd${domain_suffix}
    check_error $? "rm ${RUNSCRIPTDIR}/NAMELIST_${EXPNAME}_lnd${domain_suffix}"
  else
    check_error 1 "${RUNSCRIPTDIR}/NAMELIST_${EXPNAME}_lnd${domain_suffix} does not exist"
  fi
  j=`expr ${j} + 1`
done
fi
#
#  get model
#
ls -l ${MODEL}
check_error $? "${MODEL} does not exist?"
#
ldd -v ${MODEL}
#
#-----------------------------------------------------------------------------
#
# start experiment
#

rm -f finish.status
#
date
${START} ${MODEL} # > out.txt 2>&1
date
#
if [ -r finish.status ] ; then
  check_final_status 0 "${START} ${MODEL}"
else
  check_final_status -1 "${START} ${MODEL}"
fi
#
#-----------------------------------------------------------------------------
#
finish_status=`cat finish.status`
echo $finish_status
echo "============================"
echo "Script run successfully: $finish_status"
echo "============================"
#-----------------------------------------------------------------------------
if [[ "x$use_hamocc" = "xyes" ]]; then
# store HAMOCC log file
strg="$(ls -rt ${EXPNAME}_hamocc_EU*.nc* | tail -1 )"
prefx="${EXPNAME}_hamocc_EU_tendencies"
foo=${strg##${prefx}}
foo=${foo%%.*}
bgcout_file="bgcout_${foo}"
mv bgcout $bgcout_file
fi
#-----------------------------------------------------------------------------
namelist_list=""
#-----------------------------------------------------------------------------
# check if we have to restart, ie resubmit
#   Note: this is a different mechanism from checking the restart
if [ $finish_status = "RESTART" ] ; then
  echo "restart next experiment..."
  this_script="${RUNSCRIPTDIR}/${job_name}"
  echo 'this_script: ' "$this_script"
  touch ${restartSemaphoreFilename}
  cd ${RUNSCRIPTDIR}
  ${submit} $this_script
else
  [[ -f ${restartSemaphoreFilename} ]] && rm ${restartSemaphoreFilename}
fi

#-----------------------------------------------------------------------------
# automatic call/submission of post processing if available
if [ "x${autoPostProcessing}" = "xtrue" ]; then
  # check if there is a postprocessing is available
  cd ${RUNSCRIPTDIR}
  targetPostProcessingScript="./post.${EXPNAME}.run"
  [[ -x $targetPostProcessingScript ]] && ${submit} ${targetPostProcessingScript}
  cd -
fi

#-----------------------------------------------------------------------------

cd $RUNSCRIPTDIR

#-----------------------------------------------------------------------------


# exit 0
#
# vim:ft=sh
#-----------------------------------------------------------------------------
