#! /usr/bin/env python
# -*- coding: utf-8 -*-
#_____________________________________________________________________________
# mistral batch job parameters
#
#SBATCH --account=mh0287
#SBATCH --job-name=lkm0030_run
#SBATCH --partition=compute
#SBATCH --workdir=/home/zmaw/m214089/icon-aes-6146/run
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=24
#SBATCH --output=/home/zmaw/m214089/icon-aes-6146/run/lkm0030.run.%j.o
#SBATCH --error=/home/zmaw/m214089/icon-aes-6146/run/lkm0030.run.%j.o
#SBATCH --exclusive
#SBATCH --time=02:00:00
#
#_____________________________________________________________________________
#
import os
import sys
import resource
import shutil
import re
import errno
import time
import datetime
import subprocess
import fnmatch
import logging
import tarfile
#_____________________________________________________________________________
#
#________________________________AMIP_experiment______________________________
#
#_____________________________________________________________________________
# create logger
log = logging.getLogger('AMIP runscript')
log.setLevel(logging.DEBUG)
# console handler
ch = logging.StreamHandler()
formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s', '%Y-%m-%d %H:%M:%S')
ch.setFormatter(formatter)
log.addHandler(ch)
#_____________________________________________________________________________
#
class ModelNamelist:

    __model_types = { 'atmo': 1, 'ocean': 2, 'testbed': 99 }

    def __init__(self, minrank, maxrank, incrank, namelist, name):
        self.min_rank = minrank
        self.max_rank = maxrank
        self.inc_rank = incrank
        self.model_name = name
        self.model_type = self.__model_types.get(name, None)
        self.model_namelist = namelist

    def __repr__(self):
        return 'Model namelist: %s ranks: min = %6d, max = %6d, inc = %2d (name: %s, type %d)' % (
            self.model_namelist, 
            self.min_rank,
            self.max_rank,
            self.inc_rank,
            self.model_name,
            self.model_type )
#_____________________________________________________________________________
#
file_links = {}
file_copies = {}
#
def add_file_link (src, dst):
    if not os.path.isfile(src):
        log.error('%s does not exist!' % ( src ))
        sys.exit(-1)
    else:
        file_links[dst] = src        
    return

def print_file_links():
    for dst, src in file_links.items():
        log.info('Link source %s target %s' % ( src, dst ))
    return

def do_file_links():
    for dst, src in file_links.items():
        os.symlink(src, dst)
        log.info('Create target link %s of source %s' % ( dst, src ))
    return

def tar_file_links(experiment):
    tar_filename = '%s%s' % ( experiment, '-links.tar' )
    with tarfile.open(tar_filename, 'w') as tar:
        for ignore, file in file_links.items():
            log.info('Add source %s to %s' % ( file, tar_filename ))            
            tar.add(file)
    return

def add_file_copy (src, dst):
    if not os.path.isfile(src):
        log.error('%s does not exist!' % ( src ))
        sys.exit(-1)
    else:
        file_copies[dst] = src        
    return

def print_file_copies():
    for dst, src in file_copies.items():
        log.info('Copy source %s target %s' % ( src, dst ))
    return

def do_file_copies():
    for dst, src in file_copies.items():
        shutil.copyfile(src, dst)
        log.info('Copied source %s to %s' % ( src, dst ))
    return

def tar_file_copies(experiment):
    tar_filename = '%s%s' % ( experiment, '-copies.tar' )
    with tarfile.open(tar_filename, 'w') as tar:
        for ignore, file in file_copies.items():
            log.info('Add source %s to %s' % ( file, tar_filename ))
            tar.add(file)
    return
#_____________________________________________________________________________
# Note where we are currently working

log.info('Initial working directory ' + os.getcwd())

#_____________________________________________________________________________
# Target setup

log.info('Setup of user definable variables ...')

expname  = 'lkm0030'

loadmodule  = []

site        = 'dkrz.de'
target      = 'bullx'
compiler    = 'gcc'
with_mpi    = 'yes'
with_openmp = 'no'
#job_name    = os.path.basename(__file__))
job_name    = 'lkmpy.run'
submit      = 'sbatch'

# OpenMP setup

icon_threads    = 1
omp_num_threads = 1
omp_schedule    = 'static,4'
omp_dynamic     = 'false'
omp_stacksize   = '200m'

# push OpenMP environment variables

os.environ['ICON_THREADS']    = str(icon_threads)
os.environ['OMP_NUM_THREADS'] = str(omp_num_threads)
os.environ['OMP_SCHEDULE']    = str(omp_schedule)
os.environ['OMP_DYNAMIC']     = str(omp_dynamic)
os.environ['OMP_STACKSIZE']   = str(omp_stacksize)

# MPI setup

no_of_nodes        = os.environ.get('SLURM_JOB_NUM_NODES', '1')

mpi_root           = '/sw/rhel6-x64/intel/impi/5.1.0.038_dapl2.1.6/compilers_and_libraries/linux/mpi/intel64'
mpi_procs_pernode  = 24
mpi_total_procs    = int(no_of_nodes) * mpi_procs_pernode
start_command_args = [ 'srun',
                       '--cpu-freq=2500000',
                       '--kill-on-bad-exit=1',
                       '--nodes=' + no_of_nodes,
                       '--cpu_bind=cores',
                       '--distribution=block:block',
                       '--ntasks-per-node=' + str(mpi_procs_pernode),
                       '--ntasks=' + str(mpi_total_procs), 
                       '--propagate=STACK' ]

# other setups

nproma   = 16

cdo      = 'cdo'
cdo_diff = 'cdo diffn'

# directories setup

log.info('Directories setup ...')

basedir = os.path.abspath(os.path.join(os.environ.get('SLURM_SUBMIT_DIR', os.path.dirname( __file__ )), os.pardir))

icondir = basedir

builddir = 'build/x86_64-unknown-linux-gnu'
bindir   = os.path.join(*[basedir, builddir, 'bin'])
runscriptdir = os.path.join(icondir, 'run')
expdir = os.path.join(os.path.join(icondir, 'experiments'), expname)

icon_data_poolFolder         = '/pool/data/ICON'
icon_data_buildbotFolder     = '/pool/data/ICON/buildbot_data'
icon_data_buildbotFolder_aes = os.path.join(icon_data_buildbotFolder, 'aes')
icon_data_buildbotFolder_oes = os.path.join(icon_data_buildbotFolder, 'oes')

# miscellaneous

resource.setrlimit(resource.RLIMIT_STACK, (resource.RLIM_INFINITY, resource.RLIM_INFINITY))

if any('mxm' in module for module in loadmodule):
    mxm_root = os.environ['MXM_HOME']
    start_command_args.append('--export=LD_PRELOAD=${LD_PRELOAD+$LD_PRELOAD:}' + os.path.join(mxm_root, 'lib/libmxm.so'))

#_____________________________________________________________________________
#

log.info('Experiment setup ...')

# horizontal grid(s)

grids_folder   = os.path.join(icon_data_poolFolder, 'grids/private/r2b4_amip')
atmo_dyn_grids = 'r2b4_amip.nc'

# start and end date+time
start_date = '1979-01-01T00:00:00Z'
end_date   = '1979-01-02T00:00:00Z'

# restart intervals
checkpoint_interval = 'P1Y'
restart_interval    = 'P1Y'

# NEEDED TO KEEP THIS TEST WORKING WITHOUT '--enable-mtime-loop' CONFIGURATION.
# TO BE DELETED AFTER THE 'mtime time loop' IS COMPLETELY IMPLEMENTED.
minutes = 60 # seconds
dt_checkpoint =  8 * minutes
dt_restart    = 16 * minutes

# output intervals
output_interval = 'PT2H'
file_interval   = 'P1D'

#_____________________________________________________________________________
# namelist files

atm_namelist = 'NAMELIST_%s_atm' % ( expname )
lnd_namelist = 'NAMELIST_%s_lnd' % ( expname )

log.info('Namelist setup ...')

# atmospheric dynamics and physics

atm_namelist_string = '''
&parallel_nml
 nproma           = %(nproma)s
! num_io_procs     = 6 ! fails with JSBACH
/
&grid_nml
 dynamics_grid_filename = '%(atmo_dyn_grids)s',
/
&run_nml
 num_lev          = 47          ! number of full levels
 dtime            = 240         ! [s] time step   !! MUST BE EQUAL TO 'modelTimeStep' !!
 modelTimeStep    = 'PT4M'
 ltestcase        = .FALSE.     ! run testcase
 ldynamics        = .TRUE.      ! dynamics
 ltransport       = .TRUE.      ! transport
 ntracer          = 3           ! number of tracers
 iforcing         = 2           ! 0: none, 1: HS, 2: ECHAM, 3: NWP
 output           = 'nml'
 msg_level        = 15          ! level of details report during integration 
 restart_filename = '%(expname)s_restart_atm_<rsttime>.nc'
 irad_type        = 2
/
&extpar_nml
 itopo            = 1           ! 1: read topography from the grid file
 l_emiss          = .FALSE.
/
&initicon_nml
 init_mode        = 2           ! 2: initialize from IFS analysis
/
&dynamics_nml
 iequations       = 3           ! 3: ICONAM dynamics
/
&nonhydrostatic_nml
 ndyn_substeps    = 2           ! dtime/dt_dyn
 damp_height      = 50000.      ! [m]
 rayleigh_coeff   = 0.10
 vwind_offctr     = 0.2
 divdamp_fac      = 0.004
/
&interpol_nml
 rbf_scale_mode_ll = 1
/
&sleve_nml
 min_lay_thckn    = 40.         ! [m]
 top_height       = 83000.      ! [m]
 stretch_fac      = 0.9
 decay_scale_1    = 4000.       ! [m]
 decay_scale_2    = 2500.       ! [m]
 decay_exp        = 1.2
 flat_height      = 16000.      ! [m]
/
&diffusion_nml
/
&transport_nml
 ctracer_list     = 'vwi'       ! water vapour, cloud water, cloud ice
 ivadv_tracer     = 3,3,3
 itype_hlimit     = 3,4,4
 ihadv_tracer     = 52,2,2
/
&echam_phy_nml
 dt_rad           =  7200.       ! [s] radiation time step
 lrad             = .TRUE.
 lvdiff           = .TRUE.
 lconv            = .TRUE.
 lcond            = .TRUE.
 lgw_hines        = .TRUE.
 lssodrag         = .TRUE.
 lice             = .TRUE.
 ljsbach          = .TRUE.
 lebudget         = .TRUE.
 lmlo             = .FALSE.
 lamip            = .TRUE.
/
&radiation_nml
 irad_h2o         = 1           ! 1: prognostic vapor, liquid and ice
 irad_co2         = 4           ! 4: from greenhouse gas scenario
 irad_ch4         = 4           ! 4: from greenhouse gas scenario
 irad_n2o         = 4           ! 4: from greenhouse gas scenario
 irad_o3          = 8           ! 8: horizontally and vertically variable
 irad_o2          = 2           ! 2: horizontally and vertically constant
 irad_cfc11       = 4           ! 4: from greenhouse gas scenario
 irad_cfc12       = 4           ! 4: from greenhouse gas scenario
 irad_aero        = 15          ! 0: no aerosol
                                !13: only Kinne's tropospheric aerosols 
                                !14: only Stenchikov's volcanic aerosols
                                !15: Kinne aerosol optics for troposphere
                                !   +Stenchikov aerosol optics for stratosphere
 lrad_aero_diag   = .FALSE.     ! switch for diagnostics of the aerosol optical properties
 ighg             = 1           ! 1: transient well mixed greenhouse gas concentrations
 izenith          = 4           ! 4: seasonal and diurnal cycle
 isolrad          = 0           ! 1: transient solar irradiance (at 1 AE)
/
&psrad_nml
rad_perm          = 1           ! Integer for perturbing random number seeds
/
&echam_conv_nml
/
&gw_hines_nml
/
''' % { 'nproma': nproma, 'atmo_dyn_grids': atmo_dyn_grids, 'expname': expname }

# land surface and soil

lnd_namelist_string = '''
&jsb_model_nml
  usecase         = 'jsbach_lite'
/
&jsb_srf_nml
  bc_filename     = 'bc_land_phys.nc'
  bc_sso_filename = 'bc_land_sso.nc'
  ic_filename     = 'ic_land_soil.nc'
/
&jsb_soil_nml
  active          = .TRUE.
  nsoil_energy    = 5
  nsoil_water     = 5
  bc_filename     = 'bc_land_soil.nc'
  ic_filename     = 'ic_land_soil.nc'
/
&jsb_veg_nml
  active          = .TRUE.
  bc_filename     = 'bc_land_phys.nc'
  ic_filename     = 'ic_land_soil.nc'
/
'''

#_____________________________________________________________________________
# input

log.info('File setup ...')

# model files

add_file_link(os.path.join(basedir, 'data/rrtmg_lw.nc'), './rrtmg_lw.nc')
add_file_link(os.path.join(basedir, 'data/rrtmg_sw.nc'), './rrtmg_sw.nc')
add_file_link(os.path.join(basedir, 'data/ECHAM6_CldOptProps.nc'), './ECHAM6_CldOptProps.nc')

# dictionary file for output variable names

dict_file = 'dict.' + expname
shutil.copy('dict.iconam.mpim', dict_file)
add_file_copy(os.path.join(*[basedir, 'run', dict_file]), dict_file)

# initial conditions

initial_data = os.path.join(icon_data_poolFolder, 'input/r0003')

# atmosphere: ECMWF analysis, 1979-01-01T00:00:00Z

datadir = '/pool/data/ICON/setup/ifs_iconremap_amip'
add_file_link(os.path.join(datadir, 'ifs_remap_R2B4_00XX_AMIP_2012010100_setyear1979.nc'), './ifs2icon_R2B04_DOM01.nc')

# land: source?, date+time?
datadir = os.path.join(initial_data, 'r2b4_amip/lnd')
add_file_link(os.path.join(datadir, 'ic_land_soil_1976.nc'), './ic_land_soil.nc')

# boundary conditions
              
# assume start_date and end_date have the format +/-yyyyyyy-... (any number of year digits)

start_year = int(re.search(r'^([-|+]?[\d]+).+', start_date).groups(1)[0]) - 1
end_year   = int(re.search(r'^([-|+]?[\d]+).+', end_date).groups(1)[0]) + 1

years = range(start_year, end_year + 1) # python's range requires the increase the upper bound in this case

# well mixed greenhouse gases
datadir = os.path.join(initial_data, 'global/atm')
add_file_link(os.path.join(datadir, 'bc_greenhouse_rcp45_1765-2500.nc'), './bc_greenhouse_gases.nc')

# ozone
datadir = os.path.join(initial_data, 'r2b4_amip/atm/bc_ozone_cmip5')
for year in years:
    add_file_link(os.path.join(datadir, 'bc_ozone_cmip5_%s.nc' % ( str(year) )), './bc_ozone_%s.nc' % ( str(year) ))

# tropospheric aerosol
datadir = os.path.join(initial_data, 'r2b4_amip/atm/bc_aeropt_kinne')
for year in years:
    add_file_link(os.path.join(datadir, 'bc_aeropt_kinne_lw_b16_coa.nc'), './bc_aeropt_kinne_lw_b16_coa_%s.nc' % ( str(year) ))
    add_file_link(os.path.join(datadir, 'bc_aeropt_kinne_sw_b14_coa.nc'), './bc_aeropt_kinne_sw_b14_coa_%s.nc' % ( str(year) ))
    if year <= 2000:
        add_file_link(os.path.join(datadir, 'bc_aeropt_kinne_sw_b14_fin_%s.nc' % ( str(year) )), './bc_aeropt_kinne_sw_b14_fin_%s.nc' % ( str(year) ))
    else:
        add_file_link(os.path.join(datadir, 'bc_aeropt_kinne_sw_b14_fin_rcp45_%s.nc' % ( str(year) )), './bc_aeropt_kinne_sw_b14_fin_%s.nc' % ( str(year) ))
        
# stratospheric aerosol
datadir = os.path.join(initial_data, 'r2b4_amip/atm/bc_aeropt_stenchikov')
for year in years:
    if year <= 1999:
        add_file_link(os.path.join(datadir, 'bc_aeropt_stenchikov_lw_b16_sw_b14_%s.nc' % ( str(year) )), './bc_aeropt_stenchikov_lw_b16_sw_b14_%s.nc' % ( str(year) ))
    else:
        add_file_link(os.path.join(datadir, 'bc_aeropt_stenchikov_lw_b16_sw_b14_1999.nc'), './bc_aeropt_stenchikov_lw_b16_sw_b14_%s.nc' % ( str(year) ))

# sst and sic
datadir = os.path.join(initial_data, 'r2b4_amip/oce')
add_file_link(os.path.join(datadir, 'bc_sic_pcmdi_1870-2010.nc'), './bc_sic.nc')
add_file_link(os.path.join(datadir, 'bc_sst_pcmdi_1870-2010.nc'), './bc_sst.nc')

# ssi and tsi
datadir = os.path.join(initial_data, 'global/sun')
add_file_link(os.path.join(datadir, 'bc_solar_irradiance_14band_1849-2399.nc'), './bc_solar_irradiance_sw_b14.nc')

# land parameters
datadir = os.path.join(initial_data, 'r2b4_amip/lnd')
add_file_link(os.path.join(datadir, 'bc_land_frac_1976.nc'), './bc_land_frac.nc')
add_file_link(os.path.join(datadir, 'bc_land_phys_1976.nc'), './bc_land_phys.nc')
add_file_link(os.path.join(datadir, 'bc_land_soil_1976.nc'), './bc_land_soil.nc')
add_file_link(os.path.join(datadir, 'bc_land_sso_1976.nc'), './bc_land_sso.nc')

#_____________________________________________________________________________
# output

log.info('Output setup ...')

# Parameters for all output files

atm_namelist_string += '''
&io_nml
 dt_checkpoint    = %(dt_checkpoint)s  !  NEEDED TO KEEP THIS TEST WORKING WITHOUT '--enable-mtime-loop' CONFIGURATION.
 output_nml_dict  = '%(dict_file)s'
 netcdf_dict      = '%(dict_file)s'
 itype_pres_msl   = 4
 lzaxis_reference = .FALSE. 
/
''' % { 'dt_checkpoint': dt_checkpoint, 'dict_file': dict_file }

# Define grids for horizontal remapping
#
# The ICON RmBn grid has 3*m*2**n rows of triangles between the vertices at the N and S pole.
# The number of triangles in a row around this axis increases linearly from 5 to 5*(1+2*(i-1))
# at the base of the 'polar' icosahedral triangles. In the 'tropical' icosahedral triangles
# all rows have a  5*(2*(m*2**n)) triangles. The triangles are either northward or southward
# pointing. Thus the smallest periodic element in a tropical row is a rhombus formed by two
# adjacent triangles. A tropical row has 5*(m*n**2) rhombi.
#
# The R2B4 grid has a total of 20480 triangular cells in 96 rows.
# The tropical rows have 320 triangles or 160 rhombi.
#
# Therefore the following regular lon-lat grids are of interest for remapping:

# regular  grid: nlat=96, nlon=192, npts=18432, dlat=1.875 deg, dlon=1.875 deg
reg_lat_def_reg = (-89.0625, 1.875, 89.0625)
reg_lon_def_reg = (0., 1.875, 358.125)

# rhombus  grid: nlat=96, nlon=160, npts=15360, dlat=1.875 deg, dlon=2.250 deg
reg_lat_def_rmb = reg_lat_def_reg
reg_lon_def_rmb = (0., 2.25, 357.75)

# triangle grid: nlat=96, nlon=320, npts=30720, dlat=1.875 deg, dlon=1.125 deg
reg_lat_def_tri = reg_lat_def_reg
reg_lon_def_tri = (0., 1.125, 358.875)

output_atm_3d = True
if output_atm_3d:
    atm_namelist_string += '''
&output_nml
 output_filename  = '%(expname)s_atm_3d'
 filename_format  = '<output_filename>_<levtype_l>_<datetime2>'
 remap            = 0
 output_grid      = .TRUE.
 output_start     = '%(start_date)s'
 output_end       = '%(end_date)s'
 output_interval  = '%(output_interval)s'
 file_interval    = '%(file_interval)s'
 include_last     = .FALSE.
 ml_varlist       = 'ta','ua','va','wap','hus','hur','cl','clw','cli','rho',
                    'zg','pfull'
/
''' % { 'expname': expname, 'start_date': start_date, 'end_date': end_date, 'output_interval': output_interval, 'file_interval': file_interval }
    
output_atm_2d = True
if output_atm_3d:
    atm_namelist_string += '''
&output_nml
 output_filename  = '%(expname)s_atm_2d'
 filename_format  = '<output_filename>_<levtype_l>_<datetime2>'
 remap            = 0
 output_grid      = .TRUE.
 output_start     = '%(start_date)s'
 output_end       = '%(end_date)s'
 output_interval  = '%(output_interval)s'
 file_interval    = '%(file_interval)s'
 include_last     = .FALSE.
 ml_varlist       = 'ps'      , 'psl'     ,
                    'cosmu0'  , 'daylght_frc', 'rsdt'    ,
                    'rsns'    , 'rlns'    , 'rsnt'    , 'rlnt'    ,
                    'rsns_wtr', 'rsns_ice', 'rsns_lnd',
                    'rlns_wtr', 'rlns_ice', 'rlns_lnd', 'tend_ta_rlw_impl',
                    'ts_wtr'  , 'ts_ice'  , 'ts_lnd'  , 'ts'      , 'ts_rad'  ,
                    'sic'     , 'sit'     ,
                    'visdffsfc','nirdffsfc','vissfc'  , 'nirsfc'  ,
                    'albedo'  , 'albedo_wtr', 'albedo_ice', 'albedo_lnd',
                    'albvisdir','albvisdif' , 'albnirdir' , 'albnirdif',
                    'albvisdir_ice', 'albvisdir_wtr', 'albvisdir_lnd',
                    'clt'     ,
                    'prlr'    , 'prls'    , 'prcr'    , 'prcs'    ,
                    'pr'      , 'prw'     , 'cllvi'   , 'clivi'   ,
                    'hfls'    , 'hfss'    , 'evspsbl' ,
                    'hfls_wtr', 'hfls_ice', 'hfls_lnd',
                    'hfss_wtr', 'hfss_ice', 'hfss_lnd',
                    'tauu'    , 'tauv'    ,
                    'tauu_wtr', 'tauu_ice', 'tauu_lnd',
                    'tauv_wtr', 'tauv_ice', 'tauv_lnd',
                    'tauu_sso', 'tauv_sso', 'diss_sso', 
                    'sh_vdiff', 'qv_vdiff',
                    'ch_concloud',
                    'con_dtrl', 'con_dtri', 'con_iteqv',
                    'cld_dtrl', 'cld_dtri', 'cld_iteq'
/
''' % { 'expname': expname, 'start_date': start_date, 'end_date': end_date, 'output_interval': output_interval, 'file_interval': file_interval }

output_phy_3d = True
if output_phy_3d:
    atm_namelist_string += '''
&output_nml
 output_filename  = '%(expname)s_phy_3d'
 filename_format  = '<output_filename>_<levtype_l>_<datetime2>'
 remap            = 0
 output_grid      = .TRUE.
 output_start     = '%(start_date)s'
 output_end       = '%(end_date)s'
 output_interval  = '%(output_interval)s'
 file_interval    = '%(file_interval)s'
 include_last     = .FALSE.
 ml_varlist       = 'tend_ta'      , 'tend_ta_dyn'  , 'tend_ta_phy'  ,
                    'tend_ta_rlw'  , 'tend_ta_rsw'  ,
                    'tend_ta_vdf'  , 'tend_ta_gwh'  , 'tend_ta_sso'  ,
                    'tend_ta_cnv'  , 'tend_ta_cld'  , 
                    'tend_ua'      , 'tend_ua_dyn'  , 'tend_ua_phy'  ,
                    'tend_ua_vdf'  , 'tend_ua_gwh'  , 'tend_ua_sso'  ,
                    'tend_ua_cnv'  , 
                    'tend_va'      , 'tend_va_dyn'  , 'tend_va_phy'  ,
                    'tend_va_vdf'  , 'tend_va_gwh'  , 'tend_va_sso'  ,
                    'tend_va_cnv'  ,
                    'tend_hus'     , 'tend_hus_dyn' , 'tend_hus_phy' ,
                    'tend_hus_cld' , 'tend_hus_cnv' , 'tend_hus_vdf' ,
                    'pfull'
/
''' % { 'expname': expname, 'start_date': start_date, 'end_date': end_date, 'output_interval': output_interval, 'file_interval': file_interval }

output_rad_2d_3d_rmb = True
if output_rad_2d_3d_rmb:
    atm_namelist_string += '''
&output_nml
 output_filename  = '%(expname)s_rad_2d_3d_rmb'
 filename_format  = '<output_filename>_<levtype_l>_<datetime2>'
 remap            = 1
 reg_def_mode     = 1
 reg_lat_def      = %(reg_lat_def_rmb)s
 reg_lon_def      = %(reg_lon_def_rmb)s
 output_grid      = .TRUE.
 output_start     = '%(start_date)s'                  ! ISO-format date+time
 output_end       = '%(end_date)s'                    ! ISO-format date+time
 output_interval  = '%(output_interval)s'             ! ISO-format interval
 file_interval    = '%(file_interval)s'               ! ISO-format interval
 include_last     = .FALSE.
 ml_varlist       = 'cosmu0','cosmu0_rad', 'daylght_frc',
		    'visfrcsfc', 'parsfcdn', 
                    'nirdffsfc', 'visdffsfc',
                    'pardffsfc', 'rlus_radt', 
                    'lwflxclr', 'swtrmclr',
                    'lwflxall', 'swtrmall',
		    'o3', 
                    'aer_aod_533',  'aer_ssa_533',  'aer_asy_533',
		    'aer_aod_2325', 'aer_ssa_2325', 'aer_asy_2325',
		    'aer_aod_9731'
/
''' % { 'expname': expname, 'start_date': start_date, 'end_date': end_date, 'output_interval': output_interval, 'file_interval': file_interval,
        'reg_lat_def_rmb': ', '.join(format(f, 'f') for f in reg_lat_def_rmb), 'reg_lon_def_rmb': ', '.join(format(f, 'f') for f in reg_lon_def_rmb) }
   
output_phy_2d_rmb = True
if output_phy_2d_rmb:
    atm_namelist_string += '''
&output_nml
 output_filename  = '%(expname)s_phy_2d_rmb'
 filename_format  = '<output_filename>_<levtype_l>_<datetime2>'
 remap            = 1
 reg_def_mode     = 1
 reg_lat_def      = %(reg_lat_def_rmb)s
 reg_lon_def      = %(reg_lon_def_rmb)s
 output_grid      = .TRUE.
 output_start     = '%(start_date)s'                  ! ISO-format date+time
 output_end       = '%(end_date)s'                    ! ISO-format date+time
 output_interval  = '%(output_interval)s'             ! ISO-format interval
 file_interval    = '%(file_interval)s'               ! ISO-format interval
 include_last     = .FALSE.
 ml_varlist       = 'cosmu0'  , 'daylght_frc',      'rsdt'    ,
                    'rsns'    , 'rlns'    , 'rsnt'    , 'rlnt'    ,
                    'rsns_wtr', 'rsns_ice', 'rsns_lnd',
                    'rlns_wtr', 'rlns_ice', 'rlns_lnd',
                    'ts_wtr'  , 'ts_ice'  , 'ts_lnd'  , 'ts'      , 'ts_rad'  ,
                    'sic'     , 'sit'     ,
                    'clt'     ,
                    'prlr'    , 'prls'    , 'prcr'    , 'prcs'    ,
                    'pr'      , 'prw'     , 'cllvi'   , 'clivi'   ,
                    'hfls'    , 'hfss'    , 'evspsbl' ,
                    'hfls_wtr', 'hfls_ice', 'hfls_lnd',
                    'hfss_wtr', 'hfss_ice', 'hfss_lnd',
                    'tauu'    , 'tauv'    ,
                    'tauu_wtr', 'tauu_ice', 'tauu_lnd',
                    'tauv_wtr', 'tauv_ice', 'tauv_lnd',
                    'tauu_sso', 'tauv_sso', 'diss_sso', 
                    'sh_vdiff', 'qv_vdiff',
                    'ch_concloud',
                    'con_dtrl', 'con_dtri', 'con_iteqv',
                    'cld_dtrl', 'cld_dtri', 'cld_iteq',
                    'rintop', 'rtype', 'topmax'
/
''' % { 'expname': expname, 'start_date': start_date, 'end_date': end_date, 'output_interval': output_interval, 'file_interval': file_interval,
        'reg_lat_def_rmb': ', '.join(format(f, 'f') for f in reg_lat_def_rmb), 'reg_lon_def_rmb':  ', '.join(format(f, 'f') for f in reg_lon_def_rmb) }

output_aer_3d = False # True needs lrad_aero_diag=.TRUE. in radiation_nml
if output_aer_3d:
    atm_namelist_string += '''
&output_nml
 output_filename  = '%(expname)s_aer_3d'
 filename_format  = '<output_filename>_<levtype_l>_<datetime2>'
 remap            = 0
 output_grid      = .TRUE.
 output_start     = '%(start_date)s'
 output_end       = '%(end_date)s'
 output_interval  = '%(output_interval)s'
 file_interval    = '%(file_interval)s'
 include_last     = .FALSE.
 ml_varlist       = 'aer_aod_533',  'aer_ssa_533',  'aer_asy_533' , 
                    'aer_aod_2325', 'aer_ssa_2325', 'aer_asy_2325', 
                    'aer_aod_9731',
                    'pfull'
/
''' % { 'expname': expname, 'start_date': start_date, 'end_date': end_date, 'output_interval': output_interval, 'file_interval': file_interval }

output_lnd = True
if output_lnd:
    atm_namelist_string += '''
&output_nml
 output_filename  = '%(expname)s_lnd'
 filename_format  = '<output_filename>_<levtype_l>_<datetime2>'
 remap            = 0
 output_grid      = .TRUE.
 output_start     = '%(start_date)s'
 output_end       = '%(end_date)s'
 output_interval  = '%(output_interval)s'
 file_interval    = '%(file_interval)s'
 include_last     = .FALSE.
 ml_varlist       = 'fract', 'alb_vis_srf', 'alb_nir_srf', 't_srf', 'lai', 's_srf', 'qsat_srf'
                    'canopy_cond', 'ws_l', 'ws_fc_l', 'ws_pwp_l', 'ws_sat_l', 'ws'
                    'water_stress', 'ws_root', 'ws_fc_root', 'ws_pwp_root'
                    'albedo_srf', 't_air', 'q_air',
                    'lw_srf_down', 'swnir_srf_down', 'swpar_srf_down', 'swvis_srf_down',
                    'root_depth', 'root_depth_l', 'soil_depth', 'soil_depth_l'
                    'evapotrans', 'sensible_hflx', 'latent_hflx' 
                    'fact_qsat_srf', 'fact_qsat_trans_srf', 'fact_q_air', 'fract_fpc_max', 'fract_fpc'
                    't_srf_unfilt', 't_srf_unfilt_old', 't_srf_old'
                    't_soil', 'wsn_srf', 'wsr_srf', 't_eff_srf', 'grnd_hflx'
                    'sfract_srf', 'wfract_srf', 'sfract_soil', 'sfract_can', 'wfract_can', 'wfract_soil'
                    'tte_corr', 'rough_m_srf', 'rough_h_srf'
/
''' % { 'expname': expname, 'start_date': start_date, 'end_date': end_date, 'output_interval': output_interval, 'file_interval': file_interval }

#_____________________________________________________________________________
# set some default values and derive some run parameteres

log.info('Check for restart ...')

try:
    restart
except NameError:
    restart = False

#  do not delete restart semaphore file to enable restart after unintended abort    
restartSemaphoreFilename = 'isRestartRun.sem'

if os.path.isfile(restartSemaphoreFilename):
    restart = True

# wait to let GPFS finish the write operations in batch mode
# TODO: have to check if necessary for lustre

if restart is False and submit is not '':
    log.info('Wait for arrival of files ...')
    time.sleep(1)

# add grids to required files

if os.path.isdir(grids_folder):
   hgriddir = grids_folder
else:
   hgriddir = os.path.join(icondir, 'grids')

all_grids = []

try:
    all_grids.append(atmo_dyn_grids)
except NameError:
    pass

try:
    all_grids.append(atmo_rad_grids)
except NameError:
    pass

try:
    all_grids.append(atmo_rad_grids)
except NameError:
    pass

for gridfile in all_grids:
    add_file_link(os.path.join(hgriddir, gridfile), gridfile)    

#_____________________________________________________________________________
# create ICON master namelist
#
# For a complete list see Namelist_overview and Namelist_overview.pdf

master_namelist = 'icon_master.namelist'
master_namelist_string = ''

try:
    end_date
except NameError:
    end_date = ''

if end_date is not '':
    master_namelist_string = '''
&master_nml
 lrestart             = %(restart)s
/
&master_time_control_nml
 calendar             = 'proleptic gregorian' 
 checkpointTimeIntval = '%(checkpoint_interval)s' 
 restartTimeIntval    = '%(restart_interval)s' 
 experimentStartDate  = '%(start_date)s' 
 experimentStopDate   = '%(end_date)s' 
/
&time_nml
 ini_datetime_string  = '%(start_date)s'
 end_datetime_string  = '%(end_date)s'
 dt_restart           = %(dt_restart)s
/
''' % { 'restart': restart, 'start_date': start_date, 'dt_restart': dt_restart,
        'checkpoint_interval': checkpoint_interval, 'restart_interval': restart_interval, 'end_date':end_date }
else:
    master_namelist_string = '''
&master_nml
 lrestart             = %(restart)s
/
&time_nml
 ini_datetime_string  = '%(start_date)s'
 dt_restart           = %(dt_restart)s
/
''' % { 'restart': restart, 'start_date': start_date, 'dt_restart': dt_restart }

#_____________________________________________________________________________
# set up the model lists if they do not exist. This works for single
# model runs, for coupled runs the lists should be declared explicitly

master_model_definition_list = []

try:
    atm_namelist
    log.info('Have an atmo namelist ...')
    master_model_definition_list.append( ModelNamelist( 0, 65535, 1, atm_namelist, 'atmo'))
    run_atmo = True
except NameError:
    pass

try:
    ocean_namelist
    log.info('Have an ocean namelist ...')
    master_model_definition_list.append( ModelNamelist( 0, 65535, 1, ocean_namelist, 'ocean'))
    run_ocean = True
except NameError:
    pass

try:
    testbed_namelist
    log.info('Have an testbed namelist ...')
    master_model_definition_list.append( ModelNamelist( 0, 65535, 1, testbed_namelist, 'testbed'))
except NameError:
    pass

if not master_model_definition_list:
    log.error('No master model namelist defined ...')
    sys.exit(-1)

# add model component to master_namelist

for namelist in master_model_definition_list:
    master_namelist_string += '''
&master_model_nml
  modelName = '%(model_name)s'
  modelNamelistFilename = '%(model_namelist_filename)s'
  modelType = %(model_type)s
  modelMinRank = %(model_min_rank)s
  modelMaxRank = %(model_max_rank)s
  modelIncRank = %(model_inc_rank)s
/
''' % { 'model_name': namelist.model_name, 'model_namelist_filename': namelist.model_namelist,
        'model_type': namelist.model_type, 'model_min_rank': namelist.min_rank,
        'model_max_rank': namelist.max_rank,'model_inc_rank': namelist.inc_rank }
    
# add JSBACH part to master_namelist

if lnd_namelist is not '':
  master_namelist_string += '''
&jsb_control_nml
 is_standalone      = .false.
 restart_jsbach     = .false.
/
&jsb_model_nml
 model_name = 'JSBACHlite'
 model_shortname = 'lite'
 model_description = 'JSBACH-lite model'
 model_namelist_filename = '%(lnd_namelist)s'
/
''' % { 'lnd_namelist': lnd_namelist }

with open(master_namelist, 'w') as master_namelist_fd:
    master_namelist_fd.write(master_namelist_string.strip() + '\n')
add_file_copy(os.path.join(runscriptdir, master_namelist), os.path.join(expdir, master_namelist))
    
# write component model namelists

with open(atm_namelist, 'w') as atm_namelist_fd:
    atm_namelist_fd.write(atm_namelist_string.strip() + '\n')
add_file_copy(os.path.join(runscriptdir, atm_namelist), os.path.join(expdir, atm_namelist))
              
with open(lnd_namelist, 'w') as lnd_namelist_fd:
    lnd_namelist_fd.write(lnd_namelist_string.strip() + '\n')
add_file_copy(os.path.join(runscriptdir, lnd_namelist), os.path.join(expdir, lnd_namelist))

#_____________________________________________________________________________
# prepare and start finally the model integration. 

log.info('Prepare model ...')

log.info('ICON base directory: %s' % ( icondir ))
log.info('ICON grid directory: %s' % ( hgriddir ))
log.info('ICON run script directory: %s' % ( runscriptdir ))
log.info('ICON experiment directory: %s' % ( expdir ))    
   
# experiment directory, with plenty of space, create if does not exist

try:
    os.makedirs(expdir)
except OSError as exception:
    if exception.errno != errno.EEXIST:
        raise
    
# clean if existed and not empty - done awkward!    
if os.listdir(expdir):
    shutil.rmtree(expdir)
    os.makedirs(expdir)
    
os.chdir(expdir)

log.info('Changed working directory ' + os.getcwd())
              
# do the final 'static' file handling

os.chdir(runscriptdir)

log.info('Changed working directory ' + os.getcwd())

tar_file_links(expname)
tar_file_copies(expname)

sys.exit(0)

do_file_links()
do_file_copies()

# get restart files

try:
    restart_atmo_from
except NameError:
    restart = '.false.'
    restart_atmo_from = ''

if restart_atmo_from is not '':
    os.remove('restart_atm_DOM01.nc')
    shutil.copyfile(os.path.join(*[icondir, 'experiments',restart_from_folder, restart_atmo_from]), 'cp_restart_atm_DOM01.nc')
    os.symlink('cp_restart_atm_DOM01.nc', 'restart_atm_DOM01.nc')
    restart = '.true.'

try:
    restart_ocean_from
except NameError:
    restart = '.false.'
    restart_ocean_from = ''

if restart_ocean_from is not '':
    os.remove('restart_oce.nc')
    shutil.copyfile(os.path.join(*[icondir, 'experiments',restart_from_folder, restart_ocean_from]), 'cp_restart_oce_DOM01.nc')
    os.symlink('cp_restart_oce_DOM01.nc', 'restart_oce_DOM01.nc')
    restart = '.true.'

#_____________________________________________________________________________    
#  set and check for model executable

model = os.path.join(bindir, 'icon')
try:
    os.path.isfile(model)
except Error as why:
    log.error(str(why))
    sys.exit(-1)

# start model

log.info('Start model ...')

try:
    os.remove('finish.status')
except OSError:
    pass

log.info('Start model execution ...')

start_command_args.append(model)
start_command = ' '.join(start_command_args)
subprocess.call(start_command, shell = True) 

log.info('Finish model execution ...')
                               
try:
    os.path.isfile('finish.status')
except IOError as why:
    log.error(str(why))
    sys.exit(-1)
                               
with open('finish.status', 'r') as status_fd:
    run_status = status_fd.read()

log.info('Script finished successfully: %s' % ( run_status ))
                                                              
#_____________________________________________________________________________
# check if we have to stop, restart, or resubmit

if run_status.strip() is 'OK':
    log.info('Experiment finished successfully: %s' % ( run_status ))
    sys.exit(0)
    
if run_status.strip() is 'RESTART':
    log.info('restart next experiment ...')
    this_script = os.path.join(runscriptdir, os.path.basename(__file__))
    log.info('this_script: ' + this_script)
    with open(restartSemaphoreFilename, 'a'):
        os.utime(restartSemaphoreFilename, None)
    os.chdir(runscriptdir)
    log.info('Changed working directory ' + os.getcwd())
    submit_command = ' '.join([submit, this_script]) 
    subprocess.call(submit_command, shell = True) 
else:
    try:
        os.remove(restartSemaphoreFilename)
    except OSError:
        pass

#_____________________________________________________________________________ 
# automatic call/submit of post processing, if available

try:
    autoPostProcessing
    pwd = os.getcwd()
    os.chdir(runscriptdir)
    log.info('Changed working directory ' + os.getcwd())    
    targetPostProcessingScript = './post.%s.run' % ( expname )
    try:
        submit_command = ' '.join([submit, targetPostProcessingScript]) 
        subprocess.call(submit_command, shell = True) 
    except OSError:
        pass
    os.chdir(pwd)
except NameError:
     pass

#_____________________________________________________________________________ 
#

sys.exit(0)

#_____________________________________________________________________________ 
#


